2019-01-18 14:43:12,067 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1783.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1783.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:43:12,067 No Model Save selected!
2019-01-18 14:43:12,069 Loaded Graph data/edges/parsing/ewt/ewt_dev/1783.edges with 15 nodes scale=1.0
2019-01-18 14:43:12,069 Building dataset
2019-01-18 14:43:12,069 Subsample: 15 points with scale 1.0 subsample=14
2019-01-18 14:43:12,084 Built Data Sampler
2019-01-18 14:43:12,084 Creating a fresh model warm_start?=None
2019-01-18 14:43:12,084 	 Warmstarting? None None 15
2019-01-18 14:43:12,084 Embedding() torch.Size([15, 10])
2019-01-18 14:43:12,084 relative No Rescale
2019-01-18 14:43:12,085 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:43:12,085 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:43:12,085 *** Initial Checkpoint. Computing Stats
2019-01-18 14:43:12,085 	 Computing Major Stats lazily... 
2019-01-18 14:43:12,086 		 Completed edges=210 good=210 bad=0
2019-01-18 14:43:12,089 Distortion avg=0.9981578646585165 wc=11.112420602846855 me=0.005628252251848828 mc=1974.3998857187912 nan_elements=0
2019-01-18 14:43:12,089 MAP = 0.1929782254782255
2019-01-18 14:43:12,090 scale=[array([1.])]
2019-01-18 14:43:12,090 *** End Initial Checkpoint

2019-01-18 14:43:12,148 1 loss=0.9963206615263887
2019-01-18 14:43:12,149 2 loss=0.8952820822802222
2019-01-18 14:43:12,150 3 loss=0.8083201521509652
2019-01-18 14:43:12,150 4 loss=0.7367043538011897
2019-01-18 14:43:12,151 5 loss=0.6777729014034859
2019-01-18 14:43:12,151 6 loss=0.6290329432750924
2019-01-18 14:43:12,152 7 loss=0.5884278725819518
2019-01-18 14:43:12,153 8 loss=0.5543112633299594
2019-01-18 14:43:12,153 9 loss=0.5253791228817707
2019-01-18 14:43:12,154 10 loss=0.5006030961727086
2019-01-18 14:43:12,154 11 loss=0.4791733852982003
2019-01-18 14:43:12,155 12 loss=0.460452256813193
2019-01-18 14:43:12,156 13 loss=0.4439369587034188
2019-01-18 14:43:12,156 14 loss=0.4292304513327929
2019-01-18 14:43:12,157 15 loss=0.4160184354027581
2019-01-18 14:43:12,158 16 loss=0.40405137733940655
2019-01-18 14:43:12,158 17 loss=0.39313046732219753
2019-01-18 14:43:12,159 18 loss=0.3830966570727928
2019-01-18 14:43:12,159 19 loss=0.3738221028402252
2019-01-18 14:43:12,160 20 loss=0.36520348401911024
2019-01-18 14:43:12,161 21 loss=0.3571567835335994
2019-01-18 14:43:12,161 22 loss=0.3496132073986489
2019-01-18 14:43:12,162 23 loss=0.34251599238199054
2019-01-18 14:43:12,163 24 loss=0.335817906468054
2019-01-18 14:43:12,163 25 loss=0.32947929021117506
2019-01-18 14:43:12,164 26 loss=0.3234665207591893
2019-01-18 14:43:12,164 27 loss=0.31775080647594617
2019-01-18 14:43:12,165 28 loss=0.3123072403808698
2019-01-18 14:43:12,166 29 loss=0.30711405637462075
2019-01-18 14:43:12,166 30 loss=0.30215204445772575
2019-01-18 14:43:12,167 31 loss=0.29740409066839385
2019-01-18 14:43:12,167 32 loss=0.29285481488090653
2019-01-18 14:43:12,168 33 loss=0.2884902853911732
2019-01-18 14:43:12,168 34 loss=0.28429779373720004
2019-01-18 14:43:12,169 35 loss=0.28026567674160496
2019-01-18 14:43:12,170 36 loss=0.2763831755389068
2019-01-18 14:43:12,170 37 loss=0.2726403235305495
2019-01-18 14:43:12,171 38 loss=0.26902785692589043
2019-01-18 14:43:12,171 39 loss=0.2655371428787576
2019-01-18 14:43:12,172 40 loss=0.26216012129522126
2019-01-18 14:43:12,173 41 loss=0.25888925723005723
2019-01-18 14:43:12,173 42 loss=0.2557175014547284
2019-01-18 14:43:12,174 43 loss=0.2526382573058772
2019-01-18 14:43:12,174 44 loss=0.2496453523395457
2019-01-18 14:43:12,175 45 loss=0.24673301364558717
2019-01-18 14:43:12,176 46 loss=0.24389584593706978
2019-01-18 14:43:12,176 47 loss=0.24112881173514744
2019-01-18 14:43:12,177 48 loss=0.23842721313213605
2019-01-18 14:43:12,177 49 loss=0.23578667474329473
2019-01-18 14:43:12,178 50 loss=0.23320312755811867
2019-01-18 14:43:12,178 final loss=0.23320312755811867
2019-01-18 14:43:12,178 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:43:12,178 	 Computing Major Stats lazily... 
2019-01-18 14:43:12,179 		 Completed edges=210 good=210 bad=0
2019-01-18 14:43:12,182 Distortion avg=0.43492657049295197 wc=7.733348691435552 me=1.7132371018359518 mc=4.513881168665028 nan_elements=0
2019-01-18 14:43:12,182 MAP = 0.4253174603174603
2019-01-18 14:43:12,182 scale=[array([1.])]
2019-01-18 15:14:08,484 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1783.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1783.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:14:08,485 No Model Save selected!
