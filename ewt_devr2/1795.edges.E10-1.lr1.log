2019-01-18 14:39:52,683 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1795.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1795.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:52,684 No Model Save selected!
2019-01-18 14:39:52,685 Loaded Graph data/edges/parsing/ewt/ewt_dev/1795.edges with 4 nodes scale=1.0
2019-01-18 14:39:52,685 Building dataset
2019-01-18 14:39:52,686 Subsample: 4 points with scale 1.0 subsample=3
2019-01-18 14:39:52,689 Built Data Sampler
2019-01-18 14:39:52,689 Creating a fresh model warm_start?=None
2019-01-18 14:39:52,689 	 Warmstarting? None None 4
2019-01-18 14:39:52,689 Embedding() torch.Size([4, 10])
2019-01-18 14:39:52,689 relative No Rescale
2019-01-18 14:39:52,690 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:52,690 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:52,690 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:52,690 	 Computing Major Stats lazily... 
2019-01-18 14:39:52,691 		 Completed edges=12 good=12 bad=0
2019-01-18 14:39:52,691 Distortion avg=0.9966404299181114 wc=3.2869580912217393 me=0.005628252251848828 mc=584.0104430539702 nan_elements=0
2019-01-18 14:39:52,692 MAP = 0.5
2019-01-18 14:39:52,692 scale=[array([1.])]
2019-01-18 14:39:52,692 *** End Initial Checkpoint

2019-01-18 14:39:52,750 1 loss=0.9932946490341571
2019-01-18 14:39:52,751 2 loss=0.2407395144924753
2019-01-18 14:39:52,751 3 loss=0.1294833284649695
2019-01-18 14:39:52,751 4 loss=0.07888125022286527
2019-01-18 14:39:52,752 5 loss=0.05111446373423253
2019-01-18 14:39:52,752 6 loss=0.035110241552562343
2019-01-18 14:39:52,753 7 loss=0.02553088144826274
2019-01-18 14:39:52,753 8 loss=0.01952698322341952
2019-01-18 14:39:52,754 9 loss=0.015603051035423412
2019-01-18 14:39:52,754 10 loss=0.01294279876686467
2019-01-18 14:39:52,755 11 loss=0.011080267580807442
2019-01-18 14:39:52,755 12 loss=0.009739192030568788
2019-01-18 14:39:52,755 13 loss=0.008750077509507341
2019-01-18 14:39:52,756 14 loss=0.008005510421100225
2019-01-18 14:39:52,756 15 loss=0.00743530225563032
2019-01-18 14:39:52,757 16 loss=0.006992263995116508
2019-01-18 14:39:52,757 17 loss=0.006643831475188717
2019-01-18 14:39:52,758 18 loss=0.006366996279128556
2019-01-18 14:39:52,758 19 loss=0.0061451537737712515
2019-01-18 14:39:52,758 20 loss=0.005966092316536989
2019-01-18 14:39:52,759 21 loss=0.00582067911886724
2019-01-18 14:39:52,759 22 loss=0.005701981819181498
2019-01-18 14:39:52,760 23 loss=0.005604668880595393
2019-01-18 14:39:52,760 24 loss=0.005524592303003056
2019-01-18 14:39:52,761 25 loss=0.005458491969625524
2019-01-18 14:39:52,761 26 loss=0.0054037826825149285
2019-01-18 14:39:52,761 27 loss=0.00535839840338033
2019-01-18 14:39:52,762 28 loss=0.0053206767205548665
2019-01-18 14:39:52,762 29 loss=0.005289272036446989
2019-01-18 14:39:52,763 30 loss=0.005263089554618169
2019-01-18 14:39:52,763 31 loss=0.005241234532094112
2019-01-18 14:39:52,764 32 loss=0.005222972875700671
2019-01-18 14:39:52,764 33 loss=0.005207700267418497
2019-01-18 14:39:52,764 34 loss=0.005194917772591086
2019-01-18 14:39:52,765 35 loss=0.0051842124260252365
2019-01-18 14:39:52,765 36 loss=0.005175241676609974
2019-01-18 14:39:52,766 37 loss=0.005167720848972987
2019-01-18 14:39:52,766 38 loss=0.005161412983185449
2019-01-18 14:39:52,766 39 loss=0.005156120562642375
2019-01-18 14:39:52,767 40 loss=0.00515167875117728
2019-01-18 14:39:52,767 41 loss=0.005147949843805555
2019-01-18 14:39:52,768 42 loss=0.005144818698686664
2019-01-18 14:39:52,768 43 loss=0.005142188966251414
2019-01-18 14:39:52,769 44 loss=0.005139979968761199
2019-01-18 14:39:52,769 45 loss=0.005138124112604783
2019-01-18 14:39:52,769 46 loss=0.005136564738407268
2019-01-18 14:39:52,770 47 loss=0.005135254332007701
2019-01-18 14:39:52,770 48 loss=0.005134153033657964
2019-01-18 14:39:52,771 49 loss=0.0051332273942311475
2019-01-18 14:39:52,771 50 loss=0.0051324493364284995
2019-01-18 14:39:52,771 final loss=0.0051324493364284995
2019-01-18 14:39:52,771 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:52,771 	 Computing Major Stats lazily... 
2019-01-18 14:39:52,772 		 Completed edges=12 good=12 bad=0
2019-01-18 14:39:52,772 Distortion avg=0.07145200514321905 wc=1.1548810574391133 me=1.066326818975048 mc=1.083046057632859 nan_elements=0
2019-01-18 14:39:52,772 MAP = 1.0
2019-01-18 14:39:52,773 scale=[array([1.])]
2019-01-18 15:20:43,449 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1795.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1795.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:20:43,450 No Model Save selected!
