2019-01-18 14:41:02,180 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/492.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/492.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:02,180 No Model Save selected!
2019-01-18 14:41:02,181 Loaded Graph data/edges/parsing/ewt/ewt_dev/492.edges with 9 nodes scale=1.0
2019-01-18 14:41:02,181 Building dataset
2019-01-18 14:41:02,182 Subsample: 9 points with scale 1.0 subsample=8
2019-01-18 14:41:02,189 Built Data Sampler
2019-01-18 14:41:02,189 Creating a fresh model warm_start?=None
2019-01-18 14:41:02,189 	 Warmstarting? None None 9
2019-01-18 14:41:02,189 Embedding() torch.Size([9, 10])
2019-01-18 14:41:02,189 relative No Rescale
2019-01-18 14:41:02,190 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:02,190 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:02,190 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:02,190 	 Computing Major Stats lazily... 
2019-01-18 14:41:02,191 		 Completed edges=72 good=72 bad=0
2019-01-18 14:41:02,193 Distortion avg=0.9972861051061792 wc=5.751184174970984 me=0.005941110731069004 mc=968.0318100949036 nan_elements=0
2019-01-18 14:41:02,193 MAP = 0.29892290249433107
2019-01-18 14:41:02,193 scale=[array([1.])]
2019-01-18 14:41:02,193 *** End Initial Checkpoint

2019-01-18 14:41:02,251 1 loss=0.9945812705088143
2019-01-18 14:41:02,252 2 loss=0.6775053587443886
2019-01-18 14:41:02,252 3 loss=0.5004026013621928
2019-01-18 14:41:02,253 4 loss=0.3962454479576627
2019-01-18 14:41:02,253 5 loss=0.3268287587326612
2019-01-18 14:41:02,254 6 loss=0.27645123962995866
2019-01-18 14:41:02,254 7 loss=0.23800382587654972
2019-01-18 14:41:02,255 8 loss=0.20779284976286982
2019-01-18 14:41:02,255 9 loss=0.1836343687369496
2019-01-18 14:41:02,256 10 loss=0.1640991928384222
2019-01-18 14:41:02,256 11 loss=0.1481811850064396
2019-01-18 14:41:02,257 12 loss=0.13513471203602476
2019-01-18 14:41:02,257 13 loss=0.12438686051367608
2019-01-18 14:41:02,258 14 loss=0.11548617038131909
2019-01-18 14:41:02,258 15 loss=0.10807077106798434
2019-01-18 14:41:02,259 16 loss=0.1018474979914536
2019-01-18 14:41:02,259 17 loss=0.09657751189802749
2019-01-18 14:41:02,260 18 loss=0.09206590889400873
2019-01-18 14:41:02,260 19 loss=0.08815386534821637
2019-01-18 14:41:02,261 20 loss=0.08471245943151073
2019-01-18 14:41:02,262 21 loss=0.0816376581655774
2019-01-18 14:41:02,262 22 loss=0.07884616149877802
2019-01-18 14:41:02,263 23 loss=0.0762719119419523
2019-01-18 14:41:02,263 24 loss=0.07386314450409649
2019-01-18 14:41:02,264 25 loss=0.07157988841585562
2019-01-18 14:41:02,264 26 loss=0.06939185255497954
2019-01-18 14:41:02,265 27 loss=0.06727663846696226
2019-01-18 14:41:02,265 28 loss=0.0652182328693701
2019-01-18 14:41:02,266 29 loss=0.0632057378455355
2019-01-18 14:41:02,266 30 loss=0.061232302588209726
2019-01-18 14:41:02,267 31 loss=0.05929422585948431
2019-01-18 14:41:02,267 32 loss=0.057390203275043884
2019-01-18 14:41:02,268 33 loss=0.05552069797600539
2019-01-18 14:41:02,268 34 loss=0.053687417103573803
2019-01-18 14:41:02,269 35 loss=0.05189287967688441
2019-01-18 14:41:02,269 36 loss=0.050140063991611174
2019-01-18 14:41:02,270 37 loss=0.048432124558675446
2019-01-18 14:41:02,270 38 loss=0.04677216997874098
2019-01-18 14:41:02,271 39 loss=0.045163094109687704
2019-01-18 14:41:02,271 40 loss=0.04360745354670282
2019-01-18 14:41:02,272 41 loss=0.042107384906707
2019-01-18 14:41:02,272 42 loss=0.04066455578334278
2019-01-18 14:41:02,273 43 loss=0.039280143587296396
2019-01-18 14:41:02,273 44 loss=0.037954836857818315
2019-01-18 14:41:02,274 45 loss=0.03668885405132027
2019-01-18 14:41:02,274 46 loss=0.03548197528921556
2019-01-18 14:41:02,275 47 loss=0.03433358307254063
2019-01-18 14:41:02,275 48 loss=0.03324270852856937
2019-01-18 14:41:02,276 49 loss=0.03220808032299911
2019-01-18 14:41:02,276 50 loss=0.03122817392794899
2019-01-18 14:41:02,276 final loss=0.03122817392794899
2019-01-18 14:41:02,276 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:02,276 	 Computing Major Stats lazily... 
2019-01-18 14:41:02,277 		 Completed edges=72 good=72 bad=0
2019-01-18 14:41:02,278 Distortion avg=0.15103568115365337 wc=1.8894999210139798 me=1.2569137334086886 mc=1.503285285848336 nan_elements=0
2019-01-18 14:41:02,278 MAP = 1.0
2019-01-18 14:41:02,279 scale=[array([1.])]
2019-01-18 15:15:25,414 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/492.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/492.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:15:25,415 No Model Save selected!
