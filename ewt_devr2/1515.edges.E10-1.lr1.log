2019-01-18 14:39:29,460 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1515.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1515.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:29,460 No Model Save selected!
2019-01-18 14:39:29,462 Loaded Graph data/edges/parsing/ewt/ewt_dev/1515.edges with 4 nodes scale=1.0
2019-01-18 14:39:29,462 Building dataset
2019-01-18 14:39:29,462 Subsample: 4 points with scale 1.0 subsample=3
2019-01-18 14:39:29,465 Built Data Sampler
2019-01-18 14:39:29,465 Creating a fresh model warm_start?=None
2019-01-18 14:39:29,465 	 Warmstarting? None None 4
2019-01-18 14:39:29,466 Embedding() torch.Size([4, 10])
2019-01-18 14:39:29,466 relative No Rescale
2019-01-18 14:39:29,466 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:29,466 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:29,467 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:29,467 	 Computing Major Stats lazily... 
2019-01-18 14:39:29,467 		 Completed edges=12 good=12 bad=0
2019-01-18 14:39:29,468 Distortion avg=0.9966404299181114 wc=3.2869580912217393 me=0.005628252251848828 mc=584.0104430539702 nan_elements=0
2019-01-18 14:39:29,468 MAP = 0.5
2019-01-18 14:39:29,468 scale=[array([1.])]
2019-01-18 14:39:29,469 *** End Initial Checkpoint

2019-01-18 14:39:29,526 1 loss=0.9932946490341571
2019-01-18 14:39:29,526 2 loss=0.2407395144924753
2019-01-18 14:39:29,527 3 loss=0.1294833284649695
2019-01-18 14:39:29,527 4 loss=0.07888125022286527
2019-01-18 14:39:29,528 5 loss=0.05111446373423253
2019-01-18 14:39:29,528 6 loss=0.035110241552562343
2019-01-18 14:39:29,529 7 loss=0.02553088144826274
2019-01-18 14:39:29,529 8 loss=0.01952698322341952
2019-01-18 14:39:29,529 9 loss=0.015603051035423412
2019-01-18 14:39:29,530 10 loss=0.01294279876686467
2019-01-18 14:39:29,530 11 loss=0.011080267580807442
2019-01-18 14:39:29,531 12 loss=0.009739192030568788
2019-01-18 14:39:29,532 13 loss=0.008750077509507341
2019-01-18 14:39:29,532 14 loss=0.008005510421100225
2019-01-18 14:39:29,532 15 loss=0.00743530225563032
2019-01-18 14:39:29,533 16 loss=0.006992263995116508
2019-01-18 14:39:29,533 17 loss=0.006643831475188717
2019-01-18 14:39:29,534 18 loss=0.006366996279128556
2019-01-18 14:39:29,534 19 loss=0.0061451537737712515
2019-01-18 14:39:29,535 20 loss=0.005966092316536989
2019-01-18 14:39:29,535 21 loss=0.00582067911886724
2019-01-18 14:39:29,535 22 loss=0.005701981819181498
2019-01-18 14:39:29,536 23 loss=0.005604668880595393
2019-01-18 14:39:29,536 24 loss=0.005524592303003056
2019-01-18 14:39:29,537 25 loss=0.005458491969625524
2019-01-18 14:39:29,537 26 loss=0.0054037826825149285
2019-01-18 14:39:29,537 27 loss=0.00535839840338033
2019-01-18 14:39:29,538 28 loss=0.0053206767205548665
2019-01-18 14:39:29,538 29 loss=0.005289272036446989
2019-01-18 14:39:29,539 30 loss=0.005263089554618169
2019-01-18 14:39:29,539 31 loss=0.005241234532094112
2019-01-18 14:39:29,540 32 loss=0.005222972875700671
2019-01-18 14:39:29,540 33 loss=0.005207700267418497
2019-01-18 14:39:29,540 34 loss=0.005194917772591086
2019-01-18 14:39:29,541 35 loss=0.0051842124260252365
2019-01-18 14:39:29,541 36 loss=0.005175241676609974
2019-01-18 14:39:29,542 37 loss=0.005167720848972987
2019-01-18 14:39:29,542 38 loss=0.005161412983185449
2019-01-18 14:39:29,543 39 loss=0.005156120562642375
2019-01-18 14:39:29,543 40 loss=0.00515167875117728
2019-01-18 14:39:29,543 41 loss=0.005147949843805555
2019-01-18 14:39:29,544 42 loss=0.005144818698686664
2019-01-18 14:39:29,544 43 loss=0.005142188966251414
2019-01-18 14:39:29,545 44 loss=0.005139979968761199
2019-01-18 14:39:29,545 45 loss=0.005138124112604783
2019-01-18 14:39:29,546 46 loss=0.005136564738407268
2019-01-18 14:39:29,546 47 loss=0.005135254332007701
2019-01-18 14:39:29,546 48 loss=0.005134153033657964
2019-01-18 14:39:29,547 49 loss=0.0051332273942311475
2019-01-18 14:39:29,547 50 loss=0.0051324493364284995
2019-01-18 14:39:29,547 final loss=0.0051324493364284995
2019-01-18 14:39:29,547 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:29,547 	 Computing Major Stats lazily... 
2019-01-18 14:39:29,548 		 Completed edges=12 good=12 bad=0
2019-01-18 14:39:29,548 Distortion avg=0.07145200514321905 wc=1.1548810574391133 me=1.066326818975048 mc=1.083046057632859 nan_elements=0
2019-01-18 14:39:29,549 MAP = 1.0
2019-01-18 14:39:29,549 scale=[array([1.])]
2019-01-18 15:18:13,101 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1515.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1515.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:18:13,102 No Model Save selected!
