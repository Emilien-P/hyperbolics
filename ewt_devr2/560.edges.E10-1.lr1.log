2019-01-18 14:40:54,582 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/560.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/560.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:54,582 No Model Save selected!
2019-01-18 14:40:54,583 Loaded Graph data/edges/parsing/ewt/ewt_dev/560.edges with 7 nodes scale=1.0
2019-01-18 14:40:54,584 Building dataset
2019-01-18 14:40:54,584 Subsample: 7 points with scale 1.0 subsample=6
2019-01-18 14:40:54,590 Built Data Sampler
2019-01-18 14:40:54,591 Creating a fresh model warm_start?=None
2019-01-18 14:40:54,591 	 Warmstarting? None None 7
2019-01-18 14:40:54,591 Embedding() torch.Size([7, 10])
2019-01-18 14:40:54,592 relative No Rescale
2019-01-18 14:40:54,592 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:54,592 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:54,592 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:54,593 	 Computing Major Stats lazily... 
2019-01-18 14:40:54,593 		 Completed edges=42 good=42 bad=0
2019-01-18 14:40:54,594 Distortion avg=0.9970489094787228 wc=3.6322181433519583 me=0.005628252251848828 mc=645.354540063269 nan_elements=0
2019-01-18 14:40:54,595 MAP = 0.40238095238095234
2019-01-18 14:40:54,595 scale=[array([1.])]
2019-01-18 14:40:54,595 *** End Initial Checkpoint

2019-01-18 14:40:54,652 1 loss=0.9941078772780602
2019-01-18 14:40:54,653 2 loss=0.5251690814386136
2019-01-18 14:40:54,653 3 loss=0.34213099601809954
2019-01-18 14:40:54,654 4 loss=0.2477888702865334
2019-01-18 14:40:54,654 5 loss=0.18589309383948707
2019-01-18 14:40:54,655 6 loss=0.14203962504043957
2019-01-18 14:40:54,655 7 loss=0.11022219342171273
2019-01-18 14:40:54,656 8 loss=0.08692484908889381
2019-01-18 14:40:54,656 9 loss=0.06977937285692801
2019-01-18 14:40:54,656 10 loss=0.05710739423291392
2019-01-18 14:40:54,657 11 loss=0.047697645522898895
2019-01-18 14:40:54,657 12 loss=0.040671038214256786
2019-01-18 14:40:54,658 13 loss=0.03538904563968523
2019-01-18 14:40:54,658 14 loss=0.03138812325237591
2019-01-18 14:40:54,659 15 loss=0.028331837741132487
2019-01-18 14:40:54,659 16 loss=0.025975812004014776
2019-01-18 14:40:54,660 17 loss=0.024142154305623935
2019-01-18 14:40:54,660 18 loss=0.022700916552407965
2019-01-18 14:40:54,661 19 loss=0.02155672440582341
2019-01-18 14:40:54,661 20 loss=0.020639176284470144
2019-01-18 14:40:54,662 21 loss=0.01989596445113345
2019-01-18 14:40:54,662 22 loss=0.019287948382086355
2019-01-18 14:40:54,663 23 loss=0.018785621685618023
2019-01-18 14:40:54,663 24 loss=0.018366571227815542
2019-01-18 14:40:54,664 25 loss=0.018013642326416817
2019-01-18 14:40:54,664 26 loss=0.0177136069807312
2019-01-18 14:40:54,665 27 loss=0.01745619142674806
2019-01-18 14:40:54,665 28 loss=0.017233361345499264
2019-01-18 14:40:54,665 29 loss=0.017038792713741785
2019-01-18 14:40:54,666 30 loss=0.016867477169136693
2019-01-18 14:40:54,666 31 loss=0.01671542546035194
2019-01-18 14:40:54,667 32 loss=0.0165794429092897
2019-01-18 14:40:54,667 33 loss=0.016456958127032944
2019-01-18 14:40:54,668 34 loss=0.016345891407667373
2019-01-18 14:40:54,668 35 loss=0.016244552911165448
2019-01-18 14:40:54,669 36 loss=0.016151563382145358
2019-01-18 14:40:54,669 37 loss=0.01606579204558435
2019-01-18 14:40:54,670 38 loss=0.01598630769017776
2019-01-18 14:40:54,670 39 loss=0.015912339946759724
2019-01-18 14:40:54,670 40 loss=0.015843248499609944
2019-01-18 14:40:54,671 41 loss=0.015778498507643193
2019-01-18 14:40:54,671 42 loss=0.01571764091350327
2019-01-18 14:40:54,672 43 loss=0.015660296619165966
2019-01-18 14:40:54,672 44 loss=0.015606143733701222
2019-01-18 14:40:54,673 45 loss=0.015554907271657755
2019-01-18 14:40:54,673 46 loss=0.01550635081304431
2019-01-18 14:40:54,674 47 loss=0.0154602697382104
2019-01-18 14:40:54,674 48 loss=0.015416485730477521
2019-01-18 14:40:54,675 49 loss=0.015374842301590511
2019-01-18 14:40:54,675 50 loss=0.015335201143999378
2019-01-18 14:40:54,675 final loss=0.015335201143999378
2019-01-18 14:40:54,675 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:54,675 	 Computing Major Stats lazily... 
2019-01-18 14:40:54,676 		 Completed edges=42 good=42 bad=0
2019-01-18 14:40:54,677 Distortion avg=0.11485255481940891 wc=1.3580271314241557 me=1.1742586265407156 mc=1.1564974705996491 nan_elements=0
2019-01-18 14:40:54,677 MAP = 1.0
2019-01-18 14:40:54,677 scale=[array([1.])]
2019-01-18 15:21:59,243 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/560.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/560.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:21:59,244 No Model Save selected!
