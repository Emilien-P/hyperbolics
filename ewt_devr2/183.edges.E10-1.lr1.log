2019-01-18 14:42:10,688 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/183.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/183.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:10,688 No Model Save selected!
2019-01-18 14:42:10,690 Loaded Graph data/edges/parsing/ewt/ewt_dev/183.edges with 13 nodes scale=1.0
2019-01-18 14:42:10,690 Building dataset
2019-01-18 14:42:10,691 Subsample: 13 points with scale 1.0 subsample=12
2019-01-18 14:42:10,704 Built Data Sampler
2019-01-18 14:42:10,704 Creating a fresh model warm_start?=None
2019-01-18 14:42:10,704 	 Warmstarting? None None 13
2019-01-18 14:42:10,705 Embedding() torch.Size([13, 10])
2019-01-18 14:42:10,705 relative No Rescale
2019-01-18 14:42:10,705 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:10,705 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:10,706 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:10,706 	 Computing Major Stats lazily... 
2019-01-18 14:42:10,707 		 Completed edges=156 good=156 bad=0
2019-01-18 14:42:10,709 Distortion avg=0.9980364104454537 wc=9.483945900690545 me=0.005982886981094694 mc=1585.1788493847262 nan_elements=0
2019-01-18 14:42:10,709 MAP = 0.2720668220668221
2019-01-18 14:42:10,709 scale=[array([1.])]
2019-01-18 14:42:10,709 *** End Initial Checkpoint

2019-01-18 14:42:10,767 1 loss=0.9960782833476435
2019-01-18 14:42:10,767 2 loss=0.8630477223900903
2019-01-18 14:42:10,768 3 loss=0.7547417501230076
2019-01-18 14:42:10,768 4 loss=0.670213138618825
2019-01-18 14:42:10,769 5 loss=0.6040691800668833
2019-01-18 14:42:10,770 6 loss=0.5518252826966864
2019-01-18 14:42:10,770 7 loss=0.5100640298533999
2019-01-18 14:42:10,771 8 loss=0.4762351212848274
2019-01-18 14:42:10,771 9 loss=0.4484455118183901
2019-01-18 14:42:10,772 10 loss=0.42528934260859186
2019-01-18 14:42:10,772 11 loss=0.40571906607632147
2019-01-18 14:42:10,773 12 loss=0.38895019540670805
2019-01-18 14:42:10,773 13 loss=0.37439162051144415
2019-01-18 14:42:10,774 14 loss=0.3615948133656441
2019-01-18 14:42:10,775 15 loss=0.3502168114584201
2019-01-18 14:42:10,775 16 loss=0.3399931962898044
2019-01-18 14:42:10,776 17 loss=0.3307183113076782
2019-01-18 14:42:10,776 18 loss=0.3222307272380555
2019-01-18 14:42:10,777 19 loss=0.31440251905795247
2019-01-18 14:42:10,778 20 loss=0.3071313200746862
2019-01-18 14:42:10,778 21 loss=0.3003344065669421
2019-01-18 14:42:10,779 22 loss=0.2939442728524064
2019-01-18 14:42:10,779 23 loss=0.2879053046774148
2019-01-18 14:42:10,780 24 loss=0.2821712652077309
2019-01-18 14:42:10,780 25 loss=0.276703384587973
2019-01-18 14:42:10,781 26 loss=0.2714688995251917
2019-01-18 14:42:10,782 27 loss=0.2664399296656898
2019-01-18 14:42:10,782 28 loss=0.2615926069487126
2019-01-18 14:42:10,783 29 loss=0.2569063956749256
2019-01-18 14:42:10,783 30 loss=0.2523635568878679
2019-01-18 14:42:10,784 31 loss=0.24794872238312168
2019-01-18 14:42:10,784 32 loss=0.24364855234712948
2019-01-18 14:42:10,785 33 loss=0.2394514570903946
2019-01-18 14:42:10,786 34 loss=0.23534736816247054
2019-01-18 14:42:10,786 35 loss=0.2313275477448694
2019-01-18 14:42:10,787 36 loss=0.2273844279251031
2019-01-18 14:42:10,787 37 loss=0.22351147349028713
2019-01-18 14:42:10,788 38 loss=0.21970306341186904
2019-01-18 14:42:10,788 39 loss=0.21595438734990374
2019-01-18 14:42:10,789 40 loss=0.21226135437941615
2019-01-18 14:42:10,790 41 loss=0.20862051180250524
2019-01-18 14:42:10,790 42 loss=0.20502897241006268
2019-01-18 14:42:10,791 43 loss=0.20148434893534287
2019-01-18 14:42:10,791 44 loss=0.19798469472749677
2019-01-18 14:42:10,792 45 loss=0.19452844988867496
2019-01-18 14:42:10,792 46 loss=0.19111439228018093
2019-01-18 14:42:10,793 47 loss=0.1877415929241357
2019-01-18 14:42:10,793 48 loss=0.18440937541693847
2019-01-18 14:42:10,794 49 loss=0.181117279036933
2019-01-18 14:42:10,795 50 loss=0.17786502527689452
2019-01-18 14:42:10,795 final loss=0.17786502527689452
2019-01-18 14:42:10,795 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:10,795 	 Computing Major Stats lazily... 
2019-01-18 14:42:10,796 		 Completed edges=156 good=156 bad=0
2019-01-18 14:42:10,798 Distortion avg=0.37831624283197246 wc=5.639748573876271 me=1.6561693695787352 mc=3.4052969928497125 nan_elements=0
2019-01-18 14:42:10,798 MAP = 0.71001221001221
2019-01-18 14:42:10,798 scale=[array([1.])]
2019-01-18 15:22:55,442 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/183.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/183.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:22:55,443 No Model Save selected!
