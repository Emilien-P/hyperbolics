2019-01-18 14:39:40,443 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/353.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/353.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:40,443 No Model Save selected!
2019-01-18 14:39:40,445 Loaded Graph data/edges/parsing/ewt/ewt_dev/353.edges with 12 nodes scale=1.0
2019-01-18 14:39:40,445 Building dataset
2019-01-18 14:39:40,445 Subsample: 12 points with scale 1.0 subsample=11
2019-01-18 14:39:40,456 Built Data Sampler
2019-01-18 14:39:40,456 Creating a fresh model warm_start?=None
2019-01-18 14:39:40,456 	 Warmstarting? None None 12
2019-01-18 14:39:40,456 Embedding() torch.Size([12, 10])
2019-01-18 14:39:40,457 relative No Rescale
2019-01-18 14:39:40,457 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:40,457 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:40,457 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:40,457 	 Computing Major Stats lazily... 
2019-01-18 14:39:40,458 		 Completed edges=132 good=132 bad=0
2019-01-18 14:39:40,460 Distortion avg=0.9978447401553658 wc=8.04618509307902 me=0.005941110731069004 mc=1354.323367683006 nan_elements=0
2019-01-18 14:39:40,460 MAP = 0.28717231842231844
2019-01-18 14:39:40,461 scale=[array([1.])]
2019-01-18 14:39:40,461 *** End Initial Checkpoint

2019-01-18 14:39:40,519 1 loss=0.995695620835794
2019-01-18 14:39:40,519 2 loss=0.8213145288256677
2019-01-18 14:39:40,520 3 loss=0.6897046233328635
2019-01-18 14:39:40,520 4 loss=0.59332358566441
2019-01-18 14:39:40,521 5 loss=0.521264491283723
2019-01-18 14:39:40,522 6 loss=0.4659493288692323
2019-01-18 14:39:40,522 7 loss=0.42234316598192045
2019-01-18 14:39:40,523 8 loss=0.3871075981911464
2019-01-18 14:39:40,523 9 loss=0.35800722103166466
2019-01-18 14:39:40,524 10 loss=0.3335217374631231
2019-01-18 14:39:40,524 11 loss=0.31259718416338583
2019-01-18 14:39:40,525 12 loss=0.29448686280801584
2019-01-18 14:39:40,525 13 loss=0.27864923855436957
2019-01-18 14:39:40,526 14 loss=0.2646819097053324
2019-01-18 14:39:40,527 15 loss=0.2522784855903327
2019-01-18 14:39:40,527 16 loss=0.24120010462471952
2019-01-18 14:39:40,528 17 loss=0.2312563860095211
2019-01-18 14:39:40,528 18 loss=0.2222925177012314
2019-01-18 14:39:40,529 19 loss=0.21418037636033233
2019-01-18 14:39:40,529 20 loss=0.20681232449403147
2019-01-18 14:39:40,530 21 loss=0.2000968043083514
2019-01-18 14:39:40,530 22 loss=0.19395515052330614
2019-01-18 14:39:40,531 23 loss=0.18831923945233778
2019-01-18 14:39:40,532 24 loss=0.18312971852598312
2019-01-18 14:39:40,532 25 loss=0.17833464376364222
2019-01-18 14:39:40,533 26 loss=0.1738884079188473
2019-01-18 14:39:40,533 27 loss=0.16975087893291424
2019-01-18 14:39:40,534 28 loss=0.16588669319351718
2019-01-18 14:39:40,534 29 loss=0.16226466495736372
2019-01-18 14:39:40,535 30 loss=0.15885728480309194
2019-01-18 14:39:40,535 31 loss=0.15564028787431708
2019-01-18 14:39:40,536 32 loss=0.15259227811266204
2019-01-18 14:39:40,537 33 loss=0.14969439844433502
2019-01-18 14:39:40,537 34 loss=0.1469300394971266
2019-01-18 14:39:40,538 35 loss=0.14428458124547208
2019-01-18 14:39:40,538 36 loss=0.14174516325456835
2019-01-18 14:39:40,539 37 loss=0.13930048008926035
2019-01-18 14:39:40,539 38 loss=0.1369405990862866
2019-01-18 14:39:40,540 39 loss=0.13465679814063217
2019-01-18 14:39:40,540 40 loss=0.13244142148465637
2019-01-18 14:39:40,541 41 loss=0.13028775168171994
2019-01-18 14:39:40,542 42 loss=0.1281898962416565
2019-01-18 14:39:40,542 43 loss=0.12614268741260423
2019-01-18 14:39:40,543 44 loss=0.12414159382549574
2019-01-18 14:39:40,543 45 loss=0.12218264277273001
2019-01-18 14:39:40,544 46 loss=0.12026235199704972
2019-01-18 14:39:40,544 47 loss=0.11837766995415847
2019-01-18 14:39:40,545 48 loss=0.1165259235953632
2019-01-18 14:39:40,545 49 loss=0.11470477279574805
2019-01-18 14:39:40,546 50 loss=0.11291217062962322
2019-01-18 14:39:40,546 final loss=0.11291217062962322
2019-01-18 14:39:40,546 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:40,546 	 Computing Major Stats lazily... 
2019-01-18 14:39:40,547 		 Completed edges=132 good=132 bad=0
2019-01-18 14:39:40,549 Distortion avg=0.2923777153281653 wc=3.8508055536456793 me=1.516836861679102 mc=2.5387077878519713 nan_elements=0
2019-01-18 14:39:40,549 MAP = 0.8852843915343915
2019-01-18 14:39:40,549 scale=[array([1.])]
2019-01-18 15:23:01,102 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/353.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/353.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:23:01,103 No Model Save selected!
