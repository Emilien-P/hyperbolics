2019-01-18 14:40:07,714 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/511.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/511.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:07,714 No Model Save selected!
2019-01-18 14:40:07,716 Loaded Graph data/edges/parsing/ewt/ewt_dev/511.edges with 25 nodes scale=1.0
2019-01-18 14:40:07,716 Building dataset
2019-01-18 14:40:07,716 Subsample: 25 points with scale 1.0 subsample=24
2019-01-18 14:40:07,745 Built Data Sampler
2019-01-18 14:40:07,746 Creating a fresh model warm_start?=None
2019-01-18 14:40:07,746 	 Warmstarting? None None 25
2019-01-18 14:40:07,746 Embedding() torch.Size([25, 10])
2019-01-18 14:40:07,746 relative No Rescale
2019-01-18 14:40:07,746 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:07,747 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:07,747 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:07,747 	 Computing Major Stats lazily... 
2019-01-18 14:40:07,750 		 Completed edges=600 good=600 bad=0
2019-01-18 14:40:07,754 Distortion avg=0.998457498468614 wc=21.05756832894903 me=0.006841983940850235 mc=3077.6991748291452 nan_elements=0
2019-01-18 14:40:07,754 MAP = 0.17522205601739863
2019-01-18 14:40:07,754 scale=[array([1.])]
2019-01-18 14:40:07,754 *** End Initial Checkpoint

2019-01-18 14:40:07,812 1 loss=0.9969185275043803
2019-01-18 14:40:07,814 2 loss=0.9546852204156167
2019-01-18 14:40:07,815 3 loss=0.9142625664579881
2019-01-18 14:40:07,815 4 loss=0.8766997404656646
2019-01-18 14:40:07,816 5 loss=0.8419248176963511
2019-01-18 14:40:07,817 6 loss=0.8097516935376606
2019-01-18 14:40:07,818 7 loss=0.7799769670145127
2019-01-18 14:40:07,819 8 loss=0.7524022325106036
2019-01-18 14:40:07,820 9 loss=0.7268409386325871
2019-01-18 14:40:07,821 10 loss=0.7031204671406709
2019-01-18 14:40:07,822 11 loss=0.6810823941018288
2019-01-18 14:40:07,822 12 loss=0.660581987826237
2019-01-18 14:40:07,823 13 loss=0.641487382261852
2019-01-18 14:40:07,824 14 loss=0.6236786276368927
2019-01-18 14:40:07,825 15 loss=0.6070467170154893
2019-01-18 14:40:07,826 16 loss=0.5914926382984926
2019-01-18 14:40:07,827 17 loss=0.5769264761989498
2019-01-18 14:40:07,828 18 loss=0.5632665753948777
2019-01-18 14:40:07,829 19 loss=0.550438768748803
2019-01-18 14:40:07,829 20 loss=0.5383756704241137
2019-01-18 14:40:07,831 21 loss=0.5270160314976232
2019-01-18 14:40:07,832 22 loss=0.516304154494195
2019-01-18 14:40:07,833 23 loss=0.5061893627182593
2019-01-18 14:40:07,834 24 loss=0.49662552007559013
2019-01-18 14:40:07,835 25 loss=0.48757059711586104
2019-01-18 14:40:07,836 26 loss=0.4789862791902028
2019-01-18 14:40:07,837 27 loss=0.4708376128514023
2019-01-18 14:40:07,838 28 loss=0.4630926868920833
2019-01-18 14:40:07,839 29 loss=0.4557223446961539
2019-01-18 14:40:07,839 30 loss=0.44869992485732163
2019-01-18 14:40:07,840 31 loss=0.44200102728740215
2019-01-18 14:40:07,841 32 loss=0.43560330229166366
2019-01-18 14:40:07,842 33 loss=0.42948626032613446
2019-01-18 14:40:07,843 34 loss=0.42363110037157414
2019-01-18 14:40:07,844 35 loss=0.41802055506057534
2019-01-18 14:40:07,845 36 loss=0.41263875087852286
2019-01-18 14:40:07,846 37 loss=0.4074710819266757
2019-01-18 14:40:07,846 38 loss=0.4025040958875205
2019-01-18 14:40:07,848 39 loss=0.39772539096986564
2019-01-18 14:40:07,848 40 loss=0.3931235227350776
2019-01-18 14:40:07,850 41 loss=0.38868791981750095
2019-01-18 14:40:07,851 42 loss=0.3844088076525953
2019-01-18 14:40:07,852 43 loss=0.380277139416635
2019-01-18 14:40:07,853 44 loss=0.3762845334629756
2019-01-18 14:40:07,854 45 loss=0.3724232166127286
2019-01-18 14:40:07,855 46 loss=0.36868597272307363
2019-01-18 14:40:07,855 47 loss=0.3650660960150777
2019-01-18 14:40:07,856 48 loss=0.36155734869550155
2019-01-18 14:40:07,857 49 loss=0.35815392245423944
2019-01-18 14:40:07,858 50 loss=0.3548504034613485
2019-01-18 14:40:07,858 final loss=0.3548504034613485
2019-01-18 14:40:07,858 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:07,858 	 Computing Major Stats lazily... 
2019-01-18 14:40:07,861 		 Completed edges=600 good=600 bad=0
2019-01-18 14:40:07,864 Distortion avg=0.5569999619072813 wc=14.485164247879007 me=1.8176698607445865 mc=7.96908424390408 nan_elements=0
2019-01-18 14:40:07,864 MAP = 0.12168977949407346
2019-01-18 14:40:07,865 scale=[array([1.])]
2019-01-18 15:22:10,784 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/511.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/511.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:22:10,786 No Model Save selected!
