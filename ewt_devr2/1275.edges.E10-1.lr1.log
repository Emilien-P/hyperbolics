2019-01-18 14:42:19,319 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1275.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1275.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:19,319 No Model Save selected!
2019-01-18 14:42:19,320 Loaded Graph data/edges/parsing/ewt/ewt_dev/1275.edges with 7 nodes scale=1.0
2019-01-18 14:42:19,321 Building dataset
2019-01-18 14:42:19,321 Subsample: 7 points with scale 1.0 subsample=6
2019-01-18 14:42:19,326 Built Data Sampler
2019-01-18 14:42:19,327 Creating a fresh model warm_start?=None
2019-01-18 14:42:19,327 	 Warmstarting? None None 7
2019-01-18 14:42:19,327 Embedding() torch.Size([7, 10])
2019-01-18 14:42:19,327 relative No Rescale
2019-01-18 14:42:19,328 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:19,328 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:19,328 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:19,328 	 Computing Major Stats lazily... 
2019-01-18 14:42:19,329 		 Completed edges=42 good=42 bad=0
2019-01-18 14:42:19,330 Distortion avg=0.9971782235459303 wc=4.6630950159583 me=0.005628252251848828 mc=828.5156398998494 nan_elements=0
2019-01-18 14:42:19,330 MAP = 0.4228571428571429
2019-01-18 14:42:19,331 scale=[array([1.])]
2019-01-18 14:42:19,331 *** End Initial Checkpoint

2019-01-18 14:42:19,388 1 loss=0.9943660797040026
2019-01-18 14:42:19,388 2 loss=0.5605746890344596
2019-01-18 14:42:19,389 3 loss=0.38083361922377507
2019-01-18 14:42:19,389 4 loss=0.2935347855029888
2019-01-18 14:42:19,390 5 loss=0.23926662086743675
2019-01-18 14:42:19,390 6 loss=0.20071418217552203
2019-01-18 14:42:19,391 7 loss=0.17156065844367344
2019-01-18 14:42:19,391 8 loss=0.1487926644212846
2019-01-18 14:42:19,392 9 loss=0.13063551438439638
2019-01-18 14:42:19,392 10 loss=0.11590214903866708
2019-01-18 14:42:19,393 11 loss=0.10374755545193388
2019-01-18 14:42:19,393 12 loss=0.09355601793801765
2019-01-18 14:42:19,394 13 loss=0.08487721564573715
2019-01-18 14:42:19,394 14 loss=0.07738299615799296
2019-01-18 14:42:19,394 15 loss=0.07083505556267132
2019-01-18 14:42:19,395 16 loss=0.06506003261815853
2019-01-18 14:42:19,396 17 loss=0.059930525905130025
2019-01-18 14:42:19,396 18 loss=0.05535105021769874
2019-01-18 14:42:19,397 19 loss=0.05124801827002485
2019-01-18 14:42:19,397 20 loss=0.047562851668921276
2019-01-18 14:42:19,397 21 loss=0.04424739893882335
2019-01-18 14:42:19,398 22 loss=0.04126096774937407
2019-01-18 14:42:19,398 23 loss=0.03856843203679258
2019-01-18 14:42:19,399 24 loss=0.03613902287033657
2019-01-18 14:42:19,399 25 loss=0.03394553692497618
2019-01-18 14:42:19,400 26 loss=0.03196379193862731
2019-01-18 14:42:19,400 27 loss=0.030172225849011157
2019-01-18 14:42:19,401 28 loss=0.02855158047371626
2019-01-18 14:42:19,401 29 loss=0.027084637666403746
2019-01-18 14:42:19,402 30 loss=0.025755991350990413
2019-01-18 14:42:19,402 31 loss=0.024551847019876703
2019-01-18 14:42:19,403 32 loss=0.023459844235663167
2019-01-18 14:42:19,403 33 loss=0.022468899378927938
2019-01-18 14:42:19,404 34 loss=0.02156906651858816
2019-01-18 14:42:19,404 35 loss=0.020751414488235895
2019-01-18 14:42:19,405 36 loss=0.020007918341707617
2019-01-18 14:42:19,405 37 loss=0.01933136345801328
2019-01-18 14:42:19,405 38 loss=0.01871526070079313
2019-01-18 14:42:19,406 39 loss=0.018153771203146336
2019-01-18 14:42:19,406 40 loss=0.017641639526780956
2019-01-18 14:42:19,407 41 loss=0.01717413411847209
2019-01-18 14:42:19,407 42 loss=0.016746994145902975
2019-01-18 14:42:19,408 43 loss=0.016356381933811975
2019-01-18 14:42:19,409 44 loss=0.015998840338818588
2019-01-18 14:42:19,409 45 loss=0.015671254498724422
2019-01-18 14:42:19,409 46 loss=0.015370817472065717
2019-01-18 14:42:19,410 47 loss=0.015094999349180127
2019-01-18 14:42:19,410 48 loss=0.01484151946984251
2019-01-18 14:42:19,411 49 loss=0.014608321427050621
2019-01-18 14:42:19,411 50 loss=0.014393550573784952
2019-01-18 14:42:19,411 final loss=0.014393550573784952
2019-01-18 14:42:19,411 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:19,412 	 Computing Major Stats lazily... 
2019-01-18 14:42:19,412 		 Completed edges=42 good=42 bad=0
2019-01-18 14:42:19,413 Distortion avg=0.10977459481875547 wc=1.379147177157144 me=1.1703082463967878 mc=1.1784477990335807 nan_elements=0
2019-01-18 14:42:19,413 MAP = 1.0
2019-01-18 14:42:19,413 scale=[array([1.])]
2019-01-18 15:17:03,123 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1275.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1275.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:17:03,125 No Model Save selected!
