2019-01-18 14:42:45,536 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1615.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1615.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:45,536 No Model Save selected!
2019-01-18 14:42:45,537 Loaded Graph data/edges/parsing/ewt/ewt_dev/1615.edges with 6 nodes scale=1.0
2019-01-18 14:42:45,538 Building dataset
2019-01-18 14:42:45,538 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:42:45,543 Built Data Sampler
2019-01-18 14:42:45,543 Creating a fresh model warm_start?=None
2019-01-18 14:42:45,543 	 Warmstarting? None None 6
2019-01-18 14:42:45,543 Embedding() torch.Size([6, 10])
2019-01-18 14:42:45,543 relative No Rescale
2019-01-18 14:42:45,544 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:45,544 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:45,544 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:45,544 	 Computing Major Stats lazily... 
2019-01-18 14:42:45,545 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:45,546 Distortion avg=0.9970107087516167 wc=3.6322181433519583 me=0.005628252251848828 mc=645.354540063269 nan_elements=0
2019-01-18 14:42:45,546 MAP = 0.44999999999999996
2019-01-18 14:42:45,547 scale=[array([1.])]
2019-01-18 14:42:45,547 *** End Initial Checkpoint

2019-01-18 14:42:45,605 1 loss=0.9940318309062036
2019-01-18 14:42:45,606 2 loss=0.4293061030090941
2019-01-18 14:42:45,607 3 loss=0.26996040000143373
2019-01-18 14:42:45,607 4 loss=0.19002482905619816
2019-01-18 14:42:45,607 5 loss=0.13769665547696744
2019-01-18 14:42:45,608 6 loss=0.10183942906149393
2019-01-18 14:42:45,608 7 loss=0.0769895567126652
2019-01-18 14:42:45,609 8 loss=0.05965395439234069
2019-01-18 14:42:45,609 9 loss=0.04747097945915806
2019-01-18 14:42:45,610 10 loss=0.03882966988573068
2019-01-18 14:42:45,611 11 loss=0.03263285478227043
2019-01-18 14:42:45,611 12 loss=0.028134611961158146
2019-01-18 14:42:45,612 13 loss=0.024827266460764986
2019-01-18 14:42:45,612 14 loss=0.022363786335547396
2019-01-18 14:42:45,613 15 loss=0.02050526582498964
2019-01-18 14:42:45,613 16 loss=0.019085739612479887
2019-01-18 14:42:45,614 17 loss=0.01798870898200263
2019-01-18 14:42:45,614 18 loss=0.01713147415698903
2019-01-18 14:42:45,615 19 loss=0.016454637000385818
2019-01-18 14:42:45,615 20 loss=0.015915025397711762
2019-01-18 14:42:45,615 21 loss=0.015480888146382248
2019-01-18 14:42:45,616 22 loss=0.01512860375851301
2019-01-18 14:42:45,616 23 loss=0.014840404936778637
2019-01-18 14:42:45,617 24 loss=0.014602789308538542
2019-01-18 14:42:45,617 25 loss=0.014405397510388945
2019-01-18 14:42:45,618 26 loss=0.014240212301424358
2019-01-18 14:42:45,618 27 loss=0.014100980269528446
2019-01-18 14:42:45,619 28 loss=0.013982789439065306
2019-01-18 14:42:45,619 29 loss=0.01388175724190322
2019-01-18 14:42:45,620 30 loss=0.013794797490223169
2019-01-18 14:42:45,620 31 loss=0.013719444549844523
2019-01-18 14:42:45,621 32 loss=0.013653719404972866
2019-01-18 14:42:45,621 33 loss=0.013596026748247999
2019-01-18 14:42:45,621 34 loss=0.013545075296794716
2019-01-18 14:42:45,622 35 loss=0.013499815671958742
2019-01-18 14:42:45,622 36 loss=0.013459391684731786
2019-01-18 14:42:45,623 37 loss=0.013423101939362119
2019-01-18 14:42:45,623 38 loss=0.013390369438044527
2019-01-18 14:42:45,624 39 loss=0.013360717430402735
2019-01-18 14:42:45,624 40 loss=0.013333750164403496
2019-01-18 14:42:45,625 41 loss=0.013309137502759848
2019-01-18 14:42:45,625 42 loss=0.01328660260016593
2019-01-18 14:42:45,626 43 loss=0.013265912012422042
2019-01-18 14:42:45,626 44 loss=0.013246867743199007
2019-01-18 14:42:45,626 45 loss=0.013229300838261427
2019-01-18 14:42:45,627 46 loss=0.013213066217943614
2019-01-18 14:42:45,627 47 loss=0.013198038502061835
2019-01-18 14:42:45,628 48 loss=0.013184108631325667
2019-01-18 14:42:45,629 49 loss=0.013171181128734725
2019-01-18 14:42:45,629 50 loss=0.013159171875718296
2019-01-18 14:42:45,629 final loss=0.013159171875718296
2019-01-18 14:42:45,629 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:45,629 	 Computing Major Stats lazily... 
2019-01-18 14:42:45,630 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:45,631 Distortion avg=0.1112183391671621 wc=1.287402320310921 me=1.1471392603295907 mc=1.1222720421416235 nan_elements=0
2019-01-18 14:42:45,631 MAP = 1.0
2019-01-18 14:42:45,631 scale=[array([1.])]
2019-01-18 15:17:24,604 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1615.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1615.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:17:24,605 No Model Save selected!
