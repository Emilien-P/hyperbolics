2019-01-18 14:42:21,953 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1365.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1365.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:21,953 No Model Save selected!
2019-01-18 14:42:21,955 Loaded Graph data/edges/parsing/ewt/ewt_dev/1365.edges with 6 nodes scale=1.0
2019-01-18 14:42:21,955 Building dataset
2019-01-18 14:42:21,956 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:42:21,961 Built Data Sampler
2019-01-18 14:42:21,961 Creating a fresh model warm_start?=None
2019-01-18 14:42:21,961 	 Warmstarting? None None 6
2019-01-18 14:42:21,961 Embedding() torch.Size([6, 10])
2019-01-18 14:42:21,961 relative No Rescale
2019-01-18 14:42:21,962 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:21,962 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:21,962 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:21,962 	 Computing Major Stats lazily... 
2019-01-18 14:42:21,963 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:21,964 Distortion avg=0.9972013655344056 wc=5.448327215027938 me=0.005628252251848828 mc=968.0318100949036 nan_elements=0
2019-01-18 14:42:21,964 MAP = 0.5157407407407407
2019-01-18 14:42:21,965 scale=[array([1.])]
2019-01-18 14:42:21,965 *** End Initial Checkpoint

2019-01-18 14:42:22,022 1 loss=0.9944124643383934
2019-01-18 14:42:22,023 2 loss=0.4842956424101141
2019-01-18 14:42:22,023 3 loss=0.32684005935728055
2019-01-18 14:42:22,024 4 loss=0.2608686738120253
2019-01-18 14:42:22,024 5 loss=0.21872250806109902
2019-01-18 14:42:22,025 6 loss=0.18660755202018695
2019-01-18 14:42:22,025 7 loss=0.16088289028695626
2019-01-18 14:42:22,025 8 loss=0.13989682229042813
2019-01-18 14:42:22,026 9 loss=0.12253593628511651
2019-01-18 14:42:22,026 10 loss=0.10797119735171254
2019-01-18 14:42:22,027 11 loss=0.09559362838035199
2019-01-18 14:42:22,027 12 loss=0.08496663446804377
2019-01-18 14:42:22,028 13 loss=0.07577798532406176
2019-01-18 14:42:22,028 14 loss=0.06779828253938994
2019-01-18 14:42:22,028 15 loss=0.06085063891145488
2019-01-18 14:42:22,029 16 loss=0.05479147670399768
2019-01-18 14:42:22,029 17 loss=0.049499700740869096
2019-01-18 14:42:22,030 18 loss=0.04487106104234658
2019-01-18 14:42:22,030 19 loss=0.04081522337693485
2019-01-18 14:42:22,031 20 loss=0.03725401848399309
2019-01-18 14:42:22,031 21 loss=0.03412010053852207
2019-01-18 14:42:22,032 22 loss=0.031355712584373155
2019-01-18 14:42:22,032 23 loss=0.028911488518643755
2019-01-18 14:42:22,033 24 loss=0.026745309182268032
2019-01-18 14:42:22,033 25 loss=0.024821247065875407
2019-01-18 14:42:22,034 26 loss=0.023108624187296915
2019-01-18 14:42:22,034 27 loss=0.021581192519026054
2019-01-18 14:42:22,035 28 loss=0.020216434229276208
2019-01-18 14:42:22,035 29 loss=0.018994971688227776
2019-01-18 14:42:22,036 30 loss=0.017900073892521004
2019-01-18 14:42:22,036 31 loss=0.01691724531308647
2019-01-18 14:42:22,036 32 loss=0.016033883997154465
2019-01-18 14:42:22,037 33 loss=0.015238997247338472
2019-01-18 14:42:22,037 34 loss=0.01452296487943598
2019-01-18 14:42:22,038 35 loss=0.013877341675909287
2019-01-18 14:42:22,038 36 loss=0.013294692093991273
2019-01-18 14:42:22,039 37 loss=0.012768451523144776
2019-01-18 14:42:22,039 38 loss=0.012292809421260055
2019-01-18 14:42:22,040 39 loss=0.011862610513581779
2019-01-18 14:42:22,040 40 loss=0.011473270938703633
2019-01-18 14:42:22,041 41 loss=0.011120706797288103
2019-01-18 14:42:22,041 42 loss=0.010801273024026802
2019-01-18 14:42:22,042 43 loss=0.010511710881063242
2019-01-18 14:42:22,042 44 loss=0.010249102677799297
2019-01-18 14:42:22,043 45 loss=0.010010832571024699
2019-01-18 14:42:22,043 46 loss=0.009794552501558477
2019-01-18 14:42:22,044 47 loss=0.009598152487974082
2019-01-18 14:42:22,044 48 loss=0.009419734631724257
2019-01-18 14:42:22,044 49 loss=0.009257590296954324
2019-01-18 14:42:22,045 50 loss=0.009110180017234838
2019-01-18 14:42:22,045 final loss=0.009110180017234838
2019-01-18 14:42:22,045 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:22,045 	 Computing Major Stats lazily... 
2019-01-18 14:42:22,045 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:22,047 Distortion avg=0.08608157333910092 wc=1.3016431283092353 me=1.1311334862116098 mc=1.1507422812392338 nan_elements=0
2019-01-18 14:42:22,047 MAP = 1.0
2019-01-18 14:42:22,047 scale=[array([1.])]
2019-01-18 15:14:35,607 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1365.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1365.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:14:35,608 No Model Save selected!
