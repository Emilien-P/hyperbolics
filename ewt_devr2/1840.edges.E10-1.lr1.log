2019-01-18 14:39:24,710 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1840.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1840.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:24,710 No Model Save selected!
2019-01-18 14:39:24,712 Loaded Graph data/edges/parsing/ewt/ewt_dev/1840.edges with 11 nodes scale=1.0
2019-01-18 14:39:24,712 Building dataset
2019-01-18 14:39:24,713 Subsample: 11 points with scale 1.0 subsample=10
2019-01-18 14:39:24,722 Built Data Sampler
2019-01-18 14:39:24,722 Creating a fresh model warm_start?=None
2019-01-18 14:39:24,722 	 Warmstarting? None None 11
2019-01-18 14:39:24,722 Embedding() torch.Size([11, 10])
2019-01-18 14:39:24,723 relative No Rescale
2019-01-18 14:39:24,723 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:24,723 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:24,723 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:24,723 	 Computing Major Stats lazily... 
2019-01-18 14:39:24,724 		 Completed edges=110 good=110 bad=0
2019-01-18 14:39:24,726 Distortion avg=0.99778260832073 wc=5.988977976569666 me=0.005628252251848828 mc=1064.0919611594068 nan_elements=0
2019-01-18 14:39:24,726 MAP = 0.21296596921596925
2019-01-18 14:39:24,727 scale=[array([1.])]
2019-01-18 14:39:24,727 *** End Initial Checkpoint

2019-01-18 14:39:24,784 1 loss=0.9955717658342994
2019-01-18 14:39:24,785 2 loss=0.7979065702215934
2019-01-18 14:39:24,786 3 loss=0.6576687463479957
2019-01-18 14:39:24,786 4 loss=0.5608008532389379
2019-01-18 14:39:24,787 5 loss=0.4915621694424391
2019-01-18 14:39:24,787 6 loss=0.4399776097054572
2019-01-18 14:39:24,788 7 loss=0.39992863724475697
2019-01-18 14:39:24,788 8 loss=0.36765492540186423
2019-01-18 14:39:24,789 9 loss=0.340815251600615
2019-01-18 14:39:24,789 10 loss=0.31792303649987264
2019-01-18 14:39:24,790 11 loss=0.29801034308640983
2019-01-18 14:39:24,791 12 loss=0.28042770068246375
2019-01-18 14:39:24,791 13 loss=0.26472419292178545
2019-01-18 14:39:24,792 14 loss=0.2505750569948236
2019-01-18 14:39:24,792 15 loss=0.23773755769152372
2019-01-18 14:39:24,793 16 loss=0.22602380772646483
2019-01-18 14:39:24,794 17 loss=0.21528382216996123
2019-01-18 14:39:24,794 18 loss=0.20539479871086982
2019-01-18 14:39:24,795 19 loss=0.19625420995787654
2019-01-18 14:39:24,795 20 loss=0.1877752426314425
2019-01-18 14:39:24,796 21 loss=0.17988368859579257
2019-01-18 14:39:24,796 22 loss=0.1725157388285661
2019-01-18 14:39:24,797 23 loss=0.1656163436032928
2019-01-18 14:39:24,797 24 loss=0.1591379331825909
2019-01-18 14:39:24,798 25 loss=0.15303937452094338
2019-01-18 14:39:24,799 26 loss=0.14728508968782028
2019-01-18 14:39:24,799 27 loss=0.141844292447404
2019-01-18 14:39:24,800 28 loss=0.13669031783041208
2019-01-18 14:39:24,800 29 loss=0.13180003015420266
2019-01-18 14:39:24,801 30 loss=0.1271533007287591
2019-01-18 14:39:24,801 31 loss=0.12273254934615083
2019-01-18 14:39:24,802 32 loss=0.11852234483734907
2019-01-18 14:39:24,802 33 loss=0.11450906028941324
2019-01-18 14:39:24,803 34 loss=0.11068057843821942
2019-01-18 14:39:24,803 35 loss=0.1070260425711392
2019-01-18 14:39:24,804 36 loss=0.10353564813979667
2019-01-18 14:39:24,804 37 loss=0.1002004702604
2019-01-18 14:39:24,805 38 loss=0.09701232238374784
2019-01-18 14:39:24,806 39 loss=0.0939636416376282
2019-01-18 14:39:24,806 40 loss=0.09104739665718477
2019-01-18 14:39:24,807 41 loss=0.08825701409608767
2019-01-18 14:39:24,807 42 loss=0.08558632042590968
2019-01-18 14:39:24,808 43 loss=0.08302949605909433
2019-01-18 14:39:24,808 44 loss=0.08058103925280959
2019-01-18 14:39:24,809 45 loss=0.07823573765194947
2019-01-18 14:39:24,809 46 loss=0.07598864569920674
2019-01-18 14:39:24,810 47 loss=0.0738350664720704
2019-01-18 14:39:24,810 48 loss=0.07177053679772649
2019-01-18 14:39:24,811 49 loss=0.0697908147467098
2019-01-18 14:39:24,811 50 loss=0.06789186881627662
2019-01-18 14:39:24,812 final loss=0.06789186881627662
2019-01-18 14:39:24,812 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:24,812 	 Computing Major Stats lazily... 
2019-01-18 14:39:24,812 		 Completed edges=110 good=110 bad=0
2019-01-18 14:39:24,814 Distortion avg=0.22344543402959477 wc=2.802232149181023 me=1.3373937199996102 mc=2.0952933360430612 nan_elements=0
2019-01-18 14:39:24,814 MAP = 1.0
2019-01-18 14:39:24,814 scale=[array([1.])]
2019-01-18 15:19:54,087 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1840.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1840.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:19:54,087 No Model Save selected!
