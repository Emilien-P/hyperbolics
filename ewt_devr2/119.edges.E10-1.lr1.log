2019-01-18 14:41:59,606 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/119.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/119.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:59,606 No Model Save selected!
2019-01-18 14:41:59,608 Loaded Graph data/edges/parsing/ewt/ewt_dev/119.edges with 4 nodes scale=1.0
2019-01-18 14:41:59,608 Building dataset
2019-01-18 14:41:59,609 Subsample: 4 points with scale 1.0 subsample=3
2019-01-18 14:41:59,612 Built Data Sampler
2019-01-18 14:41:59,612 Creating a fresh model warm_start?=None
2019-01-18 14:41:59,612 	 Warmstarting? None None 4
2019-01-18 14:41:59,612 Embedding() torch.Size([4, 10])
2019-01-18 14:41:59,612 relative No Rescale
2019-01-18 14:41:59,613 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:59,613 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:59,613 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:59,613 	 Computing Major Stats lazily... 
2019-01-18 14:41:59,614 		 Completed edges=12 good=12 bad=0
2019-01-18 14:41:59,614 Distortion avg=0.9966404299181114 wc=3.2869580912217393 me=0.005628252251848828 mc=584.0104430539702 nan_elements=0
2019-01-18 14:41:59,614 MAP = 0.5
2019-01-18 14:41:59,615 scale=[array([1.])]
2019-01-18 14:41:59,615 *** End Initial Checkpoint

2019-01-18 14:41:59,672 1 loss=0.9932946490341571
2019-01-18 14:41:59,672 2 loss=0.2407395144924753
2019-01-18 14:41:59,673 3 loss=0.1294833284649695
2019-01-18 14:41:59,673 4 loss=0.07888125022286527
2019-01-18 14:41:59,674 5 loss=0.05111446373423253
2019-01-18 14:41:59,674 6 loss=0.035110241552562343
2019-01-18 14:41:59,675 7 loss=0.02553088144826274
2019-01-18 14:41:59,675 8 loss=0.01952698322341952
2019-01-18 14:41:59,676 9 loss=0.015603051035423412
2019-01-18 14:41:59,676 10 loss=0.01294279876686467
2019-01-18 14:41:59,677 11 loss=0.011080267580807442
2019-01-18 14:41:59,677 12 loss=0.009739192030568788
2019-01-18 14:41:59,678 13 loss=0.008750077509507341
2019-01-18 14:41:59,678 14 loss=0.008005510421100225
2019-01-18 14:41:59,678 15 loss=0.00743530225563032
2019-01-18 14:41:59,679 16 loss=0.006992263995116508
2019-01-18 14:41:59,679 17 loss=0.006643831475188717
2019-01-18 14:41:59,680 18 loss=0.006366996279128556
2019-01-18 14:41:59,680 19 loss=0.0061451537737712515
2019-01-18 14:41:59,681 20 loss=0.005966092316536989
2019-01-18 14:41:59,681 21 loss=0.00582067911886724
2019-01-18 14:41:59,681 22 loss=0.005701981819181498
2019-01-18 14:41:59,682 23 loss=0.005604668880595393
2019-01-18 14:41:59,682 24 loss=0.005524592303003056
2019-01-18 14:41:59,683 25 loss=0.005458491969625524
2019-01-18 14:41:59,683 26 loss=0.0054037826825149285
2019-01-18 14:41:59,684 27 loss=0.00535839840338033
2019-01-18 14:41:59,684 28 loss=0.0053206767205548665
2019-01-18 14:41:59,684 29 loss=0.005289272036446989
2019-01-18 14:41:59,685 30 loss=0.005263089554618169
2019-01-18 14:41:59,685 31 loss=0.005241234532094112
2019-01-18 14:41:59,686 32 loss=0.005222972875700671
2019-01-18 14:41:59,686 33 loss=0.005207700267418497
2019-01-18 14:41:59,687 34 loss=0.005194917772591086
2019-01-18 14:41:59,687 35 loss=0.0051842124260252365
2019-01-18 14:41:59,687 36 loss=0.005175241676609974
2019-01-18 14:41:59,688 37 loss=0.005167720848972987
2019-01-18 14:41:59,688 38 loss=0.005161412983185449
2019-01-18 14:41:59,689 39 loss=0.005156120562642375
2019-01-18 14:41:59,689 40 loss=0.00515167875117728
2019-01-18 14:41:59,690 41 loss=0.005147949843805555
2019-01-18 14:41:59,690 42 loss=0.005144818698686664
2019-01-18 14:41:59,690 43 loss=0.005142188966251414
2019-01-18 14:41:59,691 44 loss=0.005139979968761199
2019-01-18 14:41:59,691 45 loss=0.005138124112604783
2019-01-18 14:41:59,692 46 loss=0.005136564738407268
2019-01-18 14:41:59,692 47 loss=0.005135254332007701
2019-01-18 14:41:59,693 48 loss=0.005134153033657964
2019-01-18 14:41:59,693 49 loss=0.0051332273942311475
2019-01-18 14:41:59,694 50 loss=0.0051324493364284995
2019-01-18 14:41:59,694 final loss=0.0051324493364284995
2019-01-18 14:41:59,694 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:59,694 	 Computing Major Stats lazily... 
2019-01-18 14:41:59,694 		 Completed edges=12 good=12 bad=0
2019-01-18 14:41:59,695 Distortion avg=0.07145200514321905 wc=1.1548810574391133 me=1.066326818975048 mc=1.083046057632859 nan_elements=0
2019-01-18 14:41:59,695 MAP = 1.0
2019-01-18 14:41:59,695 scale=[array([1.])]
2019-01-18 15:23:03,354 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/119.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/119.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:23:03,355 No Model Save selected!
