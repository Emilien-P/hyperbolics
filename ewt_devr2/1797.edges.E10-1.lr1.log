2019-01-18 14:42:08,196 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1797.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1797.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:08,196 No Model Save selected!
2019-01-18 14:42:08,197 Loaded Graph data/edges/parsing/ewt/ewt_dev/1797.edges with 21 nodes scale=1.0
2019-01-18 14:42:08,197 Building dataset
2019-01-18 14:42:08,198 Subsample: 21 points with scale 1.0 subsample=20
2019-01-18 14:42:08,221 Built Data Sampler
2019-01-18 14:42:08,221 Creating a fresh model warm_start?=None
2019-01-18 14:42:08,221 	 Warmstarting? None None 21
2019-01-18 14:42:08,222 Embedding() torch.Size([21, 10])
2019-01-18 14:42:08,222 relative No Rescale
2019-01-18 14:42:08,222 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:08,222 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:08,222 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:08,222 	 Computing Major Stats lazily... 
2019-01-18 14:42:08,225 		 Completed edges=420 good=420 bad=0
2019-01-18 14:42:08,228 Distortion avg=0.998472176890148 wc=20.656916545919444 me=0.005941110731069004 mc=3476.945217986633 nan_elements=0
2019-01-18 14:42:08,228 MAP = 0.1444405784096924
2019-01-18 14:42:08,228 scale=[array([1.])]
2019-01-18 14:42:08,228 *** End Initial Checkpoint

2019-01-18 14:42:08,287 1 loss=0.9969481065689655
2019-01-18 14:42:08,288 2 loss=0.9467322722785013
2019-01-18 14:42:08,289 3 loss=0.899612100941943
2019-01-18 14:42:08,289 4 loss=0.8568175979432038
2019-01-18 14:42:08,290 5 loss=0.8181016516739321
2019-01-18 14:42:08,291 6 loss=0.7830917612790086
2019-01-18 14:42:08,292 7 loss=0.7514131114013883
2019-01-18 14:42:08,293 8 loss=0.7227155174192536
2019-01-18 14:42:08,293 9 loss=0.6966801564474076
2019-01-18 14:42:08,294 10 loss=0.6730201415192271
2019-01-18 14:42:08,295 11 loss=0.6514789048433556
2019-01-18 14:42:08,296 12 loss=0.631827798395558
2019-01-18 14:42:08,296 13 loss=0.6138634840848983
2019-01-18 14:42:08,297 14 loss=0.5974053630122397
2019-01-18 14:42:08,298 15 loss=0.582293153734972
2019-01-18 14:42:08,299 16 loss=0.5683846642113634
2019-01-18 14:42:08,299 17 loss=0.5555537701266698
2019-01-18 14:42:08,300 18 loss=0.5436885963439816
2019-01-18 14:42:08,301 19 loss=0.5326898903989626
2019-01-18 14:42:08,302 20 loss=0.5224695734262768
2019-01-18 14:42:08,303 21 loss=0.5129494526888722
2019-01-18 14:42:08,304 22 loss=0.5040600799178909
2019-01-18 14:42:08,305 23 loss=0.49573974037232194
2019-01-18 14:42:08,305 24 loss=0.487933558560111
2019-01-18 14:42:08,306 25 loss=0.480592707734826
2019-01-18 14:42:08,307 26 loss=0.4736737114842764
2019-01-18 14:42:08,308 27 loss=0.46713782689760674
2019-01-18 14:42:08,308 28 loss=0.4609504999016742
2019-01-18 14:42:08,309 29 loss=0.45508088437941885
2019-01-18 14:42:08,310 30 loss=0.44950141761617574
2019-01-18 14:42:08,311 31 loss=0.44418744546422223
2019-01-18 14:42:08,311 32 loss=0.43911689137467974
2019-01-18 14:42:08,312 33 loss=0.43426996412443114
2019-01-18 14:42:08,313 34 loss=0.4296288996701974
2019-01-18 14:42:08,314 35 loss=0.42517773309886675
2019-01-18 14:42:08,314 36 loss=0.420902097119053
2019-01-18 14:42:08,315 37 loss=0.41678904395990507
2019-01-18 14:42:08,316 38 loss=0.4128268879151832
2019-01-18 14:42:08,317 39 loss=0.40900506609894327
2019-01-18 14:42:08,317 40 loss=0.4053140152686952
2019-01-18 14:42:08,318 41 loss=0.4017450628270575
2019-01-18 14:42:08,319 42 loss=0.3982903303376799
2019-01-18 14:42:08,320 43 loss=0.39494264808910345
2019-01-18 14:42:08,320 44 loss=0.39169547941443433
2019-01-18 14:42:08,321 45 loss=0.3885428536280442
2019-01-18 14:42:08,322 46 loss=0.3854793065754451
2019-01-18 14:42:08,323 47 loss=0.3824998279112516
2019-01-18 14:42:08,324 48 loss=0.3795998143246593
2019-01-18 14:42:08,324 49 loss=0.3767750280238643
2019-01-18 14:42:08,325 50 loss=0.3740215598718292
2019-01-18 14:42:08,325 final loss=0.3740215598718292
2019-01-18 14:42:08,325 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:08,325 	 Computing Major Stats lazily... 
2019-01-18 14:42:08,327 		 Completed edges=420 good=420 bad=0
2019-01-18 14:42:08,330 Distortion avg=0.5732818162964564 wc=17.61525720240746 me=1.9571439533940038 mc=9.00049133936201 nan_elements=0
2019-01-18 14:42:08,331 MAP = 0.12449473655245435
2019-01-18 14:42:08,331 scale=[array([1.])]
2019-01-18 15:18:47,136 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1797.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1797.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:18:47,137 No Model Save selected!
