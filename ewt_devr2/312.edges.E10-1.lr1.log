2019-01-18 14:40:53,377 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/312.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/312.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:53,377 No Model Save selected!
2019-01-18 14:40:53,378 Loaded Graph data/edges/parsing/ewt/ewt_dev/312.edges with 2 nodes scale=1.0
2019-01-18 14:40:53,378 Building dataset
2019-01-18 14:40:53,379 Subsample: 2 points with scale 1.0 subsample=1
2019-01-18 14:40:53,381 Built Data Sampler
2019-01-18 14:40:53,381 Creating a fresh model warm_start?=None
2019-01-18 14:40:53,381 	 Warmstarting? None None 2
2019-01-18 14:40:53,381 Embedding() torch.Size([2, 10])
2019-01-18 14:40:53,382 relative No Rescale
2019-01-18 14:40:53,382 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:53,382 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:53,382 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:53,382 	 Computing Major Stats lazily... 
2019-01-18 14:40:53,383 		 Completed edges=2 good=2 bad=0
2019-01-18 14:40:53,383 Distortion avg=0.9965968412004117 wc=1.0 me=0.00340315879958833 mc=293.8446481313088 nan_elements=0
2019-01-18 14:40:53,383 MAP = 1.0
2019-01-18 14:40:53,384 scale=[array([1.])]
2019-01-18 14:40:53,384 *** End Initial Checkpoint

2019-01-18 14:40:53,441 1 loss=0.9932052638906386
2019-01-18 14:40:53,441 2 loss=8.938847375015749
2019-01-18 14:40:53,442 3 loss=48.57214009192693
2019-01-18 14:40:53,442 4 loss=357.51680197769787
2019-01-18 14:40:53,443 5 loss=2994.7538412503473
2019-01-18 14:40:53,443 6 loss=26300.09244160632
2019-01-18 14:40:53,443 7 loss=234758.7555855165
2019-01-18 14:40:53,444 8 loss=2107018.5711028273
2019-01-18 14:40:53,444 9 loss=18945752.452424984
2019-01-18 14:40:53,445 10 loss=170459544.00932342
2019-01-18 14:40:53,445 11 loss=1533979227.8964074
2019-01-18 14:40:53,445 12 loss=13805343062.505152
2019-01-18 14:40:53,446 13 loss=124246677612.85883
2019-01-18 14:40:53,446 14 loss=1118215868682.6665
2019-01-18 14:40:53,447 15 loss=10063930128660.81
2019-01-18 14:40:53,447 16 loss=90575333089513.72
2019-01-18 14:40:53,447 17 loss=815177883600338.8
2019-01-18 14:40:53,448 18 loss=7336600609787212.0
2019-01-18 14:40:53,448 19 loss=6.60294044602374e+16
2019-01-18 14:40:53,449 20 loss=5.94264637058594e+17
2019-01-18 14:40:53,449 21 loss=5.348381724276721e+18
2019-01-18 14:40:53,450 22 loss=4.81354354907386e+19
2019-01-18 14:40:53,450 23 loss=4.332189193333917e+20
2019-01-18 14:40:53,450 24 loss=3.898970273750758e+21
2019-01-18 14:40:53,451 25 loss=3.509073246300752e+22
2019-01-18 14:40:53,451 26 loss=3.158165921648198e+23
2019-01-18 14:40:53,452 27 loss=2.842349329476635e+24
2019-01-18 14:40:53,452 28 loss=2.5581143965269464e+25
2019-01-18 14:40:53,452 29 loss=2.3023029568736446e+26
2019-01-18 14:40:53,453 30 loss=2.072072661186098e+27
2019-01-18 14:40:53,453 31 loss=1.8648653950674335e+28
2019-01-18 14:40:53,454 32 loss=1.678378855560674e+29
2019-01-18 14:40:53,454 33 loss=1.5105409700046018e+30
2019-01-18 14:40:53,454 34 loss=1.3594868730041399e+31
2019-01-18 14:40:53,455 35 loss=1.2235381857037259e+32
2019-01-18 14:40:53,455 36 loss=1.1011843671333534e+33
2019-01-18 14:40:53,456 37 loss=9.91065930420018e+33
2019-01-18 14:40:53,456 38 loss=8.91959337378016e+34
2019-01-18 14:40:53,456 39 loss=8.027634036402146e+35
2019-01-18 14:40:53,457 40 loss=7.224870632761931e+36
2019-01-18 14:40:53,457 41 loss=6.502383569485739e+37
2019-01-18 14:40:53,458 42 loss=5.852145212537165e+38
2019-01-18 14:40:53,458 43 loss=5.266930691283448e+39
2019-01-18 14:40:53,458 44 loss=4.740237622155103e+40
2019-01-18 14:40:53,459 45 loss=4.2662138599395935e+41
2019-01-18 14:40:53,459 46 loss=3.839592473945634e+42
2019-01-18 14:40:53,460 47 loss=3.4556332265510695e+43
2019-01-18 14:40:53,460 48 loss=3.1100699038959636e+44
2019-01-18 14:40:53,461 49 loss=2.7990629135063678e+45
2019-01-18 14:40:53,461 50 loss=2.519156622155731e+46
2019-01-18 14:40:53,461 final loss=2.519156622155731e+46
2019-01-18 14:40:53,461 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:53,461 	 Computing Major Stats lazily... 
2019-01-18 14:40:53,461 		 Completed edges=2 good=2 bad=0
2019-01-18 14:40:53,462 Distortion avg=4.7615553760721484e+23 wc=1.0 me=4.7615553760721484e+23 mc=2.1001540904579576e-24 nan_elements=0
2019-01-18 14:40:53,462 MAP = 1.0
2019-01-18 14:40:53,462 scale=[array([1.])]
2019-01-18 15:20:15,653 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/312.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/312.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:20:15,654 No Model Save selected!
