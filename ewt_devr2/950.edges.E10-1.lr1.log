2019-01-18 14:40:44,672 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/950.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/950.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:44,672 No Model Save selected!
2019-01-18 14:40:44,674 Loaded Graph data/edges/parsing/ewt/ewt_dev/950.edges with 36 nodes scale=1.0
2019-01-18 14:40:44,674 Building dataset
2019-01-18 14:40:44,675 Subsample: 36 points with scale 1.0 subsample=35
2019-01-18 14:40:44,729 Built Data Sampler
2019-01-18 14:40:44,729 Creating a fresh model warm_start?=None
2019-01-18 14:40:44,729 	 Warmstarting? None None 36
2019-01-18 14:40:44,729 Embedding() torch.Size([36, 10])
2019-01-18 14:40:44,730 relative No Rescale
2019-01-18 14:40:44,730 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:44,730 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:44,730 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:44,730 	 Computing Major Stats lazily... 
2019-01-18 14:40:44,736 		 Completed edges=1260 good=1260 bad=0
2019-01-18 14:40:44,742 Distortion avg=0.9988228490379714 wc=25.985463815778726 me=0.005628252251848828 mc=4616.9685815419425 nan_elements=0
2019-01-18 14:40:44,742 MAP = 0.11894972985761597
2019-01-18 14:40:44,742 scale=[array([1.])]
2019-01-18 14:40:44,742 *** End Initial Checkpoint

2019-01-18 14:40:44,801 1 loss=0.9976479833956945
2019-01-18 14:40:44,803 2 loss=0.9793905290666118
2019-01-18 14:40:44,804 3 loss=0.961162813835124
2019-01-18 14:40:44,805 4 loss=0.9434708822165743
2019-01-18 14:40:44,807 5 loss=0.9263826167233848
2019-01-18 14:40:44,808 6 loss=0.9099060484668132
2019-01-18 14:40:44,809 7 loss=0.894031308917669
2019-01-18 14:40:44,811 8 loss=0.8787415564985768
2019-01-18 14:40:44,812 9 loss=0.8640169815363483
2019-01-18 14:40:44,813 10 loss=0.8498365816352118
2019-01-18 14:40:44,814 11 loss=0.8361790469781766
2019-01-18 14:40:44,816 12 loss=0.8230232357544299
2019-01-18 14:40:44,817 13 loss=0.8103484406224806
2019-01-18 14:40:44,818 14 loss=0.7981345403017448
2019-01-18 14:40:44,820 15 loss=0.7863620843258285
2019-01-18 14:40:44,821 16 loss=0.7750123372022768
2019-01-18 14:40:44,822 17 loss=0.764067297125544
2019-01-18 14:40:44,823 18 loss=0.7535096983847662
2019-01-18 14:40:44,825 19 loss=0.7433230031906183
2019-01-18 14:40:44,826 20 loss=0.733491386616362
2019-01-18 14:40:44,827 21 loss=0.7239997170986774
2019-01-18 14:40:44,828 22 loss=0.7148335341499908
2019-01-18 14:40:44,830 23 loss=0.7059790244158274
2019-01-18 14:40:44,831 24 loss=0.6974229968643808
2019-01-18 14:40:44,832 25 loss=0.6891528576593278
2019-01-18 14:40:44,833 26 loss=0.6811565851029536
2019-01-18 14:40:44,835 27 loss=0.6734227049211038
2019-01-18 14:40:44,836 28 loss=0.6659402660789926
2019-01-18 14:40:44,837 29 loss=0.6586988172573782
2019-01-18 14:40:44,839 30 loss=0.6516883840752796
2019-01-18 14:40:44,840 31 loss=0.644899447113682
2019-01-18 14:40:44,841 32 loss=0.6383229207713027
2019-01-18 14:40:44,842 33 loss=0.6319501329662781
2019-01-18 14:40:44,844 34 loss=0.6257728056849293
2019-01-18 14:40:44,845 35 loss=0.6197830363694533
2019-01-18 14:40:44,846 36 loss=0.6139732801295861
2019-01-18 14:40:44,848 37 loss=0.6083363327584193
2019-01-18 14:40:44,849 38 loss=0.602865314529115
2019-01-18 14:40:44,850 39 loss=0.5975536547469346
2019-01-18 14:40:44,852 40 loss=0.5923950770295033
2019-01-18 14:40:44,853 41 loss=0.5873835852873981
2019-01-18 14:40:44,854 42 loss=0.5825134503767581
2019-01-18 14:40:44,856 43 loss=0.577779197395651
2019-01-18 14:40:44,857 44 loss=0.5731755935961957
2019-01-18 14:40:44,858 45 loss=0.5686976368849442
2019-01-18 14:40:44,860 46 loss=0.5643405448846747
2019-01-18 14:40:44,861 47 loss=0.5600997445315102
2019-01-18 14:40:44,862 48 loss=0.5559708621821037
2019-01-18 14:40:44,863 49 loss=0.5519497142065316
2019-01-18 14:40:44,865 50 loss=0.548032298043456
2019-01-18 14:40:44,865 final loss=0.548032298043456
2019-01-18 14:40:44,865 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:44,865 	 Computing Major Stats lazily... 
2019-01-18 14:40:44,870 		 Completed edges=1260 good=1260 bad=0
2019-01-18 14:40:44,875 Distortion avg=0.713931555607948 wc=37.47942713391995 me=1.6718773431908855 mc=22.417569857360498 nan_elements=0
2019-01-18 14:40:44,876 MAP = 0.05645690823426167
2019-01-18 14:40:44,876 scale=[array([1.])]
2019-01-18 15:13:56,166 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/950.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/950.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:13:56,167 No Model Save selected!
