2019-01-18 14:42:25,626 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1777.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1777.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:25,626 No Model Save selected!
2019-01-18 14:42:25,627 Loaded Graph data/edges/parsing/ewt/ewt_dev/1777.edges with 24 nodes scale=1.0
2019-01-18 14:42:25,627 Building dataset
2019-01-18 14:42:25,628 Subsample: 24 points with scale 1.0 subsample=23
2019-01-18 14:42:25,656 Built Data Sampler
2019-01-18 14:42:25,656 Creating a fresh model warm_start?=None
2019-01-18 14:42:25,656 	 Warmstarting? None None 24
2019-01-18 14:42:25,657 Embedding() torch.Size([24, 10])
2019-01-18 14:42:25,657 relative No Rescale
2019-01-18 14:42:25,657 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:25,657 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:25,658 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:25,658 	 Computing Major Stats lazily... 
2019-01-18 14:42:25,660 		 Completed edges=552 good=552 bad=0
2019-01-18 14:42:25,664 Distortion avg=0.9983951642066798 wc=15.262713499026772 me=0.006196519622161948 mc=2463.110653993484 nan_elements=0
2019-01-18 14:42:25,664 MAP = 0.12168657789367172
2019-01-18 14:42:25,664 scale=[array([1.])]
2019-01-18 14:42:25,664 *** End Initial Checkpoint

2019-01-18 14:42:25,723 1 loss=0.9967941471240032
2019-01-18 14:42:25,724 2 loss=0.9501710233918177
2019-01-18 14:42:25,725 3 loss=0.9058907855204023
2019-01-18 14:42:25,726 4 loss=0.8651933928304247
2019-01-18 14:42:25,726 5 loss=0.8279093463475694
2019-01-18 14:42:25,727 6 loss=0.7937513532649382
2019-01-18 14:42:25,728 7 loss=0.7624260519862617
2019-01-18 14:42:25,729 8 loss=0.7336579113512379
2019-01-18 14:42:25,730 9 loss=0.7071952393045622
2019-01-18 14:42:25,731 10 loss=0.6828108525389456
2019-01-18 14:42:25,732 11 loss=0.6603008781652361
2019-01-18 14:42:25,732 12 loss=0.6394828992245928
2019-01-18 14:42:25,733 13 loss=0.6201939280297267
2019-01-18 14:42:25,734 14 loss=0.6022884141737421
2019-01-18 14:42:25,735 15 loss=0.5856363758773702
2019-01-18 14:42:25,736 16 loss=0.5701216890377656
2019-01-18 14:42:25,737 17 loss=0.5556405422744706
2019-01-18 14:42:25,737 18 loss=0.5421000536141822
2019-01-18 14:42:25,738 19 loss=0.5294170385111321
2019-01-18 14:42:25,739 20 loss=0.5175169164268079
2019-01-18 14:42:25,740 21 loss=0.5063327425451942
2019-01-18 14:42:25,741 22 loss=0.4958043515063908
2019-01-18 14:42:25,742 23 loss=0.48587760082785897
2019-01-18 14:42:25,742 24 loss=0.47650370268536796
2019-01-18 14:42:25,743 25 loss=0.467638633798175
2019-01-18 14:42:25,744 26 loss=0.45924261422402873
2019-01-18 14:42:25,745 27 loss=0.45127964687602645
2019-01-18 14:42:25,746 28 loss=0.44371711050401696
2019-01-18 14:42:25,747 29 loss=0.43652539972975996
2019-01-18 14:42:25,748 30 loss=0.4296776064864928
2019-01-18 14:42:25,749 31 loss=0.4231492378931034
2019-01-18 14:42:25,749 32 loss=0.4169179661961758
2019-01-18 14:42:25,750 33 loss=0.4109634069461531
2019-01-18 14:42:25,751 34 loss=0.4052669220434755
2019-01-18 14:42:25,752 35 loss=0.39981144470338636
2019-01-18 14:42:25,753 36 loss=0.3945813237504216
2019-01-18 14:42:25,754 37 loss=0.38956218497119716
2019-01-18 14:42:25,754 38 loss=0.38474080753226203
2019-01-18 14:42:25,755 39 loss=0.38010501371325117
2019-01-18 14:42:25,756 40 loss=0.3756435704185993
2019-01-18 14:42:25,757 41 loss=0.3713461011174381
2019-01-18 14:42:25,758 42 loss=0.3672030070243388
2019-01-18 14:42:25,759 43 loss=0.3632053964761995
2019-01-18 14:42:25,759 44 loss=0.3593450215854245
2019-01-18 14:42:25,760 45 loss=0.35561422135882453
2019-01-18 14:42:25,761 46 loss=0.35200587056739213
2019-01-18 14:42:25,762 47 loss=0.34851333373598903
2019-01-18 14:42:25,763 48 loss=0.3451304236955332
2019-01-18 14:42:25,764 49 loss=0.3418513642048026
2019-01-18 14:42:25,764 50 loss=0.3386707562056445
2019-01-18 14:42:25,764 final loss=0.3386707562056445
2019-01-18 14:42:25,765 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:25,765 	 Computing Major Stats lazily... 
2019-01-18 14:42:25,767 		 Completed edges=552 good=552 bad=0
2019-01-18 14:42:25,771 Distortion avg=0.544876926636089 wc=14.779885133007198 me=1.738699901694875 mc=8.50053831520888 nan_elements=0
2019-01-18 14:42:25,771 MAP = 0.14185998399691854
2019-01-18 14:42:25,771 scale=[array([1.])]
2019-01-18 15:15:20,920 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1777.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1777.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:15:20,921 No Model Save selected!
