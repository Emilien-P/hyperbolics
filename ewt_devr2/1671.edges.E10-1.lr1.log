2019-01-18 14:41:03,429 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1671.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1671.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:03,429 No Model Save selected!
2019-01-18 14:41:03,430 Loaded Graph data/edges/parsing/ewt/ewt_dev/1671.edges with 5 nodes scale=1.0
2019-01-18 14:41:03,431 Building dataset
2019-01-18 14:41:03,431 Subsample: 5 points with scale 1.0 subsample=4
2019-01-18 14:41:03,435 Built Data Sampler
2019-01-18 14:41:03,435 Creating a fresh model warm_start?=None
2019-01-18 14:41:03,435 	 Warmstarting? None None 5
2019-01-18 14:41:03,435 Embedding() torch.Size([5, 10])
2019-01-18 14:41:03,435 relative No Rescale
2019-01-18 14:41:03,436 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:03,436 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:03,436 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:03,436 	 Computing Major Stats lazily... 
2019-01-18 14:41:03,437 		 Completed edges=20 good=20 bad=0
2019-01-18 14:41:03,438 Distortion avg=0.9967215143566446 wc=3.26429954782084 me=0.005628252251848828 mc=579.9845852233344 nan_elements=0
2019-01-18 14:41:03,438 MAP = 0.4666666666666666
2019-01-18 14:41:03,438 scale=[array([1.])]
2019-01-18 14:41:03,438 *** End Initial Checkpoint

2019-01-18 14:41:03,496 1 loss=0.9934557708423654
2019-01-18 14:41:03,496 2 loss=0.31325420002132776
2019-01-18 14:41:03,497 3 loss=0.19965912479249623
2019-01-18 14:41:03,497 4 loss=0.1354470408350513
2019-01-18 14:41:03,498 5 loss=0.09410374813156214
2019-01-18 14:41:03,498 6 loss=0.06724310757608973
2019-01-18 14:41:03,498 7 loss=0.04971216921647029
2019-01-18 14:41:03,499 8 loss=0.038164116018673595
2019-01-18 14:41:03,499 9 loss=0.03043463971625799
2019-01-18 14:41:03,500 10 loss=0.02515118905285792
2019-01-18 14:41:03,500 11 loss=0.021455211044445806
2019-01-18 14:41:03,501 12 loss=0.018810052787481206
2019-01-18 14:41:03,501 13 loss=0.01687651985411015
2019-01-18 14:41:03,502 14 loss=0.015436205515941298
2019-01-18 14:41:03,502 15 loss=0.01434537144574044
2019-01-18 14:41:03,502 16 loss=0.013507267383608332
2019-01-18 14:41:03,503 17 loss=0.012855329454479347
2019-01-18 14:41:03,503 18 loss=0.012342800911071507
2019-01-18 14:41:03,504 19 loss=0.011936194128025436
2019-01-18 14:41:03,504 20 loss=0.011611091103494797
2019-01-18 14:41:03,505 21 loss=0.011349394137594615
2019-01-18 14:41:03,505 22 loss=0.011137492013487871
2019-01-18 14:41:03,506 23 loss=0.010965014167966868
2019-01-18 14:41:03,506 24 loss=0.01082396892588931
2019-01-18 14:41:03,506 25 loss=0.010708136846685586
2019-01-18 14:41:03,507 26 loss=0.010612636403324131
2019-01-18 14:41:03,507 27 loss=0.010533608048264241
2019-01-18 14:41:03,508 28 loss=0.010467980971624656
2019-01-18 14:41:03,508 29 loss=0.010413298564591496
2019-01-18 14:41:03,508 30 loss=0.010367586214477186
2019-01-18 14:41:03,509 31 loss=0.010329250078027258
2019-01-18 14:41:03,509 32 loss=0.010296998837271826
2019-01-18 14:41:03,510 33 loss=0.010269782720813374
2019-01-18 14:41:03,510 34 loss=0.010246745642641969
2019-01-18 14:41:03,511 35 loss=0.010227187407291144
2019-01-18 14:41:03,511 36 loss=0.010210533707948052
2019-01-18 14:41:03,512 37 loss=0.010196312203691636
2019-01-18 14:41:03,512 38 loss=0.010184133370164042
2019-01-18 14:41:03,512 39 loss=0.010173675119559385
2019-01-18 14:41:03,513 40 loss=0.010164670411371573
2019-01-18 14:41:03,513 41 loss=0.010156897245919472
2019-01-18 14:41:03,514 42 loss=0.010150170562955812
2019-01-18 14:41:03,514 43 loss=0.010144335668064795
2019-01-18 14:41:03,515 44 loss=0.01013926288752077
2019-01-18 14:41:03,515 45 loss=0.01013484321323514
2019-01-18 14:41:03,516 46 loss=0.010130984747346418
2019-01-18 14:41:03,516 47 loss=0.010127609793880917
2019-01-18 14:41:03,517 48 loss=0.01012465247496063
2019-01-18 14:41:03,517 49 loss=0.010122056772961692
2019-01-18 14:41:03,517 50 loss=0.010119774919135271
2019-01-18 14:41:03,518 final loss=0.010119774919135271
2019-01-18 14:41:03,518 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:03,518 	 Computing Major Stats lazily... 
2019-01-18 14:41:03,518 		 Completed edges=20 good=20 bad=0
2019-01-18 14:41:03,519 Distortion avg=0.10001538114972722 wc=1.2297122210781037 me=1.1123763187225821 mc=1.105482200924833 nan_elements=0
2019-01-18 14:41:03,519 MAP = 1.0
2019-01-18 14:41:03,519 scale=[array([1.])]
2019-01-18 15:21:02,263 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1671.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1671.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:21:02,264 No Model Save selected!
