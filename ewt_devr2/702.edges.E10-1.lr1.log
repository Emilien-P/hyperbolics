2019-01-18 14:42:03,227 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/702.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/702.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:03,228 No Model Save selected!
2019-01-18 14:42:03,229 Loaded Graph data/edges/parsing/ewt/ewt_dev/702.edges with 18 nodes scale=1.0
2019-01-18 14:42:03,229 Building dataset
2019-01-18 14:42:03,230 Subsample: 18 points with scale 1.0 subsample=17
2019-01-18 14:42:03,249 Built Data Sampler
2019-01-18 14:42:03,249 Creating a fresh model warm_start?=None
2019-01-18 14:42:03,249 	 Warmstarting? None None 18
2019-01-18 14:42:03,249 Embedding() torch.Size([18, 10])
2019-01-18 14:42:03,249 relative No Rescale
2019-01-18 14:42:03,250 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:03,250 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:03,250 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:03,250 	 Computing Major Stats lazily... 
2019-01-18 14:42:03,252 		 Completed edges=306 good=306 bad=0
2019-01-18 14:42:03,255 Distortion avg=0.9983063328301883 wc=14.192188806355741 me=0.007220294729497291 mc=1965.596881852476 nan_elements=0
2019-01-18 14:42:03,255 MAP = 0.2383230649162021
2019-01-18 14:42:03,255 scale=[array([1.])]
2019-01-18 14:42:03,255 *** End Initial Checkpoint

2019-01-18 14:42:03,312 1 loss=0.9966168465629685
2019-01-18 14:42:03,313 2 loss=0.922138786096271
2019-01-18 14:42:03,314 3 loss=0.854448928502958
2019-01-18 14:42:03,314 4 loss=0.7952379047824236
2019-01-18 14:42:03,315 5 loss=0.7436245411316679
2019-01-18 14:42:03,316 6 loss=0.6985849796941156
2019-01-18 14:42:03,316 7 loss=0.6591774124098262
2019-01-18 14:42:03,317 8 loss=0.6245790789828718
2019-01-18 14:42:03,318 9 loss=0.5940846529241222
2019-01-18 14:42:03,318 10 loss=0.5670945751080367
2019-01-18 14:42:03,319 11 loss=0.5431012729569044
2019-01-18 14:42:03,320 12 loss=0.5216758599097997
2019-01-18 14:42:03,320 13 loss=0.5024561679081146
2019-01-18 14:42:03,321 14 loss=0.4851363199444498
2019-01-18 14:42:03,322 15 loss=0.46945779763899154
2019-01-18 14:42:03,323 16 loss=0.45520186406595553
2019-01-18 14:42:03,323 17 loss=0.4421831742743118
2019-01-18 14:42:03,324 18 loss=0.43024440721782625
2019-01-18 14:42:03,325 19 loss=0.41925176618660387
2019-01-18 14:42:03,325 20 loss=0.40909121246001284
2019-01-18 14:42:03,326 21 loss=0.39966531510606346
2019-01-18 14:42:03,326 22 loss=0.39089061697120947
2019-01-18 14:42:03,327 23 loss=0.38269543226285824
2019-01-18 14:42:03,328 24 loss=0.3750180045403496
2019-01-18 14:42:03,328 25 loss=0.36780496545180563
2019-01-18 14:42:03,329 26 loss=0.3610100443441421
2019-01-18 14:42:03,330 27 loss=0.35459298713126336
2019-01-18 14:42:03,330 28 loss=0.3485186497357865
2019-01-18 14:42:03,331 29 loss=0.34275623721550175
2019-01-18 14:42:03,332 30 loss=0.3372786645210651
2019-01-18 14:42:03,333 31 loss=0.33206201885861747
2019-01-18 14:42:03,333 32 loss=0.32708510698149507
2019-01-18 14:42:03,334 33 loss=0.3223290735208332
2019-01-18 14:42:03,335 34 loss=0.3177770787801313
2019-01-18 14:42:03,335 35 loss=0.3134140263430441
2019-01-18 14:42:03,336 36 loss=0.30922633244308956
2019-01-18 14:42:03,337 37 loss=0.3052017303738499
2019-01-18 14:42:03,337 38 loss=0.3013291043244871
2019-01-18 14:42:03,338 39 loss=0.2975983479461483
2019-01-18 14:42:03,339 40 loss=0.29400024372165645
2019-01-18 14:42:03,339 41 loss=0.29052635984998
2019-01-18 14:42:03,340 42 loss=0.28716896189001645
2019-01-18 14:42:03,341 43 loss=0.28392093685316955
2019-01-18 14:42:03,341 44 loss=0.280775727805915
2019-01-18 14:42:03,342 45 loss=0.2777272773543582
2019-01-18 14:42:03,343 46 loss=0.27476997864288377
2019-01-18 14:42:03,343 47 loss=0.27189863271685366
2019-01-18 14:42:03,344 48 loss=0.269108411281946
2019-01-18 14:42:03,345 49 loss=0.26639482404595904
2019-01-18 14:42:03,345 50 loss=0.2637536899575794
2019-01-18 14:42:03,345 final loss=0.2637536899575794
2019-01-18 14:42:03,345 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:03,346 	 Computing Major Stats lazily... 
2019-01-18 14:42:03,347 		 Completed edges=306 good=306 bad=0
2019-01-18 14:42:03,350 Distortion avg=0.46246555044915477 wc=10.57504801645524 me=1.84207105203463 mc=5.740846969379786 nan_elements=0
2019-01-18 14:42:03,350 MAP = 0.3299236998174906
2019-01-18 14:42:03,350 scale=[array([1.])]
2019-01-18 15:13:40,481 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/702.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/702.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:13:40,482 No Model Save selected!
