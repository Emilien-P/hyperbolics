2019-01-18 14:40:46,007 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1233.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1233.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:46,007 No Model Save selected!
2019-01-18 14:40:46,009 Loaded Graph data/edges/parsing/ewt/ewt_dev/1233.edges with 5 nodes scale=1.0
2019-01-18 14:40:46,009 Building dataset
2019-01-18 14:40:46,010 Subsample: 5 points with scale 1.0 subsample=4
2019-01-18 14:40:46,013 Built Data Sampler
2019-01-18 14:40:46,014 Creating a fresh model warm_start?=None
2019-01-18 14:40:46,014 	 Warmstarting? None None 5
2019-01-18 14:40:46,014 Embedding() torch.Size([5, 10])
2019-01-18 14:40:46,014 relative No Rescale
2019-01-18 14:40:46,014 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:46,015 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:46,015 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:46,015 	 Computing Major Stats lazily... 
2019-01-18 14:40:46,015 		 Completed edges=20 good=20 bad=0
2019-01-18 14:40:46,016 Distortion avg=0.9967215143566446 wc=3.26429954782084 me=0.005628252251848828 mc=579.9845852233344 nan_elements=0
2019-01-18 14:40:46,016 MAP = 0.4666666666666666
2019-01-18 14:40:46,017 scale=[array([1.])]
2019-01-18 14:40:46,017 *** End Initial Checkpoint

2019-01-18 14:40:46,074 1 loss=0.9934557708423654
2019-01-18 14:40:46,075 2 loss=0.31325420002132776
2019-01-18 14:40:46,075 3 loss=0.19965912479249623
2019-01-18 14:40:46,076 4 loss=0.1354470408350513
2019-01-18 14:40:46,076 5 loss=0.09410374813156214
2019-01-18 14:40:46,076 6 loss=0.06724310757608973
2019-01-18 14:40:46,077 7 loss=0.04971216921647029
2019-01-18 14:40:46,077 8 loss=0.038164116018673595
2019-01-18 14:40:46,078 9 loss=0.03043463971625799
2019-01-18 14:40:46,078 10 loss=0.02515118905285792
2019-01-18 14:40:46,079 11 loss=0.021455211044445806
2019-01-18 14:40:46,079 12 loss=0.018810052787481206
2019-01-18 14:40:46,080 13 loss=0.01687651985411015
2019-01-18 14:40:46,080 14 loss=0.015436205515941298
2019-01-18 14:40:46,080 15 loss=0.01434537144574044
2019-01-18 14:40:46,081 16 loss=0.013507267383608332
2019-01-18 14:40:46,081 17 loss=0.012855329454479347
2019-01-18 14:40:46,082 18 loss=0.012342800911071507
2019-01-18 14:40:46,082 19 loss=0.011936194128025436
2019-01-18 14:40:46,083 20 loss=0.011611091103494797
2019-01-18 14:40:46,083 21 loss=0.011349394137594615
2019-01-18 14:40:46,084 22 loss=0.011137492013487871
2019-01-18 14:40:46,085 23 loss=0.010965014167966868
2019-01-18 14:40:46,085 24 loss=0.01082396892588931
2019-01-18 14:40:46,085 25 loss=0.010708136846685586
2019-01-18 14:40:46,086 26 loss=0.010612636403324131
2019-01-18 14:40:46,086 27 loss=0.010533608048264241
2019-01-18 14:40:46,087 28 loss=0.010467980971624656
2019-01-18 14:40:46,087 29 loss=0.010413298564591496
2019-01-18 14:40:46,088 30 loss=0.010367586214477186
2019-01-18 14:40:46,088 31 loss=0.010329250078027258
2019-01-18 14:40:46,089 32 loss=0.010296998837271826
2019-01-18 14:40:46,089 33 loss=0.010269782720813374
2019-01-18 14:40:46,089 34 loss=0.010246745642641969
2019-01-18 14:40:46,090 35 loss=0.010227187407291144
2019-01-18 14:40:46,090 36 loss=0.010210533707948052
2019-01-18 14:40:46,091 37 loss=0.010196312203691636
2019-01-18 14:40:46,091 38 loss=0.010184133370164042
2019-01-18 14:40:46,092 39 loss=0.010173675119559385
2019-01-18 14:40:46,092 40 loss=0.010164670411371573
2019-01-18 14:40:46,092 41 loss=0.010156897245919472
2019-01-18 14:40:46,093 42 loss=0.010150170562955812
2019-01-18 14:40:46,093 43 loss=0.010144335668064795
2019-01-18 14:40:46,094 44 loss=0.01013926288752077
2019-01-18 14:40:46,094 45 loss=0.01013484321323514
2019-01-18 14:40:46,095 46 loss=0.010130984747346418
2019-01-18 14:40:46,095 47 loss=0.010127609793880917
2019-01-18 14:40:46,096 48 loss=0.01012465247496063
2019-01-18 14:40:46,096 49 loss=0.010122056772961692
2019-01-18 14:40:46,096 50 loss=0.010119774919135271
2019-01-18 14:40:46,097 final loss=0.010119774919135271
2019-01-18 14:40:46,097 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:46,097 	 Computing Major Stats lazily... 
2019-01-18 14:40:46,097 		 Completed edges=20 good=20 bad=0
2019-01-18 14:40:46,098 Distortion avg=0.10001538114972722 wc=1.2297122210781037 me=1.1123763187225821 mc=1.105482200924833 nan_elements=0
2019-01-18 14:40:46,098 MAP = 1.0
2019-01-18 14:40:46,098 scale=[array([1.])]
2019-01-18 15:14:05,134 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1233.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1233.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:14:05,135 No Model Save selected!
