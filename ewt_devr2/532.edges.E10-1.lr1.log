2019-01-18 14:42:58,405 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/532.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/532.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:58,405 No Model Save selected!
2019-01-18 14:42:58,406 Loaded Graph data/edges/parsing/ewt/ewt_dev/532.edges with 2 nodes scale=1.0
2019-01-18 14:42:58,406 Building dataset
2019-01-18 14:42:58,407 Subsample: 2 points with scale 1.0 subsample=1
2019-01-18 14:42:58,408 Built Data Sampler
2019-01-18 14:42:58,408 Creating a fresh model warm_start?=None
2019-01-18 14:42:58,408 	 Warmstarting? None None 2
2019-01-18 14:42:58,409 Embedding() torch.Size([2, 10])
2019-01-18 14:42:58,409 relative No Rescale
2019-01-18 14:42:58,409 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:58,410 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:58,410 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:58,410 	 Computing Major Stats lazily... 
2019-01-18 14:42:58,410 		 Completed edges=2 good=2 bad=0
2019-01-18 14:42:58,411 Distortion avg=0.9965968412004117 wc=1.0 me=0.00340315879958833 mc=293.8446481313088 nan_elements=0
2019-01-18 14:42:58,411 MAP = 1.0
2019-01-18 14:42:58,411 scale=[array([1.])]
2019-01-18 14:42:58,411 *** End Initial Checkpoint

2019-01-18 14:42:58,469 1 loss=0.9932052638906386
2019-01-18 14:42:58,470 2 loss=8.938847375015749
2019-01-18 14:42:58,470 3 loss=48.57214009192693
2019-01-18 14:42:58,470 4 loss=357.51680197769787
2019-01-18 14:42:58,471 5 loss=2994.7538412503473
2019-01-18 14:42:58,471 6 loss=26300.09244160632
2019-01-18 14:42:58,472 7 loss=234758.7555855165
2019-01-18 14:42:58,472 8 loss=2107018.5711028273
2019-01-18 14:42:58,472 9 loss=18945752.452424984
2019-01-18 14:42:58,473 10 loss=170459544.00932342
2019-01-18 14:42:58,473 11 loss=1533979227.8964074
2019-01-18 14:42:58,474 12 loss=13805343062.505152
2019-01-18 14:42:58,474 13 loss=124246677612.85883
2019-01-18 14:42:58,475 14 loss=1118215868682.6665
2019-01-18 14:42:58,475 15 loss=10063930128660.81
2019-01-18 14:42:58,475 16 loss=90575333089513.72
2019-01-18 14:42:58,476 17 loss=815177883600338.8
2019-01-18 14:42:58,476 18 loss=7336600609787212.0
2019-01-18 14:42:58,477 19 loss=6.60294044602374e+16
2019-01-18 14:42:58,477 20 loss=5.94264637058594e+17
2019-01-18 14:42:58,478 21 loss=5.348381724276721e+18
2019-01-18 14:42:58,478 22 loss=4.81354354907386e+19
2019-01-18 14:42:58,478 23 loss=4.332189193333917e+20
2019-01-18 14:42:58,479 24 loss=3.898970273750758e+21
2019-01-18 14:42:58,479 25 loss=3.509073246300752e+22
2019-01-18 14:42:58,480 26 loss=3.158165921648198e+23
2019-01-18 14:42:58,480 27 loss=2.842349329476635e+24
2019-01-18 14:42:58,481 28 loss=2.5581143965269464e+25
2019-01-18 14:42:58,481 29 loss=2.3023029568736446e+26
2019-01-18 14:42:58,482 30 loss=2.072072661186098e+27
2019-01-18 14:42:58,482 31 loss=1.8648653950674335e+28
2019-01-18 14:42:58,482 32 loss=1.678378855560674e+29
2019-01-18 14:42:58,483 33 loss=1.5105409700046018e+30
2019-01-18 14:42:58,483 34 loss=1.3594868730041399e+31
2019-01-18 14:42:58,484 35 loss=1.2235381857037259e+32
2019-01-18 14:42:58,484 36 loss=1.1011843671333534e+33
2019-01-18 14:42:58,484 37 loss=9.91065930420018e+33
2019-01-18 14:42:58,485 38 loss=8.91959337378016e+34
2019-01-18 14:42:58,485 39 loss=8.027634036402146e+35
2019-01-18 14:42:58,486 40 loss=7.224870632761931e+36
2019-01-18 14:42:58,486 41 loss=6.502383569485739e+37
2019-01-18 14:42:58,486 42 loss=5.852145212537165e+38
2019-01-18 14:42:58,487 43 loss=5.266930691283448e+39
2019-01-18 14:42:58,487 44 loss=4.740237622155103e+40
2019-01-18 14:42:58,488 45 loss=4.2662138599395935e+41
2019-01-18 14:42:58,488 46 loss=3.839592473945634e+42
2019-01-18 14:42:58,489 47 loss=3.4556332265510695e+43
2019-01-18 14:42:58,489 48 loss=3.1100699038959636e+44
2019-01-18 14:42:58,489 49 loss=2.7990629135063678e+45
2019-01-18 14:42:58,490 50 loss=2.519156622155731e+46
2019-01-18 14:42:58,490 final loss=2.519156622155731e+46
2019-01-18 14:42:58,490 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:58,490 	 Computing Major Stats lazily... 
2019-01-18 14:42:58,490 		 Completed edges=2 good=2 bad=0
2019-01-18 14:42:58,491 Distortion avg=4.7615553760721484e+23 wc=1.0 me=4.7615553760721484e+23 mc=2.1001540904579576e-24 nan_elements=0
2019-01-18 14:42:58,491 MAP = 1.0
2019-01-18 14:42:58,491 scale=[array([1.])]
2019-01-18 15:16:50,682 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/532.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/532.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:16:50,683 No Model Save selected!
