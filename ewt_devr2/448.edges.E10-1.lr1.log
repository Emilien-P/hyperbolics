2019-01-18 14:42:46,800 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/448.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/448.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:46,800 No Model Save selected!
2019-01-18 14:42:46,801 Loaded Graph data/edges/parsing/ewt/ewt_dev/448.edges with 6 nodes scale=1.0
2019-01-18 14:42:46,801 Building dataset
2019-01-18 14:42:46,802 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:42:46,806 Built Data Sampler
2019-01-18 14:42:46,806 Creating a fresh model warm_start?=None
2019-01-18 14:42:46,806 	 Warmstarting? None None 6
2019-01-18 14:42:46,807 Embedding() torch.Size([6, 10])
2019-01-18 14:42:46,807 relative No Rescale
2019-01-18 14:42:46,807 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:46,807 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:46,807 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:46,808 	 Computing Major Stats lazily... 
2019-01-18 14:42:46,808 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:46,809 Distortion avg=0.9970831198655035 wc=5.448327215027938 me=0.005628252251848828 mc=968.0318100949036 nan_elements=0
2019-01-18 14:42:46,810 MAP = 0.3673611111111111
2019-01-18 14:42:46,810 scale=[array([1.])]
2019-01-18 14:42:46,810 *** End Initial Checkpoint

2019-01-18 14:42:46,869 1 loss=0.9941769604494649
2019-01-18 14:42:46,870 2 loss=0.4635441691317516
2019-01-18 14:42:46,871 3 loss=0.31525202916545497
2019-01-18 14:42:46,871 4 loss=0.2517268731485578
2019-01-18 14:42:46,872 5 loss=0.21108416500882515
2019-01-18 14:42:46,872 6 loss=0.18122722499383753
2019-01-18 14:42:46,873 7 loss=0.15828918155714375
2019-01-18 14:42:46,873 8 loss=0.14019266646627662
2019-01-18 14:42:46,874 9 loss=0.12550308167145674
2019-01-18 14:42:46,874 10 loss=0.11318669104455176
2019-01-18 14:42:46,874 11 loss=0.10252813523786034
2019-01-18 14:42:46,875 12 loss=0.09306576654852697
2019-01-18 14:42:46,875 13 loss=0.08452511825515988
2019-01-18 14:42:46,876 14 loss=0.07675588495114484
2019-01-18 14:42:46,876 15 loss=0.06967971253491857
2019-01-18 14:42:46,877 16 loss=0.0632525585402023
2019-01-18 14:42:46,877 17 loss=0.05744144103188922
2019-01-18 14:42:46,878 18 loss=0.052212746174625034
2019-01-18 14:42:46,878 19 loss=0.04752828453739764
2019-01-18 14:42:46,879 20 loss=0.04334560099376466
2019-01-18 14:42:46,879 21 loss=0.039619999109477076
2019-01-18 14:42:46,880 22 loss=0.03630677978243646
2019-01-18 14:42:46,880 23 loss=0.033363008998340674
2019-01-18 14:42:46,880 24 loss=0.03074863971179027
2019-01-18 14:42:46,881 25 loss=0.02842706533267041
2019-01-18 14:42:46,881 26 loss=0.026365265958174792
2019-01-18 14:42:46,882 27 loss=0.024533704009314372
2019-01-18 14:42:46,882 28 loss=0.022906088152048924
2019-01-18 14:42:46,883 29 loss=0.021459083027150206
2019-01-18 14:42:46,883 30 loss=0.020172009485091808
2019-01-18 14:42:46,884 31 loss=0.019026558031349557
2019-01-18 14:42:46,884 32 loss=0.01800652516614223
2019-01-18 14:42:46,885 33 loss=0.0170975753889407
2019-01-18 14:42:46,885 34 loss=0.01628702836812967
2019-01-18 14:42:46,886 35 loss=0.015563669454023217
2019-01-18 14:42:46,886 36 loss=0.014917581327572975
2019-01-18 14:42:46,886 37 loss=0.014339994590273334
2019-01-18 14:42:46,887 38 loss=0.01382315525708787
2019-01-18 14:42:46,887 39 loss=0.013360207305555448
2019-01-18 14:42:46,888 40 loss=0.012945088621465824
2019-01-18 14:42:46,888 41 loss=0.01257243885380919
2019-01-18 14:42:46,889 42 loss=0.012237517848009666
2019-01-18 14:42:46,889 43 loss=0.011936133468046008
2019-01-18 14:42:46,890 44 loss=0.011664577746325329
2019-01-18 14:42:46,890 45 loss=0.011419570416146116
2019-01-18 14:42:46,890 46 loss=0.011198208986084942
2019-01-18 14:42:46,891 47 loss=0.01099792460941962
2019-01-18 14:42:46,891 48 loss=0.010816443085544117
2019-01-18 14:42:46,892 49 loss=0.01065175040505719
2019-01-18 14:42:46,892 50 loss=0.010502062316664005
2019-01-18 14:42:46,892 final loss=0.010502062316664005
2019-01-18 14:42:46,892 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:46,892 	 Computing Major Stats lazily... 
2019-01-18 14:42:46,893 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:46,894 Distortion avg=0.09637164205233899 wc=1.3000620645469332 me=1.1333394231795701 mc=1.1471074225050997 nan_elements=0
2019-01-18 14:42:46,894 MAP = 1.0
2019-01-18 14:42:46,894 scale=[array([1.])]
2019-01-18 15:18:11,981 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/448.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/448.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:18:11,982 No Model Save selected!
