2019-01-18 14:42:34,298 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1368.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1368.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:34,298 No Model Save selected!
2019-01-18 14:42:34,300 Loaded Graph data/edges/parsing/ewt/ewt_dev/1368.edges with 17 nodes scale=1.0
2019-01-18 14:42:34,300 Building dataset
2019-01-18 14:42:34,301 Subsample: 17 points with scale 1.0 subsample=16
2019-01-18 14:42:34,317 Built Data Sampler
2019-01-18 14:42:34,317 Creating a fresh model warm_start?=None
2019-01-18 14:42:34,318 	 Warmstarting? None None 17
2019-01-18 14:42:34,318 Embedding() torch.Size([17, 10])
2019-01-18 14:42:34,318 relative No Rescale
2019-01-18 14:42:34,318 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:34,319 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:34,319 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:34,319 	 Computing Major Stats lazily... 
2019-01-18 14:42:34,320 		 Completed edges=272 good=272 bad=0
2019-01-18 14:42:34,323 Distortion avg=0.9980482170321343 wc=10.365282186826944 me=0.005941110731069004 mc=1744.670762088604 nan_elements=0
2019-01-18 14:42:34,323 MAP = 0.17751059631311733
2019-01-18 14:42:34,324 scale=[array([1.])]
2019-01-18 14:42:34,324 *** End Initial Checkpoint

2019-01-18 14:42:34,381 1 loss=0.9961013781322473
2019-01-18 14:42:34,382 2 loss=0.8917265308856193
2019-01-18 14:42:34,382 3 loss=0.8017550599765358
2019-01-18 14:42:34,383 4 loss=0.7265903268585869
2019-01-18 14:42:34,383 5 loss=0.6634492942274213
2019-01-18 14:42:34,384 6 loss=0.6099360617104019
2019-01-18 14:42:34,385 7 loss=0.5641487744238579
2019-01-18 14:42:34,385 8 loss=0.524602543923051
2019-01-18 14:42:34,386 9 loss=0.49014093759929517
2019-01-18 14:42:34,387 10 loss=0.4598608562531327
2019-01-18 14:42:34,387 11 loss=0.43305323901829146
2019-01-18 14:42:34,388 12 loss=0.4091574862596964
2019-01-18 14:42:34,389 13 loss=0.3877268129755369
2019-01-18 14:42:34,389 14 loss=0.3684020256532731
2019-01-18 14:42:34,390 15 loss=0.3508916910847044
2019-01-18 14:42:34,391 16 loss=0.3349571196419165
2019-01-18 14:42:34,391 17 loss=0.3204009630467733
2019-01-18 14:42:34,392 18 loss=0.3070585236327458
2019-01-18 14:42:34,393 19 loss=0.29479109941502996
2019-01-18 14:42:34,393 20 loss=0.2834808607400143
2019-01-18 14:42:34,394 21 loss=0.2730268825293565
2019-01-18 14:42:34,394 22 loss=0.2633420516077064
2019-01-18 14:42:34,395 23 loss=0.25435063950993925
2019-01-18 14:42:34,396 24 loss=0.24598638378124238
2019-01-18 14:42:34,396 25 loss=0.23819095984116753
2019-01-18 14:42:34,397 26 loss=0.2309127545099833
2019-01-18 14:42:34,398 27 loss=0.22410587390975112
2019-01-18 14:42:34,399 28 loss=0.2177293345872964
2019-01-18 14:42:34,399 29 loss=0.21174639878727775
2019-01-18 14:42:34,400 30 loss=0.20612402388076384
2019-01-18 14:42:34,401 31 loss=0.20083240280129225
2019-01-18 14:42:34,401 32 loss=0.1958445775260624
2019-01-18 14:42:34,402 33 loss=0.19113611158517324
2019-01-18 14:42:34,402 34 loss=0.18668481059751008
2019-01-18 14:42:34,403 35 loss=0.18247048214838715
2019-01-18 14:42:34,404 36 loss=0.1784747281125796
2019-01-18 14:42:34,405 37 loss=0.1746807639145342
2019-01-18 14:42:34,405 38 loss=0.1710732603007846
2019-01-18 14:42:34,406 39 loss=0.16763820404953572
2019-01-18 14:42:34,407 40 loss=0.16436277471296554
2019-01-18 14:42:34,407 41 loss=0.16123523501980602
2019-01-18 14:42:34,408 42 loss=0.15824483299014225
2019-01-18 14:42:34,409 43 loss=0.15538171415468124
2019-01-18 14:42:34,409 44 loss=0.15263684254501644
2019-01-18 14:42:34,410 45 loss=0.15000192934350295
2019-01-18 14:42:34,411 46 loss=0.14746936826194226
2019-01-18 14:42:34,411 47 loss=0.14503217686566922
2019-01-18 14:42:34,412 48 loss=0.14268394318030414
2019-01-18 14:42:34,413 49 loss=0.1404187770174887
2019-01-18 14:42:34,413 50 loss=0.13823126553740314
2019-01-18 14:42:34,413 final loss=0.13823126553740314
2019-01-18 14:42:34,413 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:34,413 	 Computing Major Stats lazily... 
2019-01-18 14:42:34,415 		 Completed edges=272 good=272 bad=0
2019-01-18 14:42:34,417 Distortion avg=0.3193183317098409 wc=6.5667603726874 me=1.6822172255077885 mc=3.903634009398031 nan_elements=0
2019-01-18 14:42:34,418 MAP = 0.6569027611044418
2019-01-18 14:42:34,418 scale=[array([1.])]
2019-01-18 15:19:13,189 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1368.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1368.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:19:13,190 No Model Save selected!
