2019-01-18 14:40:30,700 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/720.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/720.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:30,700 No Model Save selected!
2019-01-18 14:40:30,702 Loaded Graph data/edges/parsing/ewt/ewt_dev/720.edges with 53 nodes scale=1.0
2019-01-18 14:40:30,702 Building dataset
2019-01-18 14:40:30,702 Subsample: 53 points with scale 1.0 subsample=52
2019-01-18 14:40:30,807 Built Data Sampler
2019-01-18 14:40:30,807 Creating a fresh model warm_start?=None
2019-01-18 14:40:30,807 	 Warmstarting? None None 53
2019-01-18 14:40:30,808 Embedding() torch.Size([53, 10])
2019-01-18 14:40:30,808 relative No Rescale
2019-01-18 14:40:30,808 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:30,808 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:30,809 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:30,809 	 Computing Major Stats lazily... 
2019-01-18 14:40:30,819 		 Completed edges=2756 good=2756 bad=0
2019-01-18 14:40:30,828 Distortion avg=0.9988049016771037 wc=19.95524410067428 me=0.006076232527856744 mc=3284.147538657979 nan_elements=0
2019-01-18 14:40:30,828 MAP = 0.0736542408070676
2019-01-18 14:40:30,829 scale=[array([1.])]
2019-01-18 14:40:30,829 *** End Initial Checkpoint

2019-01-18 14:40:30,889 1 loss=0.9976119295985207
2019-01-18 14:40:30,891 2 loss=0.9861218665291
2019-01-18 14:40:30,893 3 loss=0.974504706953148
2019-01-18 14:40:30,895 4 loss=0.9630502068181483
2019-01-18 14:40:30,897 5 loss=0.951805394399048
2019-01-18 14:40:30,900 6 loss=0.9407836418189167
2019-01-18 14:40:30,902 7 loss=0.9299884433064797
2019-01-18 14:40:30,905 8 loss=0.9194192733187696
2019-01-18 14:40:30,907 9 loss=0.9090736644105019
2019-01-18 14:40:30,909 10 loss=0.8989481160581159
2019-01-18 14:40:30,911 11 loss=0.8890385503171698
2019-01-18 14:40:30,914 12 loss=0.8793405631790473
2019-01-18 14:40:30,916 13 loss=0.8698495732389065
2019-01-18 14:40:30,918 14 loss=0.8605609143216446
2019-01-18 14:40:30,921 15 loss=0.8514698954881681
2019-01-18 14:40:30,923 16 loss=0.8425718410479923
2019-01-18 14:40:30,925 17 loss=0.8338621177885736
2019-01-18 14:40:30,927 18 loss=0.8253361537408622
2019-01-18 14:40:30,930 19 loss=0.8169894511752142
2019-01-18 14:40:30,932 20 loss=0.8088175955668605
2019-01-18 14:40:30,934 21 loss=0.8008162616875427
2019-01-18 14:40:30,936 22 loss=0.7929812176125868
2019-01-18 14:40:30,939 23 loss=0.785308327194358
2019-01-18 14:40:30,941 24 loss=0.777793551394409
2019-01-18 14:40:30,943 25 loss=0.7704329487586259
2019-01-18 14:40:30,945 26 loss=0.7632226752446662
2019-01-18 14:40:30,947 27 loss=0.7561589835578844
2019-01-18 14:40:30,950 28 loss=0.7492382221137693
2019-01-18 14:40:30,952 29 loss=0.7424568337170432
2019-01-18 14:40:30,954 30 loss=0.7358113540269352
2019-01-18 14:40:30,956 31 loss=0.7292984098626983
2019-01-18 14:40:30,958 32 loss=0.722914717391709
2019-01-18 14:40:30,961 33 loss=0.7166570802335303
2019-01-18 14:40:30,963 34 loss=0.7105223875063748
2019-01-18 14:40:30,965 35 loss=0.7045076118370128
2019-01-18 14:40:30,967 36 loss=0.6986098073508955
2019-01-18 14:40:30,970 37 loss=0.6928261076559247
2019-01-18 14:40:30,972 38 loss=0.6871537238306002
2019-01-18 14:40:30,975 39 loss=0.6815899424251326
2019-01-18 14:40:30,977 40 loss=0.676132123482373
2019-01-18 14:40:30,979 41 loss=0.6707776985840103
2019-01-18 14:40:30,981 42 loss=0.6655241689263385
2019-01-18 14:40:30,984 43 loss=0.6603691034289665
2019-01-18 14:40:30,986 44 loss=0.6553101368790755
2019-01-18 14:40:30,988 45 loss=0.6503449681132029
2019-01-18 14:40:30,990 46 loss=0.6454713582380057
2019-01-18 14:40:30,993 47 loss=0.6406871288910476
2019-01-18 14:40:30,995 48 loss=0.6359901605422696
2019-01-18 14:40:30,997 49 loss=0.6313783908365503
2019-01-18 14:40:30,999 50 loss=0.626849812977485
2019-01-18 14:40:30,999 final loss=0.626849812977485
2019-01-18 14:40:30,999 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:30,999 	 Computing Major Stats lazily... 
2019-01-18 14:40:31,009 		 Completed edges=2756 good=2756 bad=0
2019-01-18 14:40:31,018 Distortion avg=0.7704538851915069 wc=37.767194838655314 me=1.4706155360584758 mc=25.681215730848624 nan_elements=0
2019-01-18 14:40:31,018 MAP = 0.038165594062693195
2019-01-18 14:40:31,018 scale=[array([1.])]
2019-01-18 15:16:12,242 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/720.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/720.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:16:12,244 No Model Save selected!
