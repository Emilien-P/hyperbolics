2019-01-18 14:40:25,652 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1441.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1441.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:25,652 No Model Save selected!
2019-01-18 14:40:25,654 Loaded Graph data/edges/parsing/ewt/ewt_dev/1441.edges with 15 nodes scale=1.0
2019-01-18 14:40:25,654 Building dataset
2019-01-18 14:40:25,654 Subsample: 15 points with scale 1.0 subsample=14
2019-01-18 14:40:25,668 Built Data Sampler
2019-01-18 14:40:25,669 Creating a fresh model warm_start?=None
2019-01-18 14:40:25,669 	 Warmstarting? None None 15
2019-01-18 14:40:25,669 Embedding() torch.Size([15, 10])
2019-01-18 14:40:25,669 relative No Rescale
2019-01-18 14:40:25,669 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:25,670 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:25,670 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:25,670 	 Computing Major Stats lazily... 
2019-01-18 14:40:25,671 		 Completed edges=210 good=210 bad=0
2019-01-18 14:40:25,674 Distortion avg=0.9980339816717586 wc=7.892371214058059 me=0.0059960279104134965 mc=1316.266590479194 nan_elements=0
2019-01-18 14:40:25,674 MAP = 0.2715957745957746
2019-01-18 14:40:25,674 scale=[array([1.])]
2019-01-18 14:40:25,674 *** End Initial Checkpoint

2019-01-18 14:40:25,731 1 loss=0.996073052535426
2019-01-18 14:40:25,732 2 loss=0.879690523581433
2019-01-18 14:40:25,733 3 loss=0.781337299311994
2019-01-18 14:40:25,734 4 loss=0.7017829529681432
2019-01-18 14:40:25,734 5 loss=0.6370906403942787
2019-01-18 14:40:25,735 6 loss=0.5839015790667691
2019-01-18 14:40:25,735 7 loss=0.539614575606434
2019-01-18 14:40:25,736 8 loss=0.5022570871130474
2019-01-18 14:40:25,737 9 loss=0.47034054390957275
2019-01-18 14:40:25,737 10 loss=0.44274043421621273
2019-01-18 14:40:25,738 11 loss=0.41860384912927323
2019-01-18 14:40:25,738 12 loss=0.3972800511870399
2019-01-18 14:40:25,739 13 loss=0.37826890652627365
2019-01-18 14:40:25,739 14 loss=0.36118275776304476
2019-01-18 14:40:25,740 15 loss=0.34571826884683726
2019-01-18 14:40:25,741 16 loss=0.33163561960876364
2019-01-18 14:40:25,741 17 loss=0.3187431022820652
2019-01-18 14:40:25,742 18 loss=0.3068856862025861
2019-01-18 14:40:25,742 19 loss=0.29593649987962906
2019-01-18 14:40:25,743 20 loss=0.2857904616947103
2019-01-18 14:40:25,744 21 loss=0.27635949691725564
2019-01-18 14:40:25,744 22 loss=0.267568929320971
2019-01-18 14:40:25,745 23 loss=0.25935474540954706
2019-01-18 14:40:25,746 24 loss=0.2516615092131957
2019-01-18 14:40:25,746 25 loss=0.2444407639350897
2019-01-18 14:40:25,747 26 loss=0.23764979933582228
2019-01-18 14:40:25,747 27 loss=0.2312506949452837
2019-01-18 14:40:25,748 28 loss=0.22520957209986314
2019-01-18 14:40:25,749 29 loss=0.21949600467354344
2019-01-18 14:40:25,749 30 loss=0.21408255083721445
2019-01-18 14:40:25,750 31 loss=0.208944377425336
2019-01-18 14:40:25,750 32 loss=0.2040589553727716
2019-01-18 14:40:25,751 33 loss=0.19940580983305056
2019-01-18 14:40:25,752 34 loss=0.19496631245905024
2019-01-18 14:40:25,752 35 loss=0.19072350625201354
2019-01-18 14:40:25,753 36 loss=0.18666195560957383
2019-01-18 14:40:25,753 37 loss=0.18276761590755733
2019-01-18 14:40:25,754 38 loss=0.1790277182655431
2019-01-18 14:40:25,755 39 loss=0.1754306661691163
2019-01-18 14:40:25,755 40 loss=0.17196594142318936
2019-01-18 14:40:25,756 41 loss=0.16862401754230064
2019-01-18 14:40:25,757 42 loss=0.1653962791830297
2019-01-18 14:40:25,757 43 loss=0.16227494661795253
2019-01-18 14:40:25,758 44 loss=0.1592530045599614
2019-01-18 14:40:25,758 45 loss=0.15632413488522812
2019-01-18 14:40:25,759 46 loss=0.15348265298405356
2019-01-18 14:40:25,759 47 loss=0.15072344760052306
2019-01-18 14:40:25,760 48 loss=0.1480419241120306
2019-01-18 14:40:25,761 49 loss=0.1454339512552367
2019-01-18 14:40:25,761 50 loss=0.14289581133218804
2019-01-18 14:40:25,761 final loss=0.14289581133218804
2019-01-18 14:40:25,761 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:25,761 	 Computing Major Stats lazily... 
2019-01-18 14:40:25,763 		 Completed edges=210 good=210 bad=0
2019-01-18 14:40:25,765 Distortion avg=0.32632157801019257 wc=5.121578014715083 me=1.5520518118973012 mc=3.299875671324545 nan_elements=0
2019-01-18 14:40:25,765 MAP = 0.7294973544973545
2019-01-18 14:40:25,765 scale=[array([1.])]
2019-01-18 15:19:00,710 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1441.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1441.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:19:00,711 No Model Save selected!
