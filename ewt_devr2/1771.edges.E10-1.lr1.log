2019-01-18 14:42:00,811 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1771.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1771.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:00,812 No Model Save selected!
2019-01-18 14:42:00,813 Loaded Graph data/edges/parsing/ewt/ewt_dev/1771.edges with 5 nodes scale=1.0
2019-01-18 14:42:00,813 Building dataset
2019-01-18 14:42:00,814 Subsample: 5 points with scale 1.0 subsample=4
2019-01-18 14:42:00,817 Built Data Sampler
2019-01-18 14:42:00,817 Creating a fresh model warm_start?=None
2019-01-18 14:42:00,817 	 Warmstarting? None None 5
2019-01-18 14:42:00,818 Embedding() torch.Size([5, 10])
2019-01-18 14:42:00,818 relative No Rescale
2019-01-18 14:42:00,818 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:00,818 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:00,819 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:00,819 	 Computing Major Stats lazily... 
2019-01-18 14:42:00,819 		 Completed edges=20 good=20 bad=0
2019-01-18 14:42:00,820 Distortion avg=0.9969002441147186 wc=4.7900427106326955 me=0.005628252251848828 mc=851.0710778926463 nan_elements=0
2019-01-18 14:42:00,820 MAP = 0.6611111111111111
2019-01-18 14:42:00,821 scale=[array([1.])]
2019-01-18 14:42:00,821 *** End Initial Checkpoint

2019-01-18 14:42:00,882 1 loss=0.993812299892074
2019-01-18 14:42:00,883 2 loss=0.35037834422263336
2019-01-18 14:42:00,883 3 loss=0.24634382556406975
2019-01-18 14:42:00,884 4 loss=0.19762130609783943
2019-01-18 14:42:00,884 5 loss=0.16107071683231505
2019-01-18 14:42:00,885 6 loss=0.13244400289502814
2019-01-18 14:42:00,885 7 loss=0.10987192124307428
2019-01-18 14:42:00,886 8 loss=0.09185258314478932
2019-01-18 14:42:00,886 9 loss=0.07726202920209826
2019-01-18 14:42:00,886 10 loss=0.0653302446286079
2019-01-18 14:42:00,887 11 loss=0.05552918216253425
2019-01-18 14:42:00,887 12 loss=0.04746806392913703
2019-01-18 14:42:00,888 13 loss=0.04083335688397818
2019-01-18 14:42:00,888 14 loss=0.03536399305357389
2019-01-18 14:42:00,889 15 loss=0.030842572541917745
2019-01-18 14:42:00,889 16 loss=0.027090534093217468
2019-01-18 14:42:00,889 17 loss=0.023963160031822014
2019-01-18 14:42:00,890 18 loss=0.02134412841428852
2019-01-18 14:42:00,890 19 loss=0.01914025169664139
2019-01-18 14:42:00,891 20 loss=0.01727686552925796
2019-01-18 14:42:00,891 21 loss=0.015694014439960415
2019-01-18 14:42:00,892 22 loss=0.014343391439147497
2019-01-18 14:42:00,892 23 loss=0.013185917891916
2019-01-18 14:42:00,892 24 loss=0.01218984129120951
2019-01-18 14:42:00,893 25 loss=0.011329242864505247
2019-01-18 14:42:00,893 26 loss=0.010582866323853014
2019-01-18 14:42:00,894 27 loss=0.009933197158080118
2019-01-18 14:42:00,894 28 loss=0.00936573704385635
2019-01-18 14:42:00,895 29 loss=0.008868430183450559
2019-01-18 14:42:00,895 30 loss=0.008431208051523137
2019-01-18 14:42:00,896 31 loss=0.008045626603440114
2019-01-18 14:42:00,896 32 loss=0.007704575877885545
2019-01-18 14:42:00,896 33 loss=0.007402046470805566
2019-01-18 14:42:00,897 34 loss=0.0071329408577113715
2019-01-18 14:42:00,897 35 loss=0.006892920232198988
2019-01-18 14:42:00,898 36 loss=0.006678279596324725
2019-01-18 14:42:00,898 37 loss=0.006485845428552868
2019-01-18 14:42:00,899 38 loss=0.006312891479719888
2019-01-18 14:42:00,899 39 loss=0.0061570691930560905
2019-01-18 14:42:00,899 40 loss=0.006016349976606024
2019-01-18 14:42:00,900 41 loss=0.005888977125514116
2019-01-18 14:42:00,900 42 loss=0.00577342563568726
2019-01-18 14:42:00,901 43 loss=0.0056683684982676815
2019-01-18 14:42:00,901 44 loss=0.005572648338161545
2019-01-18 14:42:00,902 45 loss=0.005485253476346493
2019-01-18 14:42:00,902 46 loss=0.005405297667623371
2019-01-18 14:42:00,902 47 loss=0.0053320029026847834
2019-01-18 14:42:00,903 48 loss=0.005264684773369862
2019-01-18 14:42:00,903 49 loss=0.00520273998855933
2019-01-18 14:42:00,904 50 loss=0.005145635699822565
2019-01-18 14:42:00,904 final loss=0.005145635699822565
2019-01-18 14:42:00,904 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:00,904 	 Computing Major Stats lazily... 
2019-01-18 14:42:00,904 		 Completed edges=20 good=20 bad=0
2019-01-18 14:42:00,905 Distortion avg=0.06691709709490226 wc=1.193907963915992 me=1.0826822878846882 mc=1.1027315928928818 nan_elements=0
2019-01-18 14:42:00,905 MAP = 1.0
2019-01-18 14:42:00,905 scale=[array([1.])]
2019-01-18 15:13:48,330 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1771.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1771.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:13:48,332 No Model Save selected!
