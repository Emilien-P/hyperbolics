2019-01-18 14:42:06,995 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/173.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/173.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:06,996 No Model Save selected!
2019-01-18 14:42:06,997 Loaded Graph data/edges/parsing/ewt/ewt_dev/173.edges with 7 nodes scale=1.0
2019-01-18 14:42:06,997 Building dataset
2019-01-18 14:42:06,997 Subsample: 7 points with scale 1.0 subsample=6
2019-01-18 14:42:07,002 Built Data Sampler
2019-01-18 14:42:07,003 Creating a fresh model warm_start?=None
2019-01-18 14:42:07,003 	 Warmstarting? None None 7
2019-01-18 14:42:07,003 Embedding() torch.Size([7, 10])
2019-01-18 14:42:07,003 relative No Rescale
2019-01-18 14:42:07,003 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:07,004 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:07,004 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:07,004 	 Computing Major Stats lazily... 
2019-01-18 14:42:07,004 		 Completed edges=42 good=42 bad=0
2019-01-18 14:42:07,006 Distortion avg=0.9971417873719046 wc=5.448327215027938 me=0.005628252251848828 mc=968.0318100949036 nan_elements=0
2019-01-18 14:42:07,006 MAP = 0.33595238095238095
2019-01-18 14:42:07,007 scale=[array([1.])]
2019-01-18 14:42:07,007 *** End Initial Checkpoint

2019-01-18 14:42:07,063 1 loss=0.9942936718139951
2019-01-18 14:42:07,064 2 loss=0.5562712660626117
2019-01-18 14:42:07,064 3 loss=0.3819065926402907
2019-01-18 14:42:07,065 4 loss=0.2979960566497686
2019-01-18 14:42:07,065 5 loss=0.24571710401228666
2019-01-18 14:42:07,066 6 loss=0.20846644976135487
2019-01-18 14:42:07,066 7 loss=0.18027554650145797
2019-01-18 14:42:07,067 8 loss=0.1582930564131172
2019-01-18 14:42:07,067 9 loss=0.14081413527729494
2019-01-18 14:42:07,068 10 loss=0.1266719304364028
2019-01-18 14:42:07,068 11 loss=0.11501530060149376
2019-01-18 14:42:07,069 12 loss=0.10521140259677882
2019-01-18 14:42:07,069 13 loss=0.09679224071757785
2019-01-18 14:42:07,069 14 loss=0.08941786986058704
2019-01-18 14:42:07,070 15 loss=0.08284707848428352
2019-01-18 14:42:07,070 16 loss=0.07691281289396845
2019-01-18 14:42:07,071 17 loss=0.07150172699555854
2019-01-18 14:42:07,071 18 loss=0.06653773224424013
2019-01-18 14:42:07,072 19 loss=0.06196935014708739
2019-01-18 14:42:07,072 20 loss=0.057760472803070145
2019-01-18 14:42:07,073 21 loss=0.05388398406710587
2019-01-18 14:42:07,073 22 loss=0.05031763148550593
2019-01-18 14:42:07,074 23 loss=0.04704155949107996
2019-01-18 14:42:07,074 24 loss=0.04403699017419715
2019-01-18 14:42:07,074 25 loss=0.041285640188981926
2019-01-18 14:42:07,075 26 loss=0.03876956813464662
2019-01-18 14:42:07,075 27 loss=0.036471241527420574
2019-01-18 14:42:07,076 28 loss=0.034373689176892666
2019-01-18 14:42:07,076 29 loss=0.032460661798235806
2019-01-18 14:42:07,077 30 loss=0.030716762787654166
2019-01-18 14:42:07,077 31 loss=0.029127535649737378
2019-01-18 14:42:07,078 32 loss=0.027679508387467227
2019-01-18 14:42:07,078 33 loss=0.026360201717696225
2019-01-18 14:42:07,079 34 loss=0.02515811005161305
2019-01-18 14:42:07,079 35 loss=0.02406266381727437
2019-01-18 14:42:07,080 36 loss=0.023064180249586994
2019-01-18 14:42:07,080 37 loss=0.022153808038475994
2019-01-18 14:42:07,080 38 loss=0.0213234696277076
2019-01-18 14:42:07,081 39 loss=0.020565803665516764
2019-01-18 14:42:07,081 40 loss=0.01987410915196117
2019-01-18 14:42:07,082 41 loss=0.019242292165699542
2019-01-18 14:42:07,082 42 loss=0.018664815619461667
2019-01-18 14:42:07,083 43 loss=0.018136652223875893
2019-01-18 14:42:07,083 44 loss=0.017653240679544047
2019-01-18 14:42:07,084 45 loss=0.017210445027058794
2019-01-18 14:42:07,084 46 loss=0.016804517036343912
2019-01-18 14:42:07,085 47 loss=0.016432061492443233
2019-01-18 14:42:07,085 48 loss=0.016090004223892316
2019-01-18 14:42:07,086 49 loss=0.015775562715918706
2019-01-18 14:42:07,086 50 loss=0.015486219150621412
2019-01-18 14:42:07,086 final loss=0.015486219150621412
2019-01-18 14:42:07,087 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:07,087 	 Computing Major Stats lazily... 
2019-01-18 14:42:07,087 		 Completed edges=42 good=42 bad=0
2019-01-18 14:42:07,088 Distortion avg=0.11179140013154362 wc=1.4620807619776097 me=1.171122868187921 mc=1.2484435251784365 nan_elements=0
2019-01-18 14:42:07,088 MAP = 1.0
2019-01-18 14:42:07,088 scale=[array([1.])]
2019-01-18 15:18:30,049 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/173.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/173.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:18:30,050 No Model Save selected!
