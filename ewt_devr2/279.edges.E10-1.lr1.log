2019-01-18 14:39:25,922 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/279.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/279.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:25,922 No Model Save selected!
2019-01-18 14:39:25,924 Loaded Graph data/edges/parsing/ewt/ewt_dev/279.edges with 5 nodes scale=1.0
2019-01-18 14:39:25,924 Building dataset
2019-01-18 14:39:25,924 Subsample: 5 points with scale 1.0 subsample=4
2019-01-18 14:39:25,928 Built Data Sampler
2019-01-18 14:39:25,928 Creating a fresh model warm_start?=None
2019-01-18 14:39:25,929 	 Warmstarting? None None 5
2019-01-18 14:39:25,929 Embedding() torch.Size([5, 10])
2019-01-18 14:39:25,929 relative No Rescale
2019-01-18 14:39:25,929 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:25,930 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:25,930 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:25,930 	 Computing Major Stats lazily... 
2019-01-18 14:39:25,930 		 Completed edges=20 good=20 bad=0
2019-01-18 14:39:25,931 Distortion avg=0.996888193681215 wc=4.7900427106326955 me=0.005628252251848828 mc=851.0710778926463 nan_elements=0
2019-01-18 14:39:25,931 MAP = 0.4777777777777777
2019-01-18 14:39:25,932 scale=[array([1.])]
2019-01-18 14:39:25,932 *** End Initial Checkpoint

2019-01-18 14:39:25,990 1 loss=0.9937883375237689
2019-01-18 14:39:25,991 2 loss=0.3504264268182566
2019-01-18 14:39:25,991 3 loss=0.2480168754038476
2019-01-18 14:39:25,991 4 loss=0.19943389426559932
2019-01-18 14:39:25,992 5 loss=0.16272865801281136
2019-01-18 14:39:25,992 6 loss=0.13387183017820897
2019-01-18 14:39:25,993 7 loss=0.11105342640564086
2019-01-18 14:39:25,993 8 loss=0.09279649129941057
2019-01-18 14:39:25,994 9 loss=0.07799204797276951
2019-01-18 14:39:25,994 10 loss=0.06587865323493293
2019-01-18 14:39:25,995 11 loss=0.05593087799906813
2019-01-18 14:39:25,995 12 loss=0.047755878012593886
2019-01-18 14:39:25,995 13 loss=0.04103536301910622
2019-01-18 14:39:25,996 14 loss=0.03550267217142346
2019-01-18 14:39:25,996 15 loss=0.030935172849448245
2019-01-18 14:39:25,997 16 loss=0.02714995158430201
2019-01-18 14:39:25,997 17 loss=0.023998898261343663
2019-01-18 14:39:25,998 18 loss=0.021363135824328548
2019-01-18 14:39:25,998 19 loss=0.019147583947647227
2019-01-18 14:39:25,998 20 loss=0.017276186372559153
2019-01-18 14:39:25,999 21 loss=0.01568796736703692
2019-01-18 14:39:25,999 22 loss=0.014333873532837518
2019-01-18 14:39:26,000 23 loss=0.013174281156760276
2019-01-18 14:39:26,000 24 loss=0.01217704053107198
2019-01-18 14:39:26,001 25 loss=0.011315944213835662
2019-01-18 14:39:26,001 26 loss=0.010569526826342001
2019-01-18 14:39:26,002 27 loss=0.009920123049933303
2019-01-18 14:39:26,002 28 loss=0.009353126382886236
2019-01-18 14:39:26,002 29 loss=0.008856403977927741
2019-01-18 14:39:26,003 30 loss=0.008419832945387857
2019-01-18 14:39:26,003 31 loss=0.008034931365567922
2019-01-18 14:39:26,004 32 loss=0.007694563347559959
2019-01-18 14:39:26,004 33 loss=0.007392702173566024
2019-01-18 14:39:26,005 34 loss=0.007124239183850976
2019-01-18 14:39:26,005 35 loss=0.0068848288336685135
2019-01-18 14:39:26,006 36 loss=0.006670762483991237
2019-01-18 14:39:26,006 37 loss=0.006478865123986001
2019-01-18 14:39:26,006 38 loss=0.006306410481693896
2019-01-18 14:39:26,007 39 loss=0.006151050949783915
2019-01-18 14:39:26,007 40 loss=0.006010759503784784
2019-01-18 14:39:26,008 41 loss=0.0058837813727361694
2019-01-18 14:39:26,008 42 loss=0.005768593676121774
2019-01-18 14:39:26,009 43 loss=0.005663871596145712
2019-01-18 14:39:26,009 44 loss=0.005568459933595928
2019-01-18 14:39:26,010 45 loss=0.005481349115979484
2019-01-18 14:39:26,010 46 loss=0.005401654901485761
2019-01-18 14:39:26,011 47 loss=0.005328601161704747
2019-01-18 14:39:26,011 48 loss=0.005261505237623972
2019-01-18 14:39:26,011 49 loss=0.0051997654531932905
2019-01-18 14:39:26,012 50 loss=0.005142850443277305
2019-01-18 14:39:26,012 final loss=0.005142850443277305
2019-01-18 14:39:26,012 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:26,012 	 Computing Major Stats lazily... 
2019-01-18 14:39:26,012 		 Completed edges=20 good=20 bad=0
2019-01-18 14:39:26,013 Distortion avg=0.06690398690176776 wc=1.193501935975749 me=1.0826587238513359 mc=1.1023805652533896 nan_elements=0
2019-01-18 14:39:26,013 MAP = 1.0
2019-01-18 14:39:26,014 scale=[array([1.])]
2019-01-18 15:24:19,337 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/279.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/279.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:24:19,338 No Model Save selected!
