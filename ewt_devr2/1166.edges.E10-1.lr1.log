2019-01-18 14:42:55,768 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1166.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1166.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:55,768 No Model Save selected!
2019-01-18 14:42:55,770 Loaded Graph data/edges/parsing/ewt/ewt_dev/1166.edges with 13 nodes scale=1.0
2019-01-18 14:42:55,770 Building dataset
2019-01-18 14:42:55,771 Subsample: 13 points with scale 1.0 subsample=12
2019-01-18 14:42:55,787 Built Data Sampler
2019-01-18 14:42:55,787 Creating a fresh model warm_start?=None
2019-01-18 14:42:55,788 	 Warmstarting? None None 13
2019-01-18 14:42:55,788 Embedding() torch.Size([13, 10])
2019-01-18 14:42:55,788 relative No Rescale
2019-01-18 14:42:55,789 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:55,789 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:55,789 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:55,789 	 Computing Major Stats lazily... 
2019-01-18 14:42:55,791 		 Completed edges=156 good=156 bad=0
2019-01-18 14:42:55,794 Distortion avg=0.9976916776163761 wc=6.077072733527234 me=0.005982886981094694 mc=1015.7425257622544 nan_elements=0
2019-01-18 14:42:55,794 MAP = 0.24795898545898545
2019-01-18 14:42:55,794 scale=[array([1.])]
2019-01-18 14:42:55,794 *** End Initial Checkpoint

2019-01-18 14:42:55,858 1 loss=0.9953897440848366
2019-01-18 14:42:55,858 2 loss=0.809645292235561
2019-01-18 14:42:55,860 3 loss=0.6701829173862672
2019-01-18 14:42:55,861 4 loss=0.5673409268139993
2019-01-18 14:42:55,861 5 loss=0.4886897593763277
2019-01-18 14:42:55,862 6 loss=0.426589289771824
2019-01-18 14:42:55,863 7 loss=0.37633579198115824
2019-01-18 14:42:55,863 8 loss=0.3349197949595994
2019-01-18 14:42:55,864 9 loss=0.3003236247428066
2019-01-18 14:42:55,864 10 loss=0.27113033887046695
2019-01-18 14:42:55,865 11 loss=0.24630277930313263
2019-01-18 14:42:55,866 12 loss=0.2250551084490536
2019-01-18 14:42:55,867 13 loss=0.2067752883590211
2019-01-18 14:42:55,867 14 loss=0.19097630591252673
2019-01-18 14:42:55,868 15 loss=0.17726414835559007
2019-01-18 14:42:55,869 16 loss=0.16531591301727205
2019-01-18 14:42:55,869 17 loss=0.15486429827456985
2019-01-18 14:42:55,870 18 loss=0.14568627313607513
2019-01-18 14:42:55,871 19 loss=0.13759458300653518
2019-01-18 14:42:55,871 20 loss=0.1304312415412418
2019-01-18 14:42:55,872 21 loss=0.12406245063274743
2019-01-18 14:42:55,873 22 loss=0.11837457064206053
2019-01-18 14:42:55,873 23 loss=0.11327087814872819
2019-01-18 14:42:55,874 24 loss=0.10866892459860587
2019-01-18 14:42:55,874 25 loss=0.10449836090132703
2019-01-18 14:42:55,875 26 loss=0.10069912886612253
2019-01-18 14:42:55,876 27 loss=0.09721994562427909
2019-01-18 14:42:55,876 28 loss=0.0940170252171134
2019-01-18 14:42:55,877 29 loss=0.09105299453552385
2019-01-18 14:42:55,878 30 loss=0.08829597027399266
2019-01-18 14:42:55,878 31 loss=0.08571877053883689
2019-01-18 14:42:55,879 32 loss=0.08329823994774979
2019-01-18 14:42:55,879 33 loss=0.08101467098221782
2019-01-18 14:42:55,880 34 loss=0.07885130736429839
2019-01-18 14:42:55,881 35 loss=0.07679391757755943
2019-01-18 14:42:55,881 36 loss=0.0748304285174747
2019-01-18 14:42:55,882 37 loss=0.07295061076538795
2019-01-18 14:42:55,882 38 loss=0.07114580822129672
2019-01-18 14:42:55,883 39 loss=0.06940870586703972
2019-01-18 14:42:55,884 40 loss=0.06773313030759702
2019-01-18 14:42:55,884 41 loss=0.06611387848604966
2019-01-18 14:42:55,885 42 loss=0.0645465706104482
2019-01-18 14:42:55,886 43 loss=0.06302752388556247
2019-01-18 14:42:55,886 44 loss=0.06155364412228111
2019-01-18 14:42:55,887 45 loss=0.06012233271256184
2019-01-18 14:42:55,887 46 loss=0.05873140681664108
2019-01-18 14:42:55,888 47 loss=0.05737903091870786
2019-01-18 14:42:55,889 48 loss=0.056063658173482585
2019-01-18 14:42:55,890 49 loss=0.05478398019444879
2019-01-18 14:42:55,890 50 loss=0.053538884129633035
2019-01-18 14:42:55,890 final loss=0.053538884129633035
2019-01-18 14:42:55,890 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:55,891 	 Computing Major Stats lazily... 
2019-01-18 14:42:55,891 		 Completed edges=156 good=156 bad=0
2019-01-18 14:42:55,894 Distortion avg=0.18446197033515732 wc=3.1274926488913075 me=1.4960177599435036 mc=2.090545134310047 nan_elements=0
2019-01-18 14:42:55,894 MAP = 0.9294871794871794
2019-01-18 14:42:55,894 scale=[array([1.])]
2019-01-18 15:22:08,355 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1166.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1166.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:22:08,356 No Model Save selected!
