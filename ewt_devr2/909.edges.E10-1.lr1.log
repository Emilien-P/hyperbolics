2019-01-18 14:39:36,754 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/909.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/909.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:36,755 No Model Save selected!
2019-01-18 14:39:36,756 Loaded Graph data/edges/parsing/ewt/ewt_dev/909.edges with 18 nodes scale=1.0
2019-01-18 14:39:36,756 Building dataset
2019-01-18 14:39:36,757 Subsample: 18 points with scale 1.0 subsample=17
2019-01-18 14:39:36,775 Built Data Sampler
2019-01-18 14:39:36,775 Creating a fresh model warm_start?=None
2019-01-18 14:39:36,775 	 Warmstarting? None None 18
2019-01-18 14:39:36,776 Embedding() torch.Size([18, 10])
2019-01-18 14:39:36,776 relative No Rescale
2019-01-18 14:39:36,776 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:36,776 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:36,776 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:36,777 	 Computing Major Stats lazily... 
2019-01-18 14:39:36,778 		 Completed edges=306 good=306 bad=0
2019-01-18 14:39:36,781 Distortion avg=0.9982761635227216 wc=11.051519720462572 me=0.005941110731069004 mc=1860.1773676206226 nan_elements=0
2019-01-18 14:39:36,781 MAP = 0.2537965257328002
2019-01-18 14:39:36,782 scale=[array([1.])]
2019-01-18 14:39:36,782 *** End Initial Checkpoint

2019-01-18 14:39:36,840 1 loss=0.9965566859106986
2019-01-18 14:39:36,841 2 loss=0.9210778209981834
2019-01-18 14:39:36,842 3 loss=0.8530401933785359
2019-01-18 14:39:36,842 4 loss=0.7935944140786503
2019-01-18 14:39:36,843 5 loss=0.7417847406142418
2019-01-18 14:39:36,844 6 loss=0.6965679290363179
2019-01-18 14:39:36,844 7 loss=0.6569984305094848
2019-01-18 14:39:36,845 8 loss=0.6222558262085213
2019-01-18 14:39:36,846 9 loss=0.5916393323828688
2019-01-18 14:39:36,846 10 loss=0.5645541849636585
2019-01-18 14:39:36,847 11 loss=0.5404968493848209
2019-01-18 14:39:36,848 12 loss=0.519041248027646
2019-01-18 14:39:36,849 13 loss=0.4998266434238567
2019-01-18 14:39:36,849 14 loss=0.48254725304776613
2019-01-18 14:39:36,850 15 loss=0.46694346605864967
2019-01-18 14:39:36,851 16 loss=0.452794467115899
2019-01-18 14:39:36,851 17 loss=0.43991206435336705
2019-01-18 14:39:36,852 18 loss=0.4281355333372224
2019-01-18 14:39:36,853 19 loss=0.4173273113950029
2019-01-18 14:39:36,853 20 loss=0.40736940052209986
2019-01-18 14:39:36,854 21 loss=0.3981603593565977
2019-01-18 14:39:36,855 22 loss=0.38961278442748665
2019-01-18 14:39:36,855 23 loss=0.3816511978009403
2019-01-18 14:39:36,856 24 loss=0.3742102725148762
2019-01-18 14:39:36,857 25 loss=0.367233339089489
2019-01-18 14:39:36,857 26 loss=0.3606711262571759
2019-01-18 14:39:36,858 27 loss=0.3544806971861506
2019-01-18 14:39:36,859 28 loss=0.3486245491644102
2019-01-18 14:39:36,859 29 loss=0.3430698502131621
2019-01-18 14:39:36,860 30 loss=0.3377877906221909
2019-01-18 14:39:36,861 31 loss=0.33275303112003535
2019-01-18 14:39:36,861 32 loss=0.3279432324548746
2019-01-18 14:39:36,862 33 loss=0.3233386536873273
2019-01-18 14:39:36,863 34 loss=0.3189218085817627
2019-01-18 14:39:36,864 35 loss=0.3146771712080345
2019-01-18 14:39:36,864 36 loss=0.3105909232957489
2019-01-18 14:39:36,865 37 loss=0.30665073707119844
2019-01-18 14:39:36,866 38 loss=0.3028455882959811
2019-01-18 14:39:36,866 39 loss=0.2991655950512054
2019-01-18 14:39:36,867 40 loss=0.2956018785006605
2019-01-18 14:39:36,868 41 loss=0.29214644244383525
2019-01-18 14:39:36,868 42 loss=0.2887920689543143
2019-01-18 14:39:36,869 43 loss=0.2855322278066083
2019-01-18 14:39:36,870 44 loss=0.2823609977377771
2019-01-18 14:39:36,870 45 loss=0.2792729978799241
2019-01-18 14:39:36,871 46 loss=0.2762633279445612
2019-01-18 14:39:36,872 47 loss=0.2733275159472318
2019-01-18 14:39:36,873 48 loss=0.2704614724366543
2019-01-18 14:39:36,874 49 loss=0.26766145034203187
2019-01-18 14:39:36,874 50 loss=0.2649240096792202
2019-01-18 14:39:36,874 final loss=0.2649240096792202
2019-01-18 14:39:36,874 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:36,875 	 Computing Major Stats lazily... 
2019-01-18 14:39:36,876 		 Completed edges=306 good=306 bad=0
2019-01-18 14:39:36,879 Distortion avg=0.46503719791191617 wc=8.903114421962472 me=1.8266779047051764 mc=4.873937763756673 nan_elements=0
2019-01-18 14:39:36,879 MAP = 0.3093220051553384
2019-01-18 14:39:36,879 scale=[array([1.])]
2019-01-18 15:18:57,320 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/909.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/909.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:18:57,321 No Model Save selected!
