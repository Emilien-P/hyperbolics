2019-01-18 14:42:20,557 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1894.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1894.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:20,558 No Model Save selected!
2019-01-18 14:42:20,559 Loaded Graph data/edges/parsing/ewt/ewt_dev/1894.edges with 44 nodes scale=1.0
2019-01-18 14:42:20,559 Building dataset
2019-01-18 14:42:20,560 Subsample: 44 points with scale 1.0 subsample=43
2019-01-18 14:42:20,638 Built Data Sampler
2019-01-18 14:42:20,638 Creating a fresh model warm_start?=None
2019-01-18 14:42:20,638 	 Warmstarting? None None 44
2019-01-18 14:42:20,639 Embedding() torch.Size([44, 10])
2019-01-18 14:42:20,639 relative No Rescale
2019-01-18 14:42:20,639 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:20,639 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:20,639 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:20,639 	 Computing Major Stats lazily... 
2019-01-18 14:42:20,647 		 Completed edges=1892 good=1892 bad=0
2019-01-18 14:42:20,654 Distortion avg=0.9988915194962266 wc=32.27580671266225 me=0.007048654353541345 mc=4579.002614370844 nan_elements=0
2019-01-18 14:42:20,654 MAP = 0.11969991362829284
2019-01-18 14:42:20,654 scale=[array([1.])]
2019-01-18 14:42:20,654 *** End Initial Checkpoint

2019-01-18 14:42:20,714 1 loss=0.9977850891498234
2019-01-18 14:42:20,716 2 loss=0.9850342381214137
2019-01-18 14:42:20,717 3 loss=0.9721760743754554
2019-01-18 14:42:20,719 4 loss=0.959540721994062
2019-01-18 14:42:20,721 5 loss=0.9471858868984141
2019-01-18 14:42:20,723 6 loss=0.9351281800057474
2019-01-18 14:42:20,725 7 loss=0.9233712421034754
2019-01-18 14:42:20,726 8 loss=0.9119132666738339
2019-01-18 14:42:20,729 9 loss=0.9007497911615273
2019-01-18 14:42:20,733 10 loss=0.8898749505253849
2019-01-18 14:42:20,736 11 loss=0.8792821157529088
2019-01-18 14:42:20,737 12 loss=0.8689642491891884
2019-01-18 14:42:20,739 13 loss=0.8589141154036081
2019-01-18 14:42:20,741 14 loss=0.8491244123764157
2019-01-18 14:42:20,743 15 loss=0.8395878559550014
2019-01-18 14:42:20,745 16 loss=0.8302972355193625
2019-01-18 14:42:20,746 17 loss=0.8212454511820871
2019-01-18 14:42:20,748 18 loss=0.8124255387470335
2019-01-18 14:42:20,750 19 loss=0.8038306863281104
2019-01-18 14:42:20,751 20 loss=0.7954542451565897
2019-01-18 14:42:20,753 21 loss=0.787289736263417
2019-01-18 14:42:20,755 22 loss=0.7793308541898324
2019-01-18 14:42:20,757 23 loss=0.7715714685324063
2019-01-18 14:42:20,758 24 loss=0.7640056238967603
2019-01-18 14:42:20,760 25 loss=0.7566275386760046
2019-01-18 14:42:20,762 26 loss=0.7494316029597158
2019-01-18 14:42:20,763 27 loss=0.7424123758012049
2019-01-18 14:42:20,765 28 loss=0.7355645820145414
2019-01-18 14:42:20,767 29 loss=0.7288831086317101
2019-01-18 14:42:20,768 30 loss=0.7223630011198192
2019-01-18 14:42:20,770 31 loss=0.7159994594354699
2019-01-18 14:42:20,772 32 loss=0.7097878339761059
2019-01-18 14:42:20,774 33 loss=0.7037236214749442
2019-01-18 14:42:20,775 34 loss=0.6978024608758742
2019-01-18 14:42:20,777 35 loss=0.6920201292167784
2019-01-18 14:42:20,779 36 loss=0.6863725375434834
2019-01-18 14:42:20,781 37 loss=0.6808557268716617
2019-01-18 14:42:20,783 38 loss=0.6754658642100856
2019-01-18 14:42:20,784 39 loss=0.6701992386555415
2019-01-18 14:42:20,786 40 loss=0.6650522575672165
2019-01-18 14:42:20,788 41 loss=0.6600214428263675
2019-01-18 14:42:20,790 42 loss=0.6551034271854759
2019-01-18 14:42:20,791 43 loss=0.650294950709782
2019-01-18 14:42:20,793 44 loss=0.6455928573130408
2019-01-18 14:42:20,795 45 loss=0.6409940913884876
2019-01-18 14:42:20,796 46 loss=0.63649569453531
2019-01-18 14:42:20,798 47 loss=0.6320948023803696
2019-01-18 14:42:20,800 48 loss=0.6277886414944552
2019-01-18 14:42:20,802 49 loss=0.623574526402004
2019-01-18 14:42:20,803 50 loss=0.6194498566829272
2019-01-18 14:42:20,803 final loss=0.6194498566829272
2019-01-18 14:42:20,804 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:20,804 	 Computing Major Stats lazily... 
2019-01-18 14:42:20,810 		 Completed edges=1892 good=1892 bad=0
2019-01-18 14:42:20,818 Distortion avg=0.762457475646728 wc=37.40049841090644 me=1.6058872685391874 mc=23.289616365741665 nan_elements=0
2019-01-18 14:42:20,818 MAP = 0.04598603860601394
2019-01-18 14:42:20,818 scale=[array([1.])]
2019-01-18 15:20:37,726 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1894.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1894.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:20:37,727 No Model Save selected!
