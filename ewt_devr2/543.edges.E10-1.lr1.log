2019-01-18 14:40:06,470 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/543.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/543.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:06,470 No Model Save selected!
2019-01-18 14:40:06,471 Loaded Graph data/edges/parsing/ewt/ewt_dev/543.edges with 8 nodes scale=1.0
2019-01-18 14:40:06,471 Building dataset
2019-01-18 14:40:06,472 Subsample: 8 points with scale 1.0 subsample=7
2019-01-18 14:40:06,478 Built Data Sampler
2019-01-18 14:40:06,478 Creating a fresh model warm_start?=None
2019-01-18 14:40:06,478 	 Warmstarting? None None 8
2019-01-18 14:40:06,478 Embedding() torch.Size([8, 10])
2019-01-18 14:40:06,479 relative No Rescale
2019-01-18 14:40:06,479 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:06,479 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:06,479 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:06,479 	 Computing Major Stats lazily... 
2019-01-18 14:40:06,480 		 Completed edges=56 good=56 bad=0
2019-01-18 14:40:06,482 Distortion avg=0.9972184366505245 wc=4.766312477281529 me=0.005941110731069004 mc=802.259492043487 nan_elements=0
2019-01-18 14:40:06,482 MAP = 0.3599404761904762
2019-01-18 14:40:06,482 scale=[array([1.])]
2019-01-18 14:40:06,482 *** End Initial Checkpoint

2019-01-18 14:40:06,539 1 loss=0.9944466166565221
2019-01-18 14:40:06,540 2 loss=0.6463243020855071
2019-01-18 14:40:06,540 3 loss=0.4700854513544132
2019-01-18 14:40:06,541 4 loss=0.37655616247134116
2019-01-18 14:40:06,541 5 loss=0.3177013900757148
2019-01-18 14:40:06,542 6 loss=0.27530031051682263
2019-01-18 14:40:06,542 7 loss=0.24216510243505085
2019-01-18 14:40:06,543 8 loss=0.21514224600060633
2019-01-18 14:40:06,543 9 loss=0.19262125043720718
2019-01-18 14:40:06,544 10 loss=0.17362738516590742
2019-01-18 14:40:06,544 11 loss=0.15747852656233752
2019-01-18 14:40:06,545 12 loss=0.14364988578341892
2019-01-18 14:40:06,545 13 loss=0.13171804258240083
2019-01-18 14:40:06,546 14 loss=0.12133587109835917
2019-01-18 14:40:06,546 15 loss=0.11221938390700462
2019-01-18 14:40:06,547 16 loss=0.10413888367717007
2019-01-18 14:40:06,547 17 loss=0.0969114370560935
2019-01-18 14:40:06,548 18 loss=0.09039366336951468
2019-01-18 14:40:06,548 19 loss=0.08447469385771951
2019-01-18 14:40:06,549 20 loss=0.07906950328563093
2019-01-18 14:40:06,549 21 loss=0.0741128967894484
2019-01-18 14:40:06,550 22 loss=0.06955437733008411
2019-01-18 14:40:06,550 23 loss=0.06535400281331541
2019-01-18 14:40:06,551 24 loss=0.061479221375040076
2019-01-18 14:40:06,551 25 loss=0.057902581047282756
2019-01-18 14:40:06,552 26 loss=0.054600158211330255
2019-01-18 14:40:06,552 27 loss=0.05155053499092693
2019-01-18 14:40:06,553 28 loss=0.04873416824945992
2019-01-18 14:40:06,553 29 loss=0.04613301980460349
2019-01-18 14:40:06,553 30 loss=0.043730348818087086
2019-01-18 14:40:06,554 31 loss=0.04151059661071108
2019-01-18 14:40:06,554 32 loss=0.039459318243756605
2019-01-18 14:40:06,555 33 loss=0.03756313327692528
2019-01-18 14:40:06,555 34 loss=0.03580968066474261
2019-01-18 14:40:06,556 35 loss=0.034187570858606166
2019-01-18 14:40:06,556 36 loss=0.032686333008646866
2019-01-18 14:40:06,557 37 loss=0.03129635773930284
2019-01-18 14:40:06,557 38 loss=0.03000883711474267
2019-01-18 14:40:06,558 39 loss=0.02881570370169512
2019-01-18 14:40:06,558 40 loss=0.02770957047571133
2019-01-18 14:40:06,559 41 loss=0.02668367295561565
2019-01-18 14:40:06,559 42 loss=0.025731814539780774
2019-01-18 14:40:06,560 43 loss=0.024848315637174274
2019-01-18 14:40:06,560 44 loss=0.02402796687187898
2019-01-18 14:40:06,561 45 loss=0.02326598640165254
2019-01-18 14:40:06,561 46 loss=0.02255798122444536
2019-01-18 14:40:06,562 47 loss=0.02189991224043595
2019-01-18 14:40:06,562 48 loss=0.021288062777901413
2019-01-18 14:40:06,562 49 loss=0.020719010266533226
2019-01-18 14:40:06,563 50 loss=0.020189600740841262
2019-01-18 14:40:06,563 final loss=0.020189600740841262
2019-01-18 14:40:06,563 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:06,563 	 Computing Major Stats lazily... 
2019-01-18 14:40:06,564 		 Completed edges=56 good=56 bad=0
2019-01-18 14:40:06,565 Distortion avg=0.12098602735418958 wc=1.6145120797597727 me=1.1988312421418184 mc=1.3467384090485528 nan_elements=0
2019-01-18 14:40:06,565 MAP = 1.0
2019-01-18 14:40:06,565 scale=[array([1.])]
2019-01-18 15:17:47,162 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/543.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/543.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:17:47,163 No Model Save selected!
