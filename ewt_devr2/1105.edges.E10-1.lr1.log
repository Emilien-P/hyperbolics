2019-01-18 14:41:16,959 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1105.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1105.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:16,959 No Model Save selected!
2019-01-18 14:41:16,961 Loaded Graph data/edges/parsing/ewt/ewt_dev/1105.edges with 2 nodes scale=1.0
2019-01-18 14:41:16,961 Building dataset
2019-01-18 14:41:16,961 Subsample: 2 points with scale 1.0 subsample=1
2019-01-18 14:41:16,963 Built Data Sampler
2019-01-18 14:41:16,963 Creating a fresh model warm_start?=None
2019-01-18 14:41:16,963 	 Warmstarting? None None 2
2019-01-18 14:41:16,963 Embedding() torch.Size([2, 10])
2019-01-18 14:41:16,964 relative No Rescale
2019-01-18 14:41:16,964 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:16,964 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:16,964 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:16,964 	 Computing Major Stats lazily... 
2019-01-18 14:41:16,965 		 Completed edges=2 good=2 bad=0
2019-01-18 14:41:16,965 Distortion avg=0.9965968412004117 wc=1.0 me=0.00340315879958833 mc=293.8446481313088 nan_elements=0
2019-01-18 14:41:16,966 MAP = 1.0
2019-01-18 14:41:16,966 scale=[array([1.])]
2019-01-18 14:41:16,966 *** End Initial Checkpoint

2019-01-18 14:41:17,022 1 loss=0.9932052638906386
2019-01-18 14:41:17,023 2 loss=8.938847375015749
2019-01-18 14:41:17,024 3 loss=48.57214009192693
2019-01-18 14:41:17,024 4 loss=357.51680197769787
2019-01-18 14:41:17,024 5 loss=2994.7538412503473
2019-01-18 14:41:17,025 6 loss=26300.09244160632
2019-01-18 14:41:17,025 7 loss=234758.7555855165
2019-01-18 14:41:17,026 8 loss=2107018.5711028273
2019-01-18 14:41:17,026 9 loss=18945752.452424984
2019-01-18 14:41:17,026 10 loss=170459544.00932342
2019-01-18 14:41:17,027 11 loss=1533979227.8964074
2019-01-18 14:41:17,027 12 loss=13805343062.505152
2019-01-18 14:41:17,028 13 loss=124246677612.85883
2019-01-18 14:41:17,028 14 loss=1118215868682.6665
2019-01-18 14:41:17,029 15 loss=10063930128660.81
2019-01-18 14:41:17,029 16 loss=90575333089513.72
2019-01-18 14:41:17,029 17 loss=815177883600338.8
2019-01-18 14:41:17,030 18 loss=7336600609787212.0
2019-01-18 14:41:17,030 19 loss=6.60294044602374e+16
2019-01-18 14:41:17,031 20 loss=5.94264637058594e+17
2019-01-18 14:41:17,031 21 loss=5.348381724276721e+18
2019-01-18 14:41:17,031 22 loss=4.81354354907386e+19
2019-01-18 14:41:17,032 23 loss=4.332189193333917e+20
2019-01-18 14:41:17,032 24 loss=3.898970273750758e+21
2019-01-18 14:41:17,033 25 loss=3.509073246300752e+22
2019-01-18 14:41:17,033 26 loss=3.158165921648198e+23
2019-01-18 14:41:17,034 27 loss=2.842349329476635e+24
2019-01-18 14:41:17,034 28 loss=2.5581143965269464e+25
2019-01-18 14:41:17,034 29 loss=2.3023029568736446e+26
2019-01-18 14:41:17,035 30 loss=2.072072661186098e+27
2019-01-18 14:41:17,035 31 loss=1.8648653950674335e+28
2019-01-18 14:41:17,036 32 loss=1.678378855560674e+29
2019-01-18 14:41:17,036 33 loss=1.5105409700046018e+30
2019-01-18 14:41:17,036 34 loss=1.3594868730041399e+31
2019-01-18 14:41:17,037 35 loss=1.2235381857037259e+32
2019-01-18 14:41:17,037 36 loss=1.1011843671333534e+33
2019-01-18 14:41:17,038 37 loss=9.91065930420018e+33
2019-01-18 14:41:17,038 38 loss=8.91959337378016e+34
2019-01-18 14:41:17,038 39 loss=8.027634036402146e+35
2019-01-18 14:41:17,039 40 loss=7.224870632761931e+36
2019-01-18 14:41:17,039 41 loss=6.502383569485739e+37
2019-01-18 14:41:17,040 42 loss=5.852145212537165e+38
2019-01-18 14:41:17,040 43 loss=5.266930691283448e+39
2019-01-18 14:41:17,041 44 loss=4.740237622155103e+40
2019-01-18 14:41:17,041 45 loss=4.2662138599395935e+41
2019-01-18 14:41:17,041 46 loss=3.839592473945634e+42
2019-01-18 14:41:17,042 47 loss=3.4556332265510695e+43
2019-01-18 14:41:17,042 48 loss=3.1100699038959636e+44
2019-01-18 14:41:17,043 49 loss=2.7990629135063678e+45
2019-01-18 14:41:17,043 50 loss=2.519156622155731e+46
2019-01-18 14:41:17,043 final loss=2.519156622155731e+46
2019-01-18 14:41:17,043 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:17,043 	 Computing Major Stats lazily... 
2019-01-18 14:41:17,043 		 Completed edges=2 good=2 bad=0
2019-01-18 14:41:17,044 Distortion avg=4.7615553760721484e+23 wc=1.0 me=4.7615553760721484e+23 mc=2.1001540904579576e-24 nan_elements=0
2019-01-18 14:41:17,044 MAP = 1.0
2019-01-18 14:41:17,044 scale=[array([1.])]
2019-01-18 15:22:24,891 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1105.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1105.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:22:24,892 No Model Save selected!
