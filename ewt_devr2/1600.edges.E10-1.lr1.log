2019-01-18 14:42:18,042 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1600.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1600.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:18,042 No Model Save selected!
2019-01-18 14:42:18,044 Loaded Graph data/edges/parsing/ewt/ewt_dev/1600.edges with 24 nodes scale=1.0
2019-01-18 14:42:18,044 Building dataset
2019-01-18 14:42:18,045 Subsample: 24 points with scale 1.0 subsample=23
2019-01-18 14:42:18,073 Built Data Sampler
2019-01-18 14:42:18,074 Creating a fresh model warm_start?=None
2019-01-18 14:42:18,074 	 Warmstarting? None None 24
2019-01-18 14:42:18,074 Embedding() torch.Size([24, 10])
2019-01-18 14:42:18,074 relative No Rescale
2019-01-18 14:42:18,075 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:18,075 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:18,075 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:18,075 	 Computing Major Stats lazily... 
2019-01-18 14:42:18,078 		 Completed edges=552 good=552 bad=0
2019-01-18 14:42:18,081 Distortion avg=0.998519607588971 wc=22.89407024854016 me=0.006196519622161948 mc=3694.665980990226 nan_elements=0
2019-01-18 14:42:18,081 MAP = 0.1873059294669566
2019-01-18 14:42:18,082 scale=[array([1.])]
2019-01-18 14:42:18,082 *** End Initial Checkpoint

2019-01-18 14:42:18,139 1 loss=0.9970426804139366
2019-01-18 14:42:18,140 2 loss=0.9575218551180773
2019-01-18 14:42:18,141 3 loss=0.9195104592410367
2019-01-18 14:42:18,142 4 loss=0.8841587817596864
2019-01-18 14:42:18,143 5 loss=0.8514379370999834
2019-01-18 14:42:18,144 6 loss=0.8211854069012295
2019-01-18 14:42:18,144 7 loss=0.7932135945505884
2019-01-18 14:42:18,145 8 loss=0.7673359760560939
2019-01-18 14:42:18,146 9 loss=0.7433755455043771
2019-01-18 14:42:18,147 10 loss=0.7211676695510756
2019-01-18 14:42:18,148 11 loss=0.7005607812184625
2019-01-18 14:42:18,149 12 loss=0.6814161449704035
2019-01-18 14:42:18,149 13 loss=0.6636072084273191
2019-01-18 14:42:18,150 14 loss=0.6470187793317461
2019-01-18 14:42:18,151 15 loss=0.6315461457109023
2019-01-18 14:42:18,152 16 loss=0.6170941996367826
2019-01-18 14:42:18,153 17 loss=0.6035765956429946
2019-01-18 14:42:18,154 18 loss=0.5909149591481112
2019-01-18 14:42:18,154 19 loss=0.5790381515394382
2019-01-18 14:42:18,155 20 loss=0.56788159366848
2019-01-18 14:42:18,156 21 loss=0.5573866467410088
2019-01-18 14:42:18,157 22 loss=0.5475000480540902
2019-01-18 14:42:18,158 23 loss=0.5381733982355362
2019-01-18 14:42:18,159 24 loss=0.529362696285015
2019-01-18 14:42:18,160 25 loss=0.5210279186252947
2019-01-18 14:42:18,160 26 loss=0.513132638439929
2019-01-18 14:42:18,161 27 loss=0.505643681733703
2019-01-18 14:42:18,162 28 loss=0.49853081676264893
2019-01-18 14:42:18,163 29 loss=0.4917664737151521
2019-01-18 14:42:18,164 30 loss=0.4853254917679742
2019-01-18 14:42:18,165 31 loss=0.47918489088066335
2019-01-18 14:42:18,166 32 loss=0.4733236659224906
2019-01-18 14:42:18,166 33 loss=0.46772260094416035
2019-01-18 14:42:18,167 34 loss=0.46236410161019303
2019-01-18 14:42:18,168 35 loss=0.45723204399628664
2019-01-18 14:42:18,169 36 loss=0.45231163812913466
2019-01-18 14:42:18,170 37 loss=0.44758930480449277
2019-01-18 14:42:18,171 38 loss=0.44305256436346635
2019-01-18 14:42:18,172 39 loss=0.4386899362378882
2019-01-18 14:42:18,172 40 loss=0.4344908481942067
2019-01-18 14:42:18,173 41 loss=0.430445554312459
2019-01-18 14:42:18,174 42 loss=0.42654506083361726
2019-01-18 14:42:18,175 43 loss=0.42278105909577174
2019-01-18 14:42:18,176 44 loss=0.4191458648581142
2019-01-18 14:42:18,177 45 loss=0.41563236338233206
2019-01-18 14:42:18,178 46 loss=0.4122339597045336
2019-01-18 14:42:18,178 47 loss=0.40894453358793437
2019-01-18 14:42:18,179 48 loss=0.40575839869782643
2019-01-18 14:42:18,180 49 loss=0.40267026558644325
2019-01-18 14:42:18,181 50 loss=0.39967520811672175
2019-01-18 14:42:18,181 final loss=0.39967520811672175
2019-01-18 14:42:18,181 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:18,181 	 Computing Major Stats lazily... 
2019-01-18 14:42:18,183 		 Completed edges=552 good=552 bad=0
2019-01-18 14:42:18,187 Distortion avg=0.5939278272544616 wc=19.69072265095627 me=1.746025272396487 mc=11.277455694515805 nan_elements=0
2019-01-18 14:42:18,187 MAP = 0.11557512128878002
2019-01-18 14:42:18,187 scale=[array([1.])]
2019-01-18 15:17:44,919 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1600.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1600.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:17:44,920 No Model Save selected!
