2019-01-18 14:43:25,797 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1170.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1170.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:43:25,797 No Model Save selected!
2019-01-18 14:43:25,799 Loaded Graph data/edges/parsing/ewt/ewt_dev/1170.edges with 6 nodes scale=1.0
2019-01-18 14:43:25,799 Building dataset
2019-01-18 14:43:25,799 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:43:25,804 Built Data Sampler
2019-01-18 14:43:25,804 Creating a fresh model warm_start?=None
2019-01-18 14:43:25,804 	 Warmstarting? None None 6
2019-01-18 14:43:25,804 Embedding() torch.Size([6, 10])
2019-01-18 14:43:25,804 relative No Rescale
2019-01-18 14:43:25,805 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:43:25,805 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:43:25,805 *** Initial Checkpoint. Computing Stats
2019-01-18 14:43:25,805 	 Computing Major Stats lazily... 
2019-01-18 14:43:25,806 		 Completed edges=30 good=30 bad=0
2019-01-18 14:43:25,807 Distortion avg=0.9970107087516167 wc=3.6322181433519583 me=0.005628252251848828 mc=645.354540063269 nan_elements=0
2019-01-18 14:43:25,807 MAP = 0.44999999999999996
2019-01-18 14:43:25,807 scale=[array([1.])]
2019-01-18 14:43:25,807 *** End Initial Checkpoint

2019-01-18 14:43:25,865 1 loss=0.9940318309062036
2019-01-18 14:43:25,866 2 loss=0.4293061030090941
2019-01-18 14:43:25,867 3 loss=0.26996040000143373
2019-01-18 14:43:25,867 4 loss=0.19002482905619816
2019-01-18 14:43:25,868 5 loss=0.13769665547696744
2019-01-18 14:43:25,868 6 loss=0.10183942906149393
2019-01-18 14:43:25,868 7 loss=0.0769895567126652
2019-01-18 14:43:25,869 8 loss=0.05965395439234069
2019-01-18 14:43:25,869 9 loss=0.04747097945915806
2019-01-18 14:43:25,870 10 loss=0.03882966988573068
2019-01-18 14:43:25,870 11 loss=0.03263285478227043
2019-01-18 14:43:25,871 12 loss=0.028134611961158146
2019-01-18 14:43:25,871 13 loss=0.024827266460764986
2019-01-18 14:43:25,872 14 loss=0.022363786335547396
2019-01-18 14:43:25,872 15 loss=0.02050526582498964
2019-01-18 14:43:25,873 16 loss=0.019085739612479887
2019-01-18 14:43:25,873 17 loss=0.01798870898200263
2019-01-18 14:43:25,873 18 loss=0.01713147415698903
2019-01-18 14:43:25,874 19 loss=0.016454637000385818
2019-01-18 14:43:25,874 20 loss=0.015915025397711762
2019-01-18 14:43:25,875 21 loss=0.015480888146382248
2019-01-18 14:43:25,875 22 loss=0.01512860375851301
2019-01-18 14:43:25,876 23 loss=0.014840404936778637
2019-01-18 14:43:25,876 24 loss=0.014602789308538542
2019-01-18 14:43:25,877 25 loss=0.014405397510388945
2019-01-18 14:43:25,877 26 loss=0.014240212301424358
2019-01-18 14:43:25,878 27 loss=0.014100980269528446
2019-01-18 14:43:25,878 28 loss=0.013982789439065306
2019-01-18 14:43:25,878 29 loss=0.01388175724190322
2019-01-18 14:43:25,879 30 loss=0.013794797490223169
2019-01-18 14:43:25,879 31 loss=0.013719444549844523
2019-01-18 14:43:25,880 32 loss=0.013653719404972866
2019-01-18 14:43:25,880 33 loss=0.013596026748247999
2019-01-18 14:43:25,881 34 loss=0.013545075296794716
2019-01-18 14:43:25,881 35 loss=0.013499815671958742
2019-01-18 14:43:25,882 36 loss=0.013459391684731786
2019-01-18 14:43:25,882 37 loss=0.013423101939362119
2019-01-18 14:43:25,883 38 loss=0.013390369438044527
2019-01-18 14:43:25,883 39 loss=0.013360717430402735
2019-01-18 14:43:25,884 40 loss=0.013333750164403496
2019-01-18 14:43:25,884 41 loss=0.013309137502759848
2019-01-18 14:43:25,884 42 loss=0.01328660260016593
2019-01-18 14:43:25,885 43 loss=0.013265912012422042
2019-01-18 14:43:25,885 44 loss=0.013246867743199007
2019-01-18 14:43:25,886 45 loss=0.013229300838261427
2019-01-18 14:43:25,886 46 loss=0.013213066217943614
2019-01-18 14:43:25,887 47 loss=0.013198038502061835
2019-01-18 14:43:25,887 48 loss=0.013184108631325667
2019-01-18 14:43:25,888 49 loss=0.013171181128734725
2019-01-18 14:43:25,888 50 loss=0.013159171875718296
2019-01-18 14:43:25,888 final loss=0.013159171875718296
2019-01-18 14:43:25,888 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:43:25,888 	 Computing Major Stats lazily... 
2019-01-18 14:43:25,889 		 Completed edges=30 good=30 bad=0
2019-01-18 14:43:25,890 Distortion avg=0.1112183391671621 wc=1.287402320310921 me=1.1471392603295907 mc=1.1222720421416235 nan_elements=0
2019-01-18 14:43:25,890 MAP = 1.0
2019-01-18 14:43:25,890 scale=[array([1.])]
2019-01-18 15:16:19,032 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1170.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1170.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:16:19,033 No Model Save selected!
