2019-01-18 14:42:28,139 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1101.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1101.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:28,139 No Model Save selected!
2019-01-18 14:42:28,140 Loaded Graph data/edges/parsing/ewt/ewt_dev/1101.edges with 17 nodes scale=1.0
2019-01-18 14:42:28,141 Building dataset
2019-01-18 14:42:28,141 Subsample: 17 points with scale 1.0 subsample=16
2019-01-18 14:42:28,158 Built Data Sampler
2019-01-18 14:42:28,158 Creating a fresh model warm_start?=None
2019-01-18 14:42:28,158 	 Warmstarting? None None 17
2019-01-18 14:42:28,158 Embedding() torch.Size([17, 10])
2019-01-18 14:42:28,158 relative No Rescale
2019-01-18 14:42:28,159 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:28,159 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:28,159 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:28,159 	 Computing Major Stats lazily... 
2019-01-18 14:42:28,161 		 Completed edges=272 good=272 bad=0
2019-01-18 14:42:28,163 Distortion avg=0.9980433324416995 wc=8.231965964960828 me=0.00607253907908975 mc=1355.6052678700535 nan_elements=0
2019-01-18 14:42:28,163 MAP = 0.17356610346806428
2019-01-18 14:42:28,164 scale=[array([1.])]
2019-01-18 14:42:28,164 *** End Initial Checkpoint

2019-01-18 14:42:28,220 1 loss=0.9960917873078462
2019-01-18 14:42:28,221 2 loss=0.8919041307673834
2019-01-18 14:42:28,222 3 loss=0.8028165848471134
2019-01-18 14:42:28,223 4 loss=0.7286309917382642
2019-01-18 14:42:28,223 5 loss=0.6663802846771719
2019-01-18 14:42:28,224 6 loss=0.6136138449928327
2019-01-18 14:42:28,224 7 loss=0.5684286095416031
2019-01-18 14:42:28,225 8 loss=0.5293606033936753
2019-01-18 14:42:28,226 9 loss=0.4952813812671702
2019-01-18 14:42:28,226 10 loss=0.4653156643629062
2019-01-18 14:42:28,227 11 loss=0.4387788485377756
2019-01-18 14:42:28,228 12 loss=0.41513034436832863
2019-01-18 14:42:28,228 13 loss=0.39393891309495915
2019-01-18 14:42:28,229 14 loss=0.37485691451567527
2019-01-18 14:42:28,230 15 loss=0.35760112298032126
2019-01-18 14:42:28,230 16 loss=0.34193837222513185
2019-01-18 14:42:28,231 17 loss=0.3276747525750659
2019-01-18 14:42:28,232 18 loss=0.31464742817129704
2019-01-18 14:42:28,232 19 loss=0.30271839414158636
2019-01-18 14:42:28,233 20 loss=0.2917696772224847
2019-01-18 14:42:28,234 21 loss=0.28169961652290343
2019-01-18 14:42:28,234 22 loss=0.27241995765059596
2019-01-18 14:42:28,235 23 loss=0.26385356344964217
2019-01-18 14:42:28,236 24 loss=0.2559325955010107
2019-01-18 14:42:28,236 25 loss=0.2485970576549823
2019-01-18 14:42:28,237 26 loss=0.24179362003363672
2019-01-18 14:42:28,238 27 loss=0.2354746619218595
2019-01-18 14:42:28,238 28 loss=0.22959748673612057
2019-01-18 14:42:28,239 29 loss=0.2241236732432147
2019-01-18 14:42:28,240 30 loss=0.2190185354183613
2019-01-18 14:42:28,241 31 loss=0.21425066952000507
2019-01-18 14:42:28,241 32 loss=0.2097915716495575
2019-01-18 14:42:28,242 33 loss=0.20561531264417154
2019-01-18 14:42:28,242 34 loss=0.20169825990068044
2019-01-18 14:42:28,243 35 loss=0.19801883785499436
2019-01-18 14:42:28,244 36 loss=0.1945573204952155
2019-01-18 14:42:28,244 37 loss=0.19129565058092557
2019-01-18 14:42:28,245 38 loss=0.18821728125939702
2019-01-18 14:42:28,246 39 loss=0.1853070365748899
2019-01-18 14:42:28,246 40 loss=0.18255098800738762
2019-01-18 14:42:28,247 41 loss=0.17993634468839279
2019-01-18 14:42:28,248 42 loss=0.17745135535157547
2019-01-18 14:42:28,248 43 loss=0.1750852204066059
2019-01-18 14:42:28,249 44 loss=0.17282801279204768
2019-01-18 14:42:28,250 45 loss=0.1706706064807239
2019-01-18 14:42:28,250 46 loss=0.1686046116886437
2019-01-18 14:42:28,251 47 loss=0.16662231598438448
2019-01-18 14:42:28,252 48 loss=0.16471663061605182
2019-01-18 14:42:28,253 49 loss=0.16288104147256122
2019-01-18 14:42:28,253 50 loss=0.16110956417894118
2019-01-18 14:42:28,254 final loss=0.16110956417894118
2019-01-18 14:42:28,254 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:28,254 	 Computing Major Stats lazily... 
2019-01-18 14:42:28,255 		 Completed edges=272 good=272 bad=0
2019-01-18 14:42:28,258 Distortion avg=0.34558157344349655 wc=6.387677174403112 me=1.7195361709918073 mc=3.714767553112173 nan_elements=0
2019-01-18 14:42:28,258 MAP = 0.5516965877259995
2019-01-18 14:42:28,258 scale=[array([1.])]
2019-01-18 15:16:28,752 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1101.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1101.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:16:28,753 No Model Save selected!
