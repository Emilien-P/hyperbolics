2019-01-18 14:40:39,589 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/16.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/16.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:39,589 No Model Save selected!
2019-01-18 14:40:39,591 Loaded Graph data/edges/parsing/ewt/ewt_dev/16.edges with 30 nodes scale=1.0
2019-01-18 14:40:39,591 Building dataset
2019-01-18 14:40:39,591 Subsample: 30 points with scale 1.0 subsample=29
2019-01-18 14:40:39,632 Built Data Sampler
2019-01-18 14:40:39,632 Creating a fresh model warm_start?=None
2019-01-18 14:40:39,632 	 Warmstarting? None None 30
2019-01-18 14:40:39,632 Embedding() torch.Size([30, 10])
2019-01-18 14:40:39,632 relative No Rescale
2019-01-18 14:40:39,633 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:39,633 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:39,633 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:39,633 	 Computing Major Stats lazily... 
2019-01-18 14:40:39,637 		 Completed edges=870 good=870 bad=0
2019-01-18 14:40:39,643 Distortion avg=0.998620199907971 wc=28.32442179643951 me=0.007048654353541345 mc=4018.4154841142 nan_elements=0
2019-01-18 14:40:39,643 MAP = 0.15613921015704219
2019-01-18 14:40:39,643 scale=[array([1.])]
2019-01-18 14:40:39,643 *** End Initial Checkpoint

2019-01-18 14:40:39,704 1 loss=0.9972434510204905
2019-01-18 14:40:39,705 2 loss=0.9686586366343433
2019-01-18 14:40:39,706 3 loss=0.9409383135069355
2019-01-18 14:40:39,707 4 loss=0.9145894934884028
2019-01-18 14:40:39,708 5 loss=0.8896217500407207
2019-01-18 14:40:39,710 6 loss=0.8659839731620531
2019-01-18 14:40:39,711 7 loss=0.8436095623779365
2019-01-18 14:40:39,712 8 loss=0.8224281987552586
2019-01-18 14:40:39,713 9 loss=0.802370101803616
2019-01-18 14:40:39,714 10 loss=0.7833678152203991
2019-01-18 14:40:39,715 11 loss=0.7653569892180224
2019-01-18 14:40:39,716 12 loss=0.7482766980327713
2019-01-18 14:40:39,718 13 loss=0.7320695231408325
2019-01-18 14:40:39,719 14 loss=0.7166815122641538
2019-01-18 14:40:39,720 15 loss=0.7020620711534923
2019-01-18 14:40:39,721 16 loss=0.6881638194824832
2019-01-18 14:40:39,723 17 loss=0.6749424288647773
2019-01-18 14:40:39,724 18 loss=0.662356453676745
2019-01-18 14:40:39,725 19 loss=0.6503671611424406
2019-01-18 14:40:39,726 20 loss=0.6389383646072149
2019-01-18 14:40:39,727 21 loss=0.6280362623644824
2019-01-18 14:40:39,728 22 loss=0.6176292834129605
2019-01-18 14:40:39,729 23 loss=0.607687940886607
2019-01-18 14:40:39,730 24 loss=0.5981846934862327
2019-01-18 14:40:39,731 25 loss=0.5890938149715262
2019-01-18 14:40:39,732 26 loss=0.5803912715960247
2019-01-18 14:40:39,733 27 loss=0.5720546072541463
2019-01-18 14:40:39,734 28 loss=0.5640628360384963
2019-01-18 14:40:39,735 29 loss=0.5563963418637259
2019-01-18 14:40:39,737 30 loss=0.5490367847912071
2019-01-18 14:40:39,738 31 loss=0.541967013680439
2019-01-18 14:40:39,739 32 loss=0.5351709847941096
2019-01-18 14:40:39,740 33 loss=0.5286336859910966
2019-01-18 14:40:39,741 34 loss=0.5223410661532596
2019-01-18 14:40:39,743 35 loss=0.5162799695061561
2019-01-18 14:40:39,744 36 loss=0.5104380745097153
2019-01-18 14:40:39,745 37 loss=0.5048038370116829
2019-01-18 14:40:39,746 38 loss=0.49936643737374026
2019-01-18 14:40:39,747 39 loss=0.49411573129724207
2019-01-18 14:40:39,748 40 loss=0.48904220409221655
2019-01-18 14:40:39,749 41 loss=0.48413692814946957
2019-01-18 14:40:39,750 42 loss=0.4793915233911981
2019-01-18 14:40:39,751 43 loss=0.47479812049037057
2019-01-18 14:40:39,752 44 loss=0.4703493266632395
2019-01-18 14:40:39,753 45 loss=0.4660381938526847
2019-01-18 14:40:39,754 46 loss=0.46185818913266136
2019-01-18 14:40:39,755 47 loss=0.4578031671758285
2019-01-18 14:40:39,756 48 loss=0.45386734463751616
2019-01-18 14:40:39,757 49 loss=0.4500452763195491
2019-01-18 14:40:39,759 50 loss=0.44633183298712864
2019-01-18 14:40:39,759 final loss=0.44633183298712864
2019-01-18 14:40:39,759 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:39,759 	 Computing Major Stats lazily... 
2019-01-18 14:40:39,762 		 Completed edges=870 good=870 bad=0
2019-01-18 14:40:39,767 Distortion avg=0.6369679301957896 wc=21.45139444261815 me=1.8857938654946174 mc=11.375259425288112 nan_elements=0
2019-01-18 14:40:39,767 MAP = 0.08143929210412777
2019-01-18 14:40:39,768 scale=[array([1.])]
2019-01-18 15:20:11,055 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/16.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/16.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:20:11,056 No Model Save selected!
