2019-01-18 14:42:04,484 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1022.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1022.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:04,485 No Model Save selected!
2019-01-18 14:42:04,486 Loaded Graph data/edges/parsing/ewt/ewt_dev/1022.edges with 26 nodes scale=1.0
2019-01-18 14:42:04,486 Building dataset
2019-01-18 14:42:04,487 Subsample: 26 points with scale 1.0 subsample=25
2019-01-18 14:42:04,519 Built Data Sampler
2019-01-18 14:42:04,519 Creating a fresh model warm_start?=None
2019-01-18 14:42:04,519 	 Warmstarting? None None 26
2019-01-18 14:42:04,520 Embedding() torch.Size([26, 10])
2019-01-18 14:42:04,520 relative No Rescale
2019-01-18 14:42:04,520 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:04,520 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:04,520 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:04,520 	 Computing Major Stats lazily... 
2019-01-18 14:42:04,523 		 Completed edges=650 good=650 bad=0
2019-01-18 14:42:04,528 Distortion avg=0.998303748152682 wc=16.85256353916054 me=0.006841983940850235 mc=2463.110653993484 nan_elements=0
2019-01-18 14:42:04,528 MAP = 0.201234780985539
2019-01-18 14:42:04,528 scale=[array([1.])]
2019-01-18 14:42:04,528 *** End Initial Checkpoint

2019-01-18 14:42:04,586 1 loss=0.9966115123992398
2019-01-18 14:42:04,587 2 loss=0.9516958406517869
2019-01-18 14:42:04,588 3 loss=0.9086842579895072
2019-01-18 14:42:04,589 4 loss=0.868903161935905
2019-01-18 14:42:04,590 5 loss=0.8322201861996903
2019-01-18 14:42:04,591 6 loss=0.7983849637330489
2019-01-18 14:42:04,592 7 loss=0.7671396870509127
2019-01-18 14:42:04,593 8 loss=0.7382419594961391
2019-01-18 14:42:04,594 9 loss=0.7114703849011698
2019-01-18 14:42:04,595 10 loss=0.6866251510360077
2019-01-18 14:42:04,596 11 loss=0.6635269101972897
2019-01-18 14:42:04,596 12 loss=0.6420150843683767
2019-01-18 14:42:04,597 13 loss=0.6219460350746762
2019-01-18 14:42:04,598 14 loss=0.6031912810251633
2019-01-18 14:42:04,599 15 loss=0.5856358390100719
2019-01-18 14:42:04,600 16 loss=0.5691767150475974
2019-01-18 14:42:04,601 17 loss=0.5537215500713903
2019-01-18 14:42:04,602 18 loss=0.5391874138041167
2019-01-18 14:42:04,603 19 loss=0.5254997357393015
2019-01-18 14:42:04,604 20 loss=0.5125913604297838
2019-01-18 14:42:04,605 21 loss=0.5004017140893852
2019-01-18 14:42:04,605 22 loss=0.48887607009031764
2019-01-18 14:42:04,606 23 loss=0.4779649018737592
2019-01-18 14:42:04,607 24 loss=0.46762331286354125
2019-01-18 14:42:04,608 25 loss=0.45781053406354394
2019-01-18 14:42:04,609 26 loss=0.44848948106525427
2019-01-18 14:42:04,610 27 loss=0.4396263631620755
2019-01-18 14:42:04,611 28 loss=0.43119033814854657
2019-01-18 14:42:04,612 29 loss=0.42315320717299193
2019-01-18 14:42:04,613 30 loss=0.4154891447142553
2019-01-18 14:42:04,613 31 loss=0.4081744593729308
2019-01-18 14:42:04,614 32 loss=0.4011873817120588
2019-01-18 14:42:04,615 33 loss=0.39450787585918673
2019-01-18 14:42:04,616 34 loss=0.38811747199841473
2019-01-18 14:42:04,617 35 loss=0.3819991172445672
2019-01-18 14:42:04,618 36 loss=0.3761370427083922
2019-01-18 14:42:04,619 37 loss=0.37051664483750135
2019-01-18 14:42:04,620 38 loss=0.365124379357837
2019-01-18 14:42:04,621 39 loss=0.35994766634938696
2019-01-18 14:42:04,621 40 loss=0.3549748051717152
2019-01-18 14:42:04,622 41 loss=0.3501948981131907
2019-01-18 14:42:04,624 42 loss=0.3455977817756879
2019-01-18 14:42:04,625 43 loss=0.3411739653266766
2019-01-18 14:42:04,626 44 loss=0.3369145748553944
2019-01-18 14:42:04,626 45 loss=0.33281130316120616
2019-01-18 14:42:04,627 46 loss=0.3288563643820883
2019-01-18 14:42:04,628 47 loss=0.3250424529409506
2019-01-18 14:42:04,629 48 loss=0.32136270634854325
2019-01-18 14:42:04,630 49 loss=0.31781067145514497
2019-01-18 14:42:04,631 50 loss=0.3143802737900743
2019-01-18 14:42:04,631 final loss=0.3143802737900743
2019-01-18 14:42:04,631 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:04,631 	 Computing Major Stats lazily... 
2019-01-18 14:42:04,634 		 Completed edges=650 good=650 bad=0
2019-01-18 14:42:04,638 Distortion avg=0.5177106876802912 wc=12.026690859320297 me=1.6976601870551165 mc=7.08427455095278 nan_elements=0
2019-01-18 14:42:04,638 MAP = 0.1256811541857024
2019-01-18 14:42:04,639 scale=[array([1.])]
2019-01-18 15:25:03,648 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1022.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1022.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:25:03,649 No Model Save selected!
