2019-01-18 14:40:59,646 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1404.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1404.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:59,646 No Model Save selected!
2019-01-18 14:40:59,648 Loaded Graph data/edges/parsing/ewt/ewt_dev/1404.edges with 13 nodes scale=1.0
2019-01-18 14:40:59,648 Building dataset
2019-01-18 14:40:59,649 Subsample: 13 points with scale 1.0 subsample=12
2019-01-18 14:40:59,660 Built Data Sampler
2019-01-18 14:40:59,661 Creating a fresh model warm_start?=None
2019-01-18 14:40:59,661 	 Warmstarting? None None 13
2019-01-18 14:40:59,661 Embedding() torch.Size([13, 10])
2019-01-18 14:40:59,661 relative No Rescale
2019-01-18 14:40:59,662 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:59,662 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:59,662 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:59,662 	 Computing Major Stats lazily... 
2019-01-18 14:40:59,663 		 Completed edges=156 good=156 bad=0
2019-01-18 14:40:59,665 Distortion avg=0.9982196124502946 wc=15.817928602362903 me=0.005935337598003825 mc=2665.042778305112 nan_elements=0
2019-01-18 14:40:59,665 MAP = 0.343975468975469
2019-01-18 14:40:59,666 scale=[array([1.])]
2019-01-18 14:40:59,666 *** End Initial Checkpoint

2019-01-18 14:40:59,724 1 loss=0.9964440141442891
2019-01-18 14:40:59,724 2 loss=0.8854615547670053
2019-01-18 14:40:59,725 3 loss=0.7907924320015928
2019-01-18 14:40:59,726 4 loss=0.714121611496526
2019-01-18 14:40:59,726 5 loss=0.6524543823631038
2019-01-18 14:40:59,727 6 loss=0.6028084552071147
2019-01-18 14:40:59,727 7 loss=0.5626737110572012
2019-01-18 14:40:59,728 8 loss=0.5300274725138923
2019-01-18 14:40:59,728 9 loss=0.503267694371621
2019-01-18 14:40:59,729 10 loss=0.4811357945556525
2019-01-18 14:40:59,730 11 loss=0.46264706531870875
2019-01-18 14:40:59,730 12 loss=0.44703258340727403
2019-01-18 14:40:59,731 13 loss=0.4336923263763819
2019-01-18 14:40:59,731 14 loss=0.4221579828623511
2019-01-18 14:40:59,732 15 loss=0.4120637388434568
2019-01-18 14:40:59,732 16 loss=0.403123461631596
2019-01-18 14:40:59,733 17 loss=0.39511294263861735
2019-01-18 14:40:59,733 18 loss=0.387856105977459
2019-01-18 14:40:59,734 19 loss=0.38121430959154373
2019-01-18 14:40:59,735 20 loss=0.3750780499278079
2019-01-18 14:40:59,735 21 loss=0.36936053089516835
2019-01-18 14:40:59,736 22 loss=0.3639926771809014
2019-01-18 14:40:59,736 23 loss=0.35891926598372764
2019-01-18 14:40:59,737 24 loss=0.3540959246832725
2019-01-18 14:40:59,737 25 loss=0.34948679909518043
2019-01-18 14:40:59,738 26 loss=0.3450627412430614
2019-01-18 14:40:59,738 27 loss=0.3407998998287591
2019-01-18 14:40:59,739 28 loss=0.33667862303954144
2019-01-18 14:40:59,740 29 loss=0.33268260375432473
2019-01-18 14:40:59,740 30 loss=0.32879821297396505
2019-01-18 14:40:59,741 31 loss=0.32501397946881216
2019-01-18 14:40:59,741 32 loss=0.3213201830347492
2019-01-18 14:40:59,742 33 loss=0.3177085360133
2019-01-18 14:40:59,742 34 loss=0.3141719333526486
2019-01-18 14:40:59,743 35 loss=0.3107042558423538
2019-01-18 14:40:59,744 36 loss=0.3073002145359252
2019-01-18 14:40:59,744 37 loss=0.3039552270060068
2019-01-18 14:40:59,745 38 loss=0.30066531812876984
2019-01-18 14:40:59,745 39 loss=0.2974270396995629
2019-01-18 14:40:59,746 40 loss=0.2942374044424677
2019-01-18 14:40:59,747 41 loss=0.2910938309700617
2019-01-18 14:40:59,747 42 loss=0.28799409703594836
2019-01-18 14:40:59,748 43 loss=0.2849362990469151
2019-01-18 14:40:59,748 44 loss=0.28191881629847393
2019-01-18 14:40:59,749 45 loss=0.27894027879326394
2019-01-18 14:40:59,749 46 loss=0.2759995378162666
2019-01-18 14:40:59,750 47 loss=0.27309563868916953
2019-01-18 14:40:59,750 48 loss=0.2702277953202568
2019-01-18 14:40:59,751 49 loss=0.26739536631501754
2019-01-18 14:40:59,752 50 loss=0.2645978325237063
2019-01-18 14:40:59,752 final loss=0.2645978325237063
2019-01-18 14:40:59,752 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:59,752 	 Computing Major Stats lazily... 
2019-01-18 14:40:59,753 		 Completed edges=156 good=156 bad=0
2019-01-18 14:40:59,755 Distortion avg=0.45320210760766855 wc=8.807324113834916 me=1.6495249261688936 mc=5.339309503064243 nan_elements=0
2019-01-18 14:40:59,755 MAP = 0.584065934065934
2019-01-18 14:40:59,755 scale=[array([1.])]
2019-01-18 15:23:42,086 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1404.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1404.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:23:42,087 No Model Save selected!
