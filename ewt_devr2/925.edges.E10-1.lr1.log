2019-01-18 14:40:40,902 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/925.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/925.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:40:40,902 No Model Save selected!
2019-01-18 14:40:40,904 Loaded Graph data/edges/parsing/ewt/ewt_dev/925.edges with 29 nodes scale=1.0
2019-01-18 14:40:40,904 Building dataset
2019-01-18 14:40:40,904 Subsample: 29 points with scale 1.0 subsample=28
2019-01-18 14:40:40,943 Built Data Sampler
2019-01-18 14:40:40,943 Creating a fresh model warm_start?=None
2019-01-18 14:40:40,943 	 Warmstarting? None None 29
2019-01-18 14:40:40,943 Embedding() torch.Size([29, 10])
2019-01-18 14:40:40,943 relative No Rescale
2019-01-18 14:40:40,944 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:40:40,944 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:40:40,944 *** Initial Checkpoint. Computing Stats
2019-01-18 14:40:40,944 	 Computing Major Stats lazily... 
2019-01-18 14:40:40,948 		 Completed edges=812 good=812 bad=0
2019-01-18 14:40:40,952 Distortion avg=0.9985191888498176 wc=16.85256353916054 me=0.006841983940850235 mc=2463.110653993484 nan_elements=0
2019-01-18 14:40:40,952 MAP = 0.21177632864664347
2019-01-18 14:40:40,953 scale=[array([1.])]
2019-01-18 14:40:40,953 *** End Initial Checkpoint

2019-01-18 14:40:41,011 1 loss=0.9970415440817488
2019-01-18 14:40:41,013 2 loss=0.9632197658285288
2019-01-18 14:40:41,014 3 loss=0.9302597735367633
2019-01-18 14:40:41,015 4 loss=0.8990878623810094
2019-01-18 14:40:41,016 5 loss=0.8697346202790177
2019-01-18 14:40:41,017 6 loss=0.8421259917590067
2019-01-18 14:40:41,018 7 loss=0.816162396408788
2019-01-18 14:40:41,019 8 loss=0.7917389244442535
2019-01-18 14:40:41,020 9 loss=0.7687524283757555
2019-01-18 14:40:41,021 10 loss=0.7471043505994306
2019-01-18 14:40:41,022 11 loss=0.726701846369731
2019-01-18 14:40:41,023 12 loss=0.7074581362296012
2019-01-18 14:40:41,024 13 loss=0.6892924845415779
2019-01-18 14:40:41,025 14 loss=0.6721299912754225
2019-01-18 14:40:41,026 15 loss=0.6559012922269674
2019-01-18 14:40:41,027 16 loss=0.6405422186582299
2019-01-18 14:40:41,028 17 loss=0.6259934445977081
2019-01-18 14:40:41,029 18 loss=0.612200137673811
2019-01-18 14:40:41,030 19 loss=0.5991116223460665
2019-01-18 14:40:41,032 20 loss=0.5866810603003085
2019-01-18 14:40:41,033 21 loss=0.5748651503245396
2019-01-18 14:40:41,034 22 loss=0.5636238485002006
2019-01-18 14:40:41,035 23 loss=0.55292010864577
2019-01-18 14:40:41,036 24 loss=0.5427196424124032
2019-01-18 14:40:41,037 25 loss=0.5329906981206698
2019-01-18 14:40:41,038 26 loss=0.5237038572605895
2019-01-18 14:40:41,039 27 loss=0.514831847502226
2019-01-18 14:40:41,040 28 loss=0.5063493710476639
2019-01-18 14:40:41,041 29 loss=0.4982329471757037
2019-01-18 14:40:41,042 30 loss=0.49046076787376597
2019-01-18 14:40:41,043 31 loss=0.48301256550797095
2019-01-18 14:40:41,044 32 loss=0.4758694915458454
2019-01-18 14:40:41,045 33 loss=0.4690140054125212
2019-01-18 14:40:41,046 34 loss=0.46242977262787816
2019-01-18 14:40:41,047 35 loss=0.45610157143714825
2019-01-18 14:40:41,048 36 loss=0.4500152072098574
2019-01-18 14:40:41,049 37 loss=0.4441574339410882
2019-01-18 14:40:41,050 38 loss=0.43851588224447663
2019-01-18 14:40:41,051 39 loss=0.43307899327800264
2019-01-18 14:40:41,052 40 loss=0.4278359580915254
2019-01-18 14:40:41,053 41 loss=0.4227766619291813
2019-01-18 14:40:41,054 42 loss=0.41789163306043225
2019-01-18 14:40:41,055 43 loss=0.4131719957508475
2019-01-18 14:40:41,056 44 loss=0.40860942701787306
2019-01-18 14:40:41,057 45 loss=0.40419611684808165
2019-01-18 14:40:41,058 46 loss=0.39992473158092134
2019-01-18 14:40:41,059 47 loss=0.39578838019001167
2019-01-18 14:40:41,060 48 loss=0.39178058321674575
2019-01-18 14:40:41,062 49 loss=0.3878952441325877
2019-01-18 14:40:41,063 50 loss=0.38412662292610844
2019-01-18 14:40:41,063 final loss=0.38412662292610844
2019-01-18 14:40:41,063 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:40:41,063 	 Computing Major Stats lazily... 
2019-01-18 14:40:41,066 		 Completed edges=812 good=812 bad=0
2019-01-18 14:40:41,071 Distortion avg=0.5861677933090256 wc=16.827657293034132 me=1.8227200787083289 mc=9.232167621129767 nan_elements=0
2019-01-18 14:40:41,071 MAP = 0.08786264410084355
2019-01-18 14:40:41,071 scale=[array([1.])]
2019-01-18 15:14:33,349 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/925.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/925.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:14:33,350 No Model Save selected!
