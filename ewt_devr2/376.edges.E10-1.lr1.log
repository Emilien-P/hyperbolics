2019-01-18 14:42:16,782 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/376.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/376.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:16,782 No Model Save selected!
2019-01-18 14:42:16,783 Loaded Graph data/edges/parsing/ewt/ewt_dev/376.edges with 19 nodes scale=1.0
2019-01-18 14:42:16,783 Building dataset
2019-01-18 14:42:16,784 Subsample: 19 points with scale 1.0 subsample=18
2019-01-18 14:42:16,803 Built Data Sampler
2019-01-18 14:42:16,803 Creating a fresh model warm_start?=None
2019-01-18 14:42:16,804 	 Warmstarting? None None 19
2019-01-18 14:42:16,804 Embedding() torch.Size([19, 10])
2019-01-18 14:42:16,804 relative No Rescale
2019-01-18 14:42:16,804 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:16,805 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:16,805 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:16,805 	 Computing Major Stats lazily... 
2019-01-18 14:42:16,807 		 Completed edges=342 good=342 bad=0
2019-01-18 14:42:16,810 Distortion avg=0.9982907790215955 wc=13.824577256964519 me=0.00582765269827822 mc=2372.2376697309005 nan_elements=0
2019-01-18 14:42:16,810 MAP = 0.29955376208472184
2019-01-18 14:42:16,810 scale=[array([1.])]
2019-01-18 14:42:16,810 *** End Initial Checkpoint

2019-01-18 14:42:16,868 1 loss=0.996585678464919
2019-01-18 14:42:16,869 2 loss=0.9284618741328784
2019-01-18 14:42:16,869 3 loss=0.8655229091201099
2019-01-18 14:42:16,870 4 loss=0.8097575711495558
2019-01-18 14:42:16,871 5 loss=0.7605485734947857
2019-01-18 14:42:16,871 6 loss=0.7170950568397482
2019-01-18 14:42:16,872 7 loss=0.6786391625772253
2019-01-18 14:42:16,873 8 loss=0.6445078990303142
2019-01-18 14:42:16,874 9 loss=0.6141167662336056
2019-01-18 14:42:16,874 10 loss=0.5869629257716195
2019-01-18 14:42:16,875 11 loss=0.5626156487732784
2019-01-18 14:42:16,876 12 loss=0.5407066185240362
2019-01-18 14:42:16,876 13 loss=0.5209209882601088
2019-01-18 14:42:16,877 14 loss=0.5029894701729013
2019-01-18 14:42:16,878 15 loss=0.4866814825100849
2019-01-18 14:42:16,879 16 loss=0.4717992823737827
2019-01-18 14:42:16,879 17 loss=0.4581729766971825
2019-01-18 14:42:16,880 18 loss=0.4456562971510575
2019-01-18 14:42:16,881 19 loss=0.43412303041832645
2019-01-18 14:42:16,882 20 loss=0.42346400593239086
2019-01-18 14:42:16,882 21 loss=0.41358455526605353
2019-01-18 14:42:16,883 22 loss=0.4044023692198577
2019-01-18 14:42:16,884 23 loss=0.39584568955636507
2019-01-18 14:42:16,884 24 loss=0.3878517819894601
2019-01-18 14:42:16,885 25 loss=0.3803656454257305
2019-01-18 14:42:16,886 26 loss=0.3733389196391758
2019-01-18 14:42:16,887 27 loss=0.3667289596593645
2019-01-18 14:42:16,887 28 loss=0.3604980502995634
2019-01-18 14:42:16,888 29 loss=0.35461273857631154
2019-01-18 14:42:16,889 30 loss=0.34904326539628333
2019-01-18 14:42:16,889 31 loss=0.3437630809179297
2019-01-18 14:42:16,890 32 loss=0.338748430528213
2019-01-18 14:42:16,891 33 loss=0.33397800048942206
2019-01-18 14:42:16,891 34 loss=0.3294326140761277
2019-01-18 14:42:16,892 35 loss=0.32509497049567926
2019-01-18 14:42:16,893 36 loss=0.320949420115824
2019-01-18 14:42:16,893 37 loss=0.3169817705507087
2019-01-18 14:42:16,894 38 loss=0.313179119015601
2019-01-18 14:42:16,895 39 loss=0.3095297070793903
2019-01-18 14:42:16,896 40 loss=0.3060227945457946
2019-01-18 14:42:16,896 41 loss=0.30264854969871335
2019-01-18 14:42:16,897 42 loss=0.2993979535705595
2019-01-18 14:42:16,898 43 loss=0.2962627162481279
2019-01-18 14:42:16,898 44 loss=0.29323520352981297
2019-01-18 14:42:16,899 45 loss=0.2903083725000391
2019-01-18 14:42:16,900 46 loss=0.28747571479937173
2019-01-18 14:42:16,900 47 loss=0.28473120654831724
2019-01-18 14:42:16,901 48 loss=0.282069264034674
2019-01-18 14:42:16,902 49 loss=0.2794847044028887
2019-01-18 14:42:16,902 50 loss=0.27697271069293183
2019-01-18 14:42:16,903 final loss=0.27697271069293183
2019-01-18 14:42:16,903 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:16,903 	 Computing Major Stats lazily... 
2019-01-18 14:42:16,904 		 Completed edges=342 good=342 bad=0
2019-01-18 14:42:16,907 Distortion avg=0.47955334768245605 wc=10.672673066453072 me=1.7404227796500882 mc=6.1322301634082335 nan_elements=0
2019-01-18 14:42:16,907 MAP = 0.24944596339333178
2019-01-18 14:42:16,907 scale=[array([1.])]
2019-01-18 15:22:23,787 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/376.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/376.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:22:23,788 No Model Save selected!
