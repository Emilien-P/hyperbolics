2019-01-18 14:41:10,883 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1283.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1283.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:10,883 No Model Save selected!
2019-01-18 14:41:10,885 Loaded Graph data/edges/parsing/ewt/ewt_dev/1283.edges with 6 nodes scale=1.0
2019-01-18 14:41:10,885 Building dataset
2019-01-18 14:41:10,885 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:41:10,890 Built Data Sampler
2019-01-18 14:41:10,890 Creating a fresh model warm_start?=None
2019-01-18 14:41:10,890 	 Warmstarting? None None 6
2019-01-18 14:41:10,890 Embedding() torch.Size([6, 10])
2019-01-18 14:41:10,890 relative No Rescale
2019-01-18 14:41:10,891 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:10,891 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:10,891 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:10,891 	 Computing Major Stats lazily... 
2019-01-18 14:41:10,892 		 Completed edges=30 good=30 bad=0
2019-01-18 14:41:10,893 Distortion avg=0.9970831198655035 wc=5.448327215027938 me=0.005628252251848828 mc=968.0318100949036 nan_elements=0
2019-01-18 14:41:10,893 MAP = 0.3673611111111111
2019-01-18 14:41:10,893 scale=[array([1.])]
2019-01-18 14:41:10,893 *** End Initial Checkpoint

2019-01-18 14:41:10,951 1 loss=0.9941769604494649
2019-01-18 14:41:10,951 2 loss=0.4635441691317516
2019-01-18 14:41:10,952 3 loss=0.31525202916545497
2019-01-18 14:41:10,952 4 loss=0.2517268731485578
2019-01-18 14:41:10,953 5 loss=0.21108416500882515
2019-01-18 14:41:10,953 6 loss=0.18122722499383753
2019-01-18 14:41:10,953 7 loss=0.15828918155714375
2019-01-18 14:41:10,954 8 loss=0.14019266646627662
2019-01-18 14:41:10,954 9 loss=0.12550308167145674
2019-01-18 14:41:10,955 10 loss=0.11318669104455176
2019-01-18 14:41:10,955 11 loss=0.10252813523786034
2019-01-18 14:41:10,956 12 loss=0.09306576654852697
2019-01-18 14:41:10,956 13 loss=0.08452511825515988
2019-01-18 14:41:10,957 14 loss=0.07675588495114484
2019-01-18 14:41:10,957 15 loss=0.06967971253491857
2019-01-18 14:41:10,957 16 loss=0.0632525585402023
2019-01-18 14:41:10,958 17 loss=0.05744144103188922
2019-01-18 14:41:10,958 18 loss=0.052212746174625034
2019-01-18 14:41:10,959 19 loss=0.04752828453739764
2019-01-18 14:41:10,959 20 loss=0.04334560099376466
2019-01-18 14:41:10,960 21 loss=0.039619999109477076
2019-01-18 14:41:10,960 22 loss=0.03630677978243646
2019-01-18 14:41:10,961 23 loss=0.033363008998340674
2019-01-18 14:41:10,961 24 loss=0.03074863971179027
2019-01-18 14:41:10,961 25 loss=0.02842706533267041
2019-01-18 14:41:10,962 26 loss=0.026365265958174792
2019-01-18 14:41:10,962 27 loss=0.024533704009314372
2019-01-18 14:41:10,963 28 loss=0.022906088152048924
2019-01-18 14:41:10,963 29 loss=0.021459083027150206
2019-01-18 14:41:10,964 30 loss=0.020172009485091808
2019-01-18 14:41:10,964 31 loss=0.019026558031349557
2019-01-18 14:41:10,965 32 loss=0.01800652516614223
2019-01-18 14:41:10,965 33 loss=0.0170975753889407
2019-01-18 14:41:10,965 34 loss=0.01628702836812967
2019-01-18 14:41:10,966 35 loss=0.015563669454023217
2019-01-18 14:41:10,966 36 loss=0.014917581327572975
2019-01-18 14:41:10,967 37 loss=0.014339994590273334
2019-01-18 14:41:10,967 38 loss=0.01382315525708787
2019-01-18 14:41:10,968 39 loss=0.013360207305555448
2019-01-18 14:41:10,968 40 loss=0.012945088621465824
2019-01-18 14:41:10,969 41 loss=0.01257243885380919
2019-01-18 14:41:10,969 42 loss=0.012237517848009666
2019-01-18 14:41:10,970 43 loss=0.011936133468046008
2019-01-18 14:41:10,970 44 loss=0.011664577746325329
2019-01-18 14:41:10,971 45 loss=0.011419570416146116
2019-01-18 14:41:10,971 46 loss=0.011198208986084942
2019-01-18 14:41:10,972 47 loss=0.01099792460941962
2019-01-18 14:41:10,972 48 loss=0.010816443085544117
2019-01-18 14:41:10,972 49 loss=0.01065175040505719
2019-01-18 14:41:10,973 50 loss=0.010502062316664005
2019-01-18 14:41:10,973 final loss=0.010502062316664005
2019-01-18 14:41:10,973 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:10,973 	 Computing Major Stats lazily... 
2019-01-18 14:41:10,973 		 Completed edges=30 good=30 bad=0
2019-01-18 14:41:10,974 Distortion avg=0.09637164205233899 wc=1.3000620645469332 me=1.1333394231795701 mc=1.1471074225050997 nan_elements=0
2019-01-18 14:41:10,975 MAP = 1.0
2019-01-18 14:41:10,975 scale=[array([1.])]
2019-01-18 15:14:24,217 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1283.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1283.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:14:24,219 No Model Save selected!
