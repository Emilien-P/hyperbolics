2019-01-18 14:39:33,106 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/425.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/425.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:39:33,106 No Model Save selected!
2019-01-18 14:39:33,108 Loaded Graph data/edges/parsing/ewt/ewt_dev/425.edges with 11 nodes scale=1.0
2019-01-18 14:39:33,108 Building dataset
2019-01-18 14:39:33,108 Subsample: 11 points with scale 1.0 subsample=10
2019-01-18 14:39:33,118 Built Data Sampler
2019-01-18 14:39:33,118 Creating a fresh model warm_start?=None
2019-01-18 14:39:33,118 	 Warmstarting? None None 11
2019-01-18 14:39:33,119 Embedding() torch.Size([11, 10])
2019-01-18 14:39:33,119 relative No Rescale
2019-01-18 14:39:33,119 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:39:33,119 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:39:33,119 *** Initial Checkpoint. Computing Stats
2019-01-18 14:39:33,119 	 Computing Major Stats lazily... 
2019-01-18 14:39:33,120 		 Completed edges=110 good=110 bad=0
2019-01-18 14:39:33,122 Distortion avg=0.9979040653253441 wc=8.102763644702978 me=0.005982886981094694 mc=1354.323367683006 nan_elements=0
2019-01-18 14:39:33,122 MAP = 0.3663660413660414
2019-01-18 14:39:33,123 scale=[array([1.])]
2019-01-18 14:39:33,123 *** End Initial Checkpoint

2019-01-18 14:39:33,181 1 loss=0.9958140947421993
2019-01-18 14:39:33,182 2 loss=0.8146913715905196
2019-01-18 14:39:33,182 3 loss=0.6798236305005054
2019-01-18 14:39:33,183 4 loss=0.5841477273890674
2019-01-18 14:39:33,183 5 loss=0.5153730655357098
2019-01-18 14:39:33,184 6 loss=0.46475117724127785
2019-01-18 14:39:33,184 7 loss=0.4264089224661661
2019-01-18 14:39:33,185 8 loss=0.3964525250662306
2019-01-18 14:39:33,185 9 loss=0.37230204874815426
2019-01-18 14:39:33,186 10 loss=0.35224048225236626
2019-01-18 14:39:33,186 11 loss=0.3351165761820492
2019-01-18 14:39:33,187 12 loss=0.32015079060973517
2019-01-18 14:39:33,188 13 loss=0.3068088179685914
2019-01-18 14:39:33,188 14 loss=0.2947190397030975
2019-01-18 14:39:33,189 15 loss=0.2836185043124963
2019-01-18 14:39:33,189 16 loss=0.2733174517586955
2019-01-18 14:39:33,190 17 loss=0.2636759352169369
2019-01-18 14:39:33,190 18 loss=0.25458836189772605
2019-01-18 14:39:33,191 19 loss=0.24597323555824846
2019-01-18 14:39:33,191 20 loss=0.23776632524010718
2019-01-18 14:39:33,192 21 loss=0.22991609446569838
2019-01-18 14:39:33,193 22 loss=0.2223806217061962
2019-01-18 14:39:33,193 23 loss=0.2151255023172809
2019-01-18 14:39:33,194 24 loss=0.20812239283973447
2019-01-18 14:39:33,194 25 loss=0.20134797171145774
2019-01-18 14:39:33,195 26 loss=0.1947831660894057
2019-01-18 14:39:33,195 27 loss=0.18841254558197368
2019-01-18 14:39:33,196 28 loss=0.1822238185972394
2019-01-18 14:39:33,196 29 loss=0.1762073910855254
2019-01-18 14:39:33,197 30 loss=0.17035596412084275
2019-01-18 14:39:33,197 31 loss=0.16466415820515887
2019-01-18 14:39:33,198 32 loss=0.15912815979695125
2019-01-18 14:39:33,199 33 loss=0.15374539030581258
2019-01-18 14:39:33,199 34 loss=0.14851420034591212
2019-01-18 14:39:33,200 35 loss=0.14343359295482871
2019-01-18 14:39:33,200 36 loss=0.13850297923625726
2019-01-18 14:39:33,201 37 loss=0.1337219688941921
2019-01-18 14:39:33,201 38 loss=0.1290901967517011
2019-01-18 14:39:33,202 39 loss=0.12460718487908565
2019-01-18 14:39:33,202 40 loss=0.12027223860675156
2019-01-18 14:39:33,203 41 loss=0.11608437360292127
2019-01-18 14:39:33,203 42 loss=0.11204227042134522
2019-01-18 14:39:33,204 43 loss=0.10814425247945232
2019-01-18 14:39:33,205 44 loss=0.1043882832833237
2019-01-18 14:39:33,205 45 loss=0.10077197881927442
2019-01-18 14:39:33,206 46 loss=0.0972926313195246
2019-01-18 14:39:33,206 47 loss=0.09394724101854879
2019-01-18 14:39:33,207 48 loss=0.09073255299126493
2019-01-18 14:39:33,207 49 loss=0.08764509665876004
2019-01-18 14:39:33,208 50 loss=0.08468122602773161
2019-01-18 14:39:33,208 final loss=0.08468122602773161
2019-01-18 14:39:33,208 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:39:33,208 	 Computing Major Stats lazily... 
2019-01-18 14:39:33,209 		 Completed edges=110 good=110 bad=0
2019-01-18 14:39:33,210 Distortion avg=0.25306866761122565 wc=3.6592092677359074 me=1.380934785324526 mc=2.649805991291599 nan_elements=0
2019-01-18 14:39:33,211 MAP = 1.0
2019-01-18 14:39:33,211 scale=[array([1.])]
2019-01-18 15:17:52,786 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/425.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/425.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:17:52,787 No Model Save selected!
