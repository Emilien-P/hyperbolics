2019-01-18 14:41:28,173 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/152.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/152.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:41:28,173 No Model Save selected!
2019-01-18 14:41:28,175 Loaded Graph data/edges/parsing/ewt/ewt_dev/152.edges with 9 nodes scale=1.0
2019-01-18 14:41:28,175 Building dataset
2019-01-18 14:41:28,175 Subsample: 9 points with scale 1.0 subsample=8
2019-01-18 14:41:28,182 Built Data Sampler
2019-01-18 14:41:28,182 Creating a fresh model warm_start?=None
2019-01-18 14:41:28,183 	 Warmstarting? None None 9
2019-01-18 14:41:28,183 Embedding() torch.Size([9, 10])
2019-01-18 14:41:28,183 relative No Rescale
2019-01-18 14:41:28,183 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:41:28,184 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:41:28,184 *** Initial Checkpoint. Computing Stats
2019-01-18 14:41:28,184 	 Computing Major Stats lazily... 
2019-01-18 14:41:28,185 		 Completed edges=72 good=72 bad=0
2019-01-18 14:41:28,187 Distortion avg=0.9977250562991993 wc=7.128524246500089 me=0.005200518808456536 mc=1370.7332881689483 nan_elements=0
2019-01-18 14:41:28,187 MAP = 0.34581128747795414
2019-01-18 14:41:28,187 scale=[array([1.])]
2019-01-18 14:41:28,187 *** End Initial Checkpoint

2019-01-18 14:41:28,245 1 loss=0.9954570330244502
2019-01-18 14:41:28,246 2 loss=0.754366307979124
2019-01-18 14:41:28,246 3 loss=0.5967906173724093
2019-01-18 14:41:28,247 4 loss=0.49879996763875106
2019-01-18 14:41:28,247 5 loss=0.43577840445230454
2019-01-18 14:41:28,248 6 loss=0.39314639020334075
2019-01-18 14:41:28,248 7 loss=0.3626112869198303
2019-01-18 14:41:28,249 8 loss=0.33946730076470466
2019-01-18 14:41:28,250 9 loss=0.32101776942931
2019-01-18 14:41:28,250 10 loss=0.30569034771404524
2019-01-18 14:41:28,251 11 loss=0.29254536233622885
2019-01-18 14:41:28,251 12 loss=0.28100233873711267
2019-01-18 14:41:28,252 13 loss=0.27068714349074824
2019-01-18 14:41:28,252 14 loss=0.2613460547281151
2019-01-18 14:41:28,253 15 loss=0.25279721300894353
2019-01-18 14:41:28,253 16 loss=0.2449030898010556
2019-01-18 14:41:28,254 17 loss=0.23755483084403917
2019-01-18 14:41:28,254 18 loss=0.23066331789194583
2019-01-18 14:41:28,255 19 loss=0.2241540177311895
2019-01-18 14:41:28,255 20 loss=0.21796394487107013
2019-01-18 14:41:28,256 21 loss=0.212039782917445
2019-01-18 14:41:28,256 22 loss=0.20633662390390922
2019-01-18 14:41:28,257 23 loss=0.20081702480286712
2019-01-18 14:41:28,257 24 loss=0.19545021932799692
2019-01-18 14:41:28,258 25 loss=0.19021140290881752
2019-01-18 14:41:28,258 26 loss=0.18508105372287648
2019-01-18 14:41:28,259 27 loss=0.18004427721669827
2019-01-18 14:41:28,259 28 loss=0.17509017410249336
2019-01-18 14:41:28,260 29 loss=0.17021123742372554
2019-01-18 14:41:28,260 30 loss=0.1654027859475219
2019-01-18 14:41:28,261 31 loss=0.16066244066498322
2019-01-18 14:41:28,261 32 loss=0.15598964963877734
2019-01-18 14:41:28,262 33 loss=0.15138526447431783
2019-01-18 14:41:28,262 34 loss=0.1468511696868226
2019-01-18 14:41:28,263 35 loss=0.14238996441023624
2019-01-18 14:41:28,264 36 loss=0.13800469436205595
2019-01-18 14:41:28,264 37 loss=0.13369863079121627
2019-01-18 14:41:28,265 38 loss=0.12947509230151633
2019-01-18 14:41:28,265 39 loss=0.1253373049389375
2019-01-18 14:41:28,266 40 loss=0.12128829571762845
2019-01-18 14:41:28,266 41 loss=0.11733081478599579
2019-01-18 14:41:28,267 42 loss=0.11346728164685185
2019-01-18 14:41:28,267 43 loss=0.10969975119040755
2019-01-18 14:41:28,268 44 loss=0.10602989572700901
2019-01-18 14:41:28,268 45 loss=0.10245899967574965
2019-01-18 14:41:28,269 46 loss=0.0989879640414734
2019-01-18 14:41:28,269 47 loss=0.09561731827072345
2019-01-18 14:41:28,270 48 loss=0.09234723749943402
2019-01-18 14:41:28,270 49 loss=0.08917756358122089
2019-01-18 14:41:28,271 50 loss=0.08610782861041293
2019-01-18 14:41:28,271 final loss=0.08610782861041293
2019-01-18 14:41:28,271 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:41:28,271 	 Computing Major Stats lazily... 
2019-01-18 14:41:28,271 		 Completed edges=72 good=72 bad=0
2019-01-18 14:41:28,273 Distortion avg=0.2529770450491384 wc=2.660739450791342 me=1.2815595409453626 mc=2.076173104550886 nan_elements=0
2019-01-18 14:41:28,273 MAP = 1.0
2019-01-18 14:41:28,273 scale=[array([1.])]
2019-01-18 15:13:44,957 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/152.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/152.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:13:44,959 No Model Save selected!
