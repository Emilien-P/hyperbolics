2019-01-18 14:42:33,077 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1987.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1987.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 14:42:33,077 No Model Save selected!
2019-01-18 14:42:33,078 Loaded Graph data/edges/parsing/ewt/ewt_dev/1987.edges with 6 nodes scale=1.0
2019-01-18 14:42:33,079 Building dataset
2019-01-18 14:42:33,079 Subsample: 6 points with scale 1.0 subsample=5
2019-01-18 14:42:33,084 Built Data Sampler
2019-01-18 14:42:33,084 Creating a fresh model warm_start?=None
2019-01-18 14:42:33,084 	 Warmstarting? None None 6
2019-01-18 14:42:33,084 Embedding() torch.Size([6, 10])
2019-01-18 14:42:33,084 relative No Rescale
2019-01-18 14:42:33,085 Constructed model with dim=0 and epochs=0 isnan=False
2019-01-18 14:42:33,085 SGD (
Parameter Group 0
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 1
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 2
    dampening: 0
    initial_lr: 0.1
    lr: 1.0
    momentum: 0.0
    nesterov: False
    weight_decay: 0

Parameter Group 3
    dampening: 0
    initial_lr: 0.0001
    lr: 0.001
    momentum: 0.0
    nesterov: False
    weight_decay: 0
)
2019-01-18 14:42:33,085 *** Initial Checkpoint. Computing Stats
2019-01-18 14:42:33,085 	 Computing Major Stats lazily... 
2019-01-18 14:42:33,086 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:33,087 Distortion avg=0.9971468202815983 wc=4.429205455045332 me=0.005628252251848828 mc=786.9593004809583 nan_elements=0
2019-01-18 14:42:33,087 MAP = 0.45555555555555555
2019-01-18 14:42:33,087 scale=[array([1.])]
2019-01-18 14:42:33,087 *** End Initial Checkpoint

2019-01-18 14:42:33,145 1 loss=0.9943036683992853
2019-01-18 14:42:33,145 2 loss=0.46895896591539044
2019-01-18 14:42:33,146 3 loss=0.31363130427147967
2019-01-18 14:42:33,146 4 loss=0.24545644610691483
2019-01-18 14:42:33,147 5 loss=0.20155096324716354
2019-01-18 14:42:33,147 6 loss=0.1692022535367684
2019-01-18 14:42:33,148 7 loss=0.14425605440645312
2019-01-18 14:42:33,148 8 loss=0.12451900914960287
2019-01-18 14:42:33,148 9 loss=0.10854229711055983
2019-01-18 14:42:33,149 10 loss=0.09532524168088893
2019-01-18 14:42:33,149 11 loss=0.08418674327181588
2019-01-18 14:42:33,150 12 loss=0.07467106007349288
2019-01-18 14:42:33,150 13 loss=0.06647133706733972
2019-01-18 14:42:33,151 14 loss=0.05937249107738991
2019-01-18 14:42:33,151 15 loss=0.053213326512301505
2019-01-18 14:42:33,152 16 loss=0.04786428688536967
2019-01-18 14:42:33,152 17 loss=0.04321585436073805
2019-01-18 14:42:33,152 18 loss=0.0391731027516297
2019-01-18 14:42:33,153 19 loss=0.035653235479523475
2019-01-18 14:42:33,154 20 loss=0.03258427463893052
2019-01-18 14:42:33,154 21 loss=0.029904039464066116
2019-01-18 14:42:33,155 22 loss=0.027559119031961014
2019-01-18 14:42:33,155 23 loss=0.02550380751025718
2019-01-18 14:42:33,155 24 loss=0.023699056087215238
2019-01-18 14:42:33,156 25 loss=0.02211149915850871
2019-01-18 14:42:33,156 26 loss=0.020712589348120754
2019-01-18 14:42:33,157 27 loss=0.01947785240285258
2019-01-18 14:42:33,157 28 loss=0.01838625719120373
2019-01-18 14:42:33,158 29 loss=0.01741968811515612
2019-01-18 14:42:33,158 30 loss=0.016562504790937484
2019-01-18 14:42:33,159 31 loss=0.01580117440481665
2019-01-18 14:42:33,159 32 loss=0.01512396397412072
2019-01-18 14:42:33,160 33 loss=0.014520681864635366
2019-01-18 14:42:33,160 34 loss=0.01398245988135772
2019-01-18 14:42:33,160 35 loss=0.013501568907510576
2019-01-18 14:42:33,161 36 loss=0.013071262406666137
2019-01-18 14:42:33,161 37 loss=0.012685643168234522
2019-01-18 14:42:33,162 38 loss=0.012339549521843164
2019-01-18 14:42:33,162 39 loss=0.012028457919917095
2019-01-18 14:42:33,163 40 loss=0.011748399328729673
2019-01-18 14:42:33,163 41 loss=0.011495887305657962
2019-01-18 14:42:33,164 42 loss=0.011267855996358453
2019-01-18 14:42:33,164 43 loss=0.011061606576715911
2019-01-18 14:42:33,164 44 loss=0.010874760903496037
2019-01-18 14:42:33,165 45 loss=0.010705221334634758
2019-01-18 14:42:33,165 46 loss=0.010551135842936177
2019-01-18 14:42:33,166 47 loss=0.010410867681959878
2019-01-18 14:42:33,166 48 loss=0.010282968975156808
2019-01-18 14:42:33,167 49 loss=0.010166157692987279
2019-01-18 14:42:33,167 50 loss=0.010059297561164606
2019-01-18 14:42:33,167 final loss=0.010059297561164606
2019-01-18 14:42:33,167 best loss=10000000000.0, distortion=10000000000.0, map=0.0, wc_dist=10000000000.0
2019-01-18 14:42:33,167 	 Computing Major Stats lazily... 
2019-01-18 14:42:33,168 		 Completed edges=30 good=30 bad=0
2019-01-18 14:42:33,169 Distortion avg=0.0948381852491261 wc=1.286727708244645 me=1.1311724060921398 mc=1.137516881878247 nan_elements=0
2019-01-18 14:42:33,169 MAP = 1.0
2019-01-18 14:42:33,169 scale=[array([1.])]
2019-01-18 15:19:49,573 Commandline ['pytorch/pytorch_hyperbolic.py', 'learn', 'data/edges/parsing/ewt/ewt_dev/1987.edges', '--dim', '0', '--hyp', '0', '--edim', '10', '--euc', '1', '--sdim', '0', '--sph', '0', '--log-name', 'ewt_devr2/1987.edges.E10-1.lr1.log', '--batch-size', '65536', '--epochs', '50', '--checkpoint-freq', '10', '-g', '--subsample', '1024', '--learning-rate', '1']
2019-01-18 15:19:49,574 No Model Save selected!
